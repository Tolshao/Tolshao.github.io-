<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>免费图床:Github+Picgo+jsDelivr</title>
      <link href="/posts/img-bed/"/>
      <url>/posts/img-bed/</url>
      
        <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>简单说图床就是一个在网络上存储图片的地方，目的是为了节省本地服务器空间（<code>.md</code>和<code>.html</code>文件里图片是以链接的形式），加快图片打开速度，主要是个人博客和网站使用。</p><ul><li>微博图床：挂了已经</li><li>SM.MS：国外服务，慢</li><li>imgur：国外，被Q，慢</li><li>七牛云：需要注册国内域名，备案麻烦</li><li>阿里云：要花几块钱</li><li>腾讯云：比阿里贵</li></ul><p>但是，Github也有缺点，比如不用爬墙访问慢等，会导致国内访问网页的时候，图片刷新极慢，但是不要钱啊，配合jsDelivr可以白嫖成功。</p><p>另，不可能每次都开浏览器去上传图片，图床工具Picgo可以方便的帮你上传图片到图床，并且插件可以支持自定义域名，方便你用cdn工具来加速Github存放的图片访问。</p><h1 id="搭建步骤"><a href="#搭建步骤" class="headerlink" title="搭建步骤"></a>搭建步骤</h1><h2 id="新建Github仓库"><a href="#新建Github仓库" class="headerlink" title="新建Github仓库"></a>新建Github仓库</h2><p>登录/注册GitHub，新建一个仓库，填写好仓库名，仓库描述，根据需求选择是否为仓库初始化一个README.md描述文件。</p><p><img src="/img/15978320697562.jpg" alt=""></p><ul><li>仓库设置<ul><li>仓库名称</li><li>仓库公有/私有：因为图床需要被很多应用程序访问，所以需要设置成public的，切记</li><li>根据需要，决定是否初始化<code>readme.md</code></li></ul></li></ul><p><img src="/img/15978321283696.jpg" alt=""></p><h2 id="申请access-token给picgo"><a href="#申请access-token给picgo" class="headerlink" title="申请access token给picgo"></a>申请access token给picgo</h2><p>token是外部应用程序访问github的密钥，是picgo在github的身份证明<br>【注意】：需要注意的是token申请成功后，只会显示一次，需要自己妥善保存，否则要重新申请，最好配置完后在关闭picgo</p><ul><li>设置路径在<code>settings/Developer settings/generate new token</code></li></ul><p><img src="/img/15978321943320.jpg" alt=""></p><p><img src="/img/15978322447146.jpg" alt=""></p><ul><li>设置token<ul><li>填写token描述：方便知道哪个token干嘛的</li><li>token权限：这里只开放仓库repo的权限</li></ul></li></ul><p><img src="/img/15978322969831.jpg" alt=""></p><h2 id="配置Picgo"><a href="#配置Picgo" class="headerlink" title="配置Picgo"></a>配置Picgo</h2><ul><li>安装<ul><li>下载地址在这里<a href="https://github.com/Molunerfinn/PicGo">Picgo</a></li><li>也可以<code>brew cask install picgo</code> 大法</li></ul></li></ul><p>上图，我的设置如下：</p><ul><li>用户名<code>tolshao</code></li><li>仓库名<code>media</code></li><li>设定分支名：<code>master</code></li><li>设定Token：粘贴之前生成的<code>Token</code></li><li>存储路径<code>img/</code></li><li>自定义域名是仓库的别名，这里可以用<code>jsDelivr</code>来进行<code>cdn</code>加速，实现<code>https://raw.githubusercontent.com/tolshao/media/master/img/contact.jpg</code>到<code>https://cdn.jsdelivr.net/gh/tolshao/media/img/contact.jpg</code>的替换，实测快很多</li></ul><p><img src="/img/15978324636801.jpg" alt=""></p><p><img src="https://cdn.jsdelivr.net/gh/tolshao/media/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 图床 </tag>
            
            <tag> Picgo </tag>
            
            <tag> jsDelivr </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo 进阶设置指南</title>
      <link href="/posts/hexo-advanced/"/>
      <url>/posts/hexo-advanced/</url>
      
        <content type="html"><![CDATA[<h1 id="让hexo渲染MathJax复杂公式-默认的渲染引擎复杂公式会报错"><a href="#让hexo渲染MathJax复杂公式-默认的渲染引擎复杂公式会报错" class="headerlink" title="让hexo渲染MathJax复杂公式(默认的渲染引擎复杂公式会报错)"></a>让hexo渲染MathJax复杂公式(默认的渲染引擎复杂公式会报错)</h1><h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>对复杂公式的支持不够好，简单公式可以显示，复杂编译错误，验证表明，问题不是mathjax.js导致，是默认hexo引擎编译导致html文本转义错误。<br><img src="/img/15972822338745.jpg" alt="-w192"><br><img src="/img/15972822421519.jpg" alt="-w894"></p><h3 id="Reason"><a href="#Reason" class="headerlink" title="Reason"></a>Reason</h3><p>Hexo默认使用”hexo-renderer-marked”引擎渲染网页，该引擎会把一些特殊的markdown符号转换为相应的html标签，比如在markdown语法中，下划线’_’代表斜体，会被渲染引擎处理为<code>&lt;em&gt;</code>标签</p><p>因为类Latex格式书写的数学公式下划线 ‘_’ 表示下标，有特殊的含义，如果被强制转换为<code>&lt;em&gt;</code>标签，那么MathJax引擎在渲染数学公式的时候就会出错。例如，<code>x_i</code>在开始被渲染的时候，处理为<code>x&lt;em&gt;i&lt;/em&gt;</code>，这样MathJax引擎就认为该公式有语法错误，因为不会渲染。</p><p>类似的语义冲突的符号还包括’*’, ‘{‘, ‘}’, ‘\’等。</p><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><ul><li>更换默认的Hexo下 Markdown渲染引擎<br>marked -&gt; kramed</li></ul><pre><code class="lang-dash">npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-kramed --save</code></pre><ul><li><p>更改hexo转义冲突<br>找到根目录<code>node_modules\kramed\lib\rules\inline.js</code></p><ul><li><p>修改11行，取消对<code>\,{,}</code>的转义escape</p><pre><code class="lang-dash">//  escape: /^\\([\\`*&amp;#123;&amp;#125;\[\]()#$+\-.!_&gt;])/,escape: /^\\([`*\[\]()#$+\-.!_&gt;])/,</code></pre></li><li><p>修改20行em</p><pre><code class="lang-dash">//  em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</code></pre></li></ul></li><li><p>三连 <code>hexo cl &amp;&amp; hexo g &amp;&amp; hexo s</code>查看效果</p><h2 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h2></li><li><p>如果出问题，在主题<code>_config.yml</code>下设置<code>mathjax</code>为<code>true</code></p></li><li>文章也要开启<code>mathjax</code></li></ul><pre><code class="lang-yml">---title: 我是标题date: 2020-08-15 23:18:50tags:mathjax: true--</code></pre><h2 id="其他解决办法"><a href="#其他解决办法" class="headerlink" title="其他解决办法"></a>其他解决办法</h2><ul><li>服务器端的渲染<ul><li><a href="https://math.now.sh/home">math.now.sh</a></li><li><a href="https://github.com/MakerGYT/markdown-it-latex2img">markdown-it-latex2img</a></li></ul></li></ul><h1 id="SEO-搜索引擎优化"><a href="#SEO-搜索引擎优化" class="headerlink" title="SEO 搜索引擎优化"></a>SEO 搜索引擎优化</h1><p><a href="https://zhuanlan.zhihu.com/p/150718629">Google search console 大全</a></p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 博客设置 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> blog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习笔记7：策略梯度 Policy Gradient</title>
      <link href="/posts/rl-7/"/>
      <url>/posts/rl-7/</url>
      
        <content type="html"><![CDATA[<p>之前的策略优化，用的基本都是$\epsilon-greedly$的policy improve方法，这里介绍policy gradient法，不基于v、q函数</p><h1 id="1-introduction"><a href="#1-introduction" class="headerlink" title="1. introduction"></a>1. introduction</h1><p>策略梯度是以$P(a|s)$入手，概率$\pi(s,a)$的形式，同样是model free的<br><img src="/img/15973090963916.jpg" alt=""></p><script type="math/tex; mode=display">\pi_{\theta}(s, a)=\mathbb{P}[a \mid s, \theta]</script><p>调整策略的概率分布，寻找最优策略$\pi_*$</p><p><img src="/img/15971227558962.jpg" alt="-w497"></p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul><li>优点：<ul><li>更好收敛性</li><li>高维、连续动作空间高效</li><li>从随机策略中学习</li></ul></li><li>缺点：<ul><li>会限于<strong>局部最优</strong>，而不是全局最优</li><li>评价策略的过程：低效、高方差</li></ul></li><li>随机策略有时是最优策略，基于价值函数的策略有时会限于局部最优</li></ul><h2 id="Policy-Objective-function-策略目标函数"><a href="#Policy-Objective-function-策略目标函数" class="headerlink" title="Policy Objective function 策略目标函数"></a>Policy Objective function 策略目标函数</h2><p>对于不同的任务，需要建立针对性的3种目标函数</p><ul><li>1.Start Value：任务有始有终<script type="math/tex; mode=display">J_{1}(\theta)=V^{\pi_{\theta}}\left(s_{1}\right)=\mathbb{E}_{\pi_{\theta}}\left[v_{1}\right]</script></li><li>2.Average Value：连续任务，不停止。对所有状态求平均，d是状态s在策略$\pi\theta$下的分布函数。根据V值求P<script type="math/tex; mode=display">J_{a v V}(\theta)=\sum_{s} d^{\pi_{\theta}}(s) V^{\pi_{\theta}}(s)</script></li><li><p>3.Average reward per time-step：连续任务，不停止。d是状态s在策略$\pi\theta$下的分布函数。根据R值求P</p><script type="math/tex; mode=display">J_{a v R}(\theta)=\sum_{s} d^{\pi_{\theta}}(s) \sum_{a} \pi_{\theta}(s, a) \mathcal{R}_{s}^{a}</script></li><li><p>Objective：优化目标函数<br>find $\theta$ 最大化 $J(\theta)$</p></li></ul><h1 id="2-Finite-Difference-PG-有限差分策略梯度"><a href="#2-Finite-Difference-PG-有限差分策略梯度" class="headerlink" title="2. Finite Difference PG 有限差分策略梯度"></a>2. Finite Difference PG 有限差分策略梯度</h1><p>对每个维度的权重，分别进行查分求梯度，然后迭代权重，至最优<br><img src="/img/15971425601126.jpg" alt="-w449"></p><p>特点：</p><ul><li>n次运算，求得n维的梯度</li><li>简单、噪声、偶尔高效</li><li>通用性好，任意策略可用，即使策略目标函数不可微</li></ul><h1 id="3-MC-PG-蒙特卡洛策略梯度"><a href="#3-MC-PG-蒙特卡洛策略梯度" class="headerlink" title="3. MC PG 蒙特卡洛策略梯度"></a>3. MC PG 蒙特卡洛策略梯度</h1><p>要求：策略目标函数可微分，梯度可计算<br>引入了似然比概念</p><h2 id="Likelihood-ratios"><a href="#Likelihood-ratios" class="headerlink" title="Likelihood ratios"></a>Likelihood ratios</h2><h3 id="Score-function（not-value-function）"><a href="#Score-function（not-value-function）" class="headerlink" title="Score function（not value function）"></a>Score function（not value function）</h3><ul><li><p>Trick here： 用似然比 Likelihood ratios<br>将$\pi$梯度，变为$\pi$ 乘以 log 的梯度<br>函数在某个变量θ处的<strong>梯度</strong>等于该处<strong>函数值</strong>与该函数的<strong>对数函数</strong>在此处<strong>梯度</strong>的乘积 $d log(y) = dy/y$，默认底数为$e$</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\theta} \pi_{\theta}(s, a) &=\pi_{\theta}(s, a) \frac{\nabla_{\theta} \pi_{\theta}(s, a)}{\pi_{\theta}(s, a)} \\&=\pi_{\theta}(s, a) \nabla_{\theta} \log \pi_{\theta}(s, a)\end{aligned}</script></li><li><p>Score function: $\nabla_{\theta} \log \pi_{\theta}(s, a)$</p></li></ul><h3 id="Softmax-policy：策略概率按照指数分配"><a href="#Softmax-policy：策略概率按照指数分配" class="headerlink" title="Softmax policy：策略概率按照指数分配"></a>Softmax policy：策略概率按照指数分配</h3><p>线性组合 -&gt; softmax = $\pi$ 是状态s下，采取每个a的概率<br><img src="/img/15971450080893.jpg" alt="-w451"></p><p>通过取对数，拆分为加法，进而表示为</p><h3 id="Gaussian-polisy：策略概率按照距离分配"><a href="#Gaussian-polisy：策略概率按照距离分配" class="headerlink" title="Gaussian polisy：策略概率按照距离分配"></a>Gaussian polisy：策略概率按照距离分配</h3><ul><li>In continuous action spaces, a Gaussian policy is natural </li><li>Mean is a linear combination of state features $μ(s) = φ(s)^{T}θ$</li><li>Variance may be fixed σ , or can also parametrised Policy is Gaussian, a ∼ N (μ(s), σ2)</li><li>The score function is<script type="math/tex; mode=display">\nabla_{\theta} \log \pi_{\theta}(s, a)=\frac{(a-\mu(s)) \phi(s)}{\sigma^{2}}</script></li></ul><p>在实际应用中，要注意梯度消失现象，可以利用代数方法求解</p><h2 id="Policy-Gradient-theorem-策略梯度定理"><a href="#Policy-Gradient-theorem-策略梯度定理" class="headerlink" title="Policy Gradient theorem 策略梯度定理"></a>Policy Gradient theorem 策略梯度定理</h2><h3 id="One-step-MDPs"><a href="#One-step-MDPs" class="headerlink" title="One-step MDPs"></a>One-step MDPs</h3><p>没有序列，整个任务过程只有一步</p><ul><li>状态s~d(s)</li><li>r = R_{s,a}</li></ul><p>用似然比，计算策略梯度：<br>先给出奖励函数，三种形式一样如下：</p><script type="math/tex; mode=display">\begin{aligned}J(\theta) &=\mathbb{E}_{\pi_{\theta}}[r] \\&=\sum_{s \in \mathcal{S}} d(s) \sum_{a \in \mathcal{A}} \pi_{\theta}(s, a) \mathcal{R}_{s, a} \\\end{aligned}</script><p>相应梯度表示为：</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\theta} J(\theta) &=\sum_{s \in \mathcal{S}} d(s) \sum_{a \in \mathcal{A}} \pi_{\theta}(s, a) \nabla_{\theta} \log \pi_{\theta}(s, a) \mathcal{R}_{s, a} \\&=\mathbb{E}_{\pi_{\theta}}\left[\nabla_{\theta} \log \pi_{\theta}(s, a) r\right]\end{aligned}</script><h3 id="对于多步的标准MDPs"><a href="#对于多步的标准MDPs" class="headerlink" title="对于多步的标准MDPs"></a>对于多步的标准MDPs</h3><p>用Q函数，替代R函数，即可表征序列到End的奖励<br>对于下列都适用：</p><ul><li>初始价值函数：$J = J_1$</li><li>平均奖励函数： $J_{avR}$</li><li>平均价值函数： $\frac{1}{1-\gamma}J_{avV}$</li></ul><p>对任意可微策略，梯度都为</p><script type="math/tex; mode=display">\nabla_{\theta} J(\theta)=\mathbb{E}_{\pi_{\theta}}\left[\nabla_{\theta} \log \pi_{\theta}(s, a) Q^{\pi_{\theta}}(s, a)\right]</script><h3 id="MCPG-蒙特卡洛策略梯度法"><a href="#MCPG-蒙特卡洛策略梯度法" class="headerlink" title="MCPG 蒙特卡洛策略梯度法"></a>MCPG 蒙特卡洛策略梯度法</h3><ul><li>采样 替代 期望<br>上节式子表示为Score function 和 Q 值在策略$\pi$下的<strong>期望</strong><br>在MC中，在每个episode在$\pi$下，产生的序列就满足分布，整个过程都迭代完后的值，自然就是期望，因此梯度前没有概率分布函数，用常值替代。</li></ul><p><img src="/img/15971998167024.jpg" alt="-w433"></p><ul><li>特点：<ul><li>动作平滑</li><li>收敛性好，但是慢</li><li>方差大</li></ul></li></ul><h1 id="4-Actor-Critic-PG-AC策略梯度"><a href="#4-Actor-Critic-PG-AC策略梯度" class="headerlink" title="4. Actor-Critic PG AC策略梯度"></a>4. Actor-Critic PG AC策略梯度</h1><p>ACPG提出，解决PG方差大的问题<br>为了加快更新速度，我们希望把回合更新变为，每步更新，需要Q的估计值（指导策略更新），引入函数逼近器，取代PG中的Q采样</p><script type="math/tex; mode=display">Q_W(s,a) \approx Q^{\pi \theta}(s,a)</script><p>AC算法的主要部分 </p><ul><li>Critic：用来估计价值函数，（更新q(s,a,w)的参数w）</li><li>Actor：生成动作，（在critic的指引下，更新$\pi_\theta$的参数$\theta$）</li></ul><p>AC算法遵循， <strong>近似</strong>策略梯度法</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\theta} J(\theta) & \approx \mathbb{E}_{\pi_{\theta}}\left[\nabla_{\theta} \log \pi_{\theta}(s, a) Q_{w}(s, a)\right] \\\Delta \theta &=\alpha \nabla_{\theta} \log \pi_{\theta}(s, a) Q_{w}(s, a)\end{aligned}</script><p>例子：简单线性价值函数的AC算法</p><ul><li>Critic 线性组合，TD(0)</li><li>Actor  PG更新</li><li><p>逐步更新，在线实时<br><img src="/img/15976384741868.jpg" alt="-w377"></p></li><li><p>AC算法中的偏差</p><ul><li>对PG的估计引入了偏差</li><li>正确选择价值函数，有利于减小、消灭偏差，but how？？？</li></ul></li></ul><h2 id="Compatible-function-approximation-兼容函数估计"><a href="#Compatible-function-approximation-兼容函数估计" class="headerlink" title="Compatible function approximation 兼容函数估计"></a>Compatible function approximation 兼容函数估计</h2><p>上节线性近似的价值函数引入了偏差，小心设计的Q函数满足：</p><p>1.近似价值函数的梯度完全等同于策略函数对数的梯度，即不存在重名情况：</p><script type="math/tex; mode=display">\nabla_{w} Q_{w}(s, a)=\nabla_{\theta} \log \pi_{\theta}(s, a)</script><p>2.价值函数参数w使得均方差最小：</p><script type="math/tex; mode=display">\varepsilon=\mathbb{E}_{\pi_{\theta}}\left[\left(Q^{\pi_{\theta}}(s, a)-Q_{w}(s, a)\right)^{2}\right]</script><p>此时策略梯度是准确的，满足</p><script type="math/tex; mode=display">\nabla_{\theta} J(\theta)=\mathbb{E}_{\pi_{\theta}}\left[\nabla_{\theta} \log \pi_{\theta}(s, a) Q_{w}(s, a)\right]</script><ul><li>证明过程，（参数梯度 = 0）<br><img src="/img/15976423506794.jpg" alt="-w483"></li></ul><h3 id="Tricks——Advantage-function-critic"><a href="#Tricks——Advantage-function-critic" class="headerlink" title="Tricks——Advantage function critic"></a>Tricks——Advantage function critic</h3><p>核心思想：减去一个baseline，将MSE的减数和被减数都 往 0 方向拉，减小偏差<br>Advantage function = PG减去B(s)，好的B(s)是状态价值函数，V(s)是和<strong>策略无关</strong>的值，所以<strong>不改变梯度</strong>的期望的值<br><img src="/img/15976428419935.jpg" alt="-w465"></p><h4 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h4><ul><li><p>通过两个估计函数 和 两套参数，分别估计V、Q，进而估计A<br><img src="/img/15976451232295.jpg" alt="-w476"></p></li><li><p>直接用v值运算<br>但是并不需要用2个估计函数，因为<strong>TD误差是Q-V的无偏估计</strong></p></li></ul><p><img src="/img/15976451043580.jpg" alt="-w457"></p><h3 id="不同时间尺度下——Eligibility-Traces"><a href="#不同时间尺度下——Eligibility-Traces" class="headerlink" title="不同时间尺度下——Eligibility Traces"></a>不同时间尺度下——Eligibility Traces</h3><p>几种时间尺度下的更新算法</p><ul><li><p>针对<strong>Critic</strong>过程使用TD(λ)<br><img src="/img/15976458664595.jpg" alt="-w469"></p></li><li><p>针对<strong>Actor</strong>过程使用TD(λ)<br><img src="/img/15976475762634.jpg" alt="-w512"></p></li></ul><p><img src="/img/15976476902568.jpg" alt="-w473"></p><p>将TD(λ)的后向视角算法应用于实际问题时，可以在线实时更新，而且不需要完整的Episode。</p><p>PG是理论上是基于真实价值函数V(s)的<br>但是critic给PG提供了V的估计值，进而PG用估计的梯度去更新参数θ<br>结论是梯度也能使Actor更新到最优策略$\pi$</p><h3 id="Natural-policy-gradient"><a href="#Natural-policy-gradient" class="headerlink" title="Natural policy gradient"></a>Natural policy gradient</h3><p>高斯策略：按照期望和概率执行动作<br>缺点：对梯度估计不利，收敛性不好</p><p>Solution：Natural PG</p><ul><li>参数化独立</li><li><p>估计值与真值近似</p></li><li><p>对目标函数改写（噪声为0下）</p><script type="math/tex; mode=display">\nabla_{\theta}^{\text {nat}} \pi_{\theta}(s, a)=G_{\theta}^{-1} \nabla_{\theta} \pi_{\theta}(s, a)</script></li><li>Fisher information matrix 费雪信息矩阵<br>G反应了对估计值的准确程度，值越大，梯度更新越小，抑制噪声<script type="math/tex; mode=display">G_{\theta}=\mathbb{E}_{\pi_{\theta}}\left[\nabla_{\theta} \log \pi_{\theta}(s, a) \nabla_{\theta} \log \pi_{\theta}(s, a)^{T}\right]</script></li></ul><ul><li><p>Compatible function approximation</p><script type="math/tex; mode=display">\nabla_{w} A_{w}(s, a)=\nabla_{\theta} \log \pi_{\theta}(s, a)</script></li><li><p>简化为</p><script type="math/tex; mode=display">\begin{aligned}\nabla_{\theta} J(\theta) &=\mathbb{E}_{\pi_{\theta}}\left[\nabla_{\theta} \log \pi_{\theta}(s, a) A^{\pi_{\theta}}(s, a)\right] \\&=\mathbb{E}_{\pi_{\theta}}\left[\nabla_{\theta} \log \pi_{\theta}(s, a) \nabla_{\theta} \log \pi_{\theta}(s, a)^{T} w\right] \\&=G_{\theta} w \\\nabla_{\theta}^{n a t} J(\theta) &=w\end{aligned}</script></li><li><p><strong>用Critic参数，更新Actor参数</strong></p></li></ul><h2 id="总结PG"><a href="#总结PG" class="headerlink" title="总结PG"></a>总结PG</h2><p><img src="/img/15976510887080.jpg" alt="-w519"></p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> RL </tag>
            
            <tag> Policy gradient </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从0 -&gt; 1，拥有你的免费个人博客之“打个前站”</title>
      <link href="/posts/set-up-hexo/"/>
      <url>/posts/set-up-hexo/</url>
      
        <content type="html"><![CDATA[<h1 id="为什么想写个博客耍？"><a href="#为什么想写个博客耍？" class="headerlink" title="为什么想写个博客耍？"></a>为什么想写个博客耍？</h1><p>我们在生活和工作中会遇到的各种问题，现在基本都能从互联网上找到答案，因为个体相较于群体，所能接触到的面，太窄，也太小了。以前常去“百度知道”去搜答案，上网的门槛逐步降低之后，“知道”也不知道了，碎片化的问答里总是充斥着各种水军、广告，令人窒息。<br><img src="/img/15968069169200.jpg" alt="你说得对"></p><p>现在，你询问搜索引擎的问题，大多会在“知乎”、“博客”找到答案，与“知道”不同的是，详实且完整，足可以指引你前进。</p><p>然后就突发奇想，自己也写个吧？既然也在能力范围之内，就找资料去做了，正好也可以把最近写的笔记什么的归档起来。以前，没有读书写作的习惯，靠着还不算傻的脑瓜也把义务教育兑付了，往后才意识到，不是笔记没有用，而是你不知道它有用。也不知道是脑子笨了，还是知识多了，总容易忘东西，才意识到：写作的过程就是思考的量化，写不出来就是你不会，你不懂，你忘了，如果把自己的碎片拼成一篇博文，别人看了，能有所启发，甚至帮他解决了别地儿没解决的问题，那就更棒了。</p><p>博客同样也是一个记录生活的地方，比起微博，也更像回事儿。因为微博并不适用于所有的场合，碎片化的文字，更适合用来打发公交、地铁的闲暇。博客上的东西比微博，多少还是更有含金量的，当然这只针对大部分情况，如果有人在微博写书，咱也不能有啥意见，毕竟用微博(Twitter)治国的人，还是有的。<br><img src="/img/15968070216543.jpg" alt="你必须承认, 我独当一面"></p><p>前前后后花费了2天时间。就感慨，很多时候，事情能做成，大概有两种情况：</p><ol><li>你不得不做：老板追你，朋友挺你，亲人需要你</li><li>你想做：发自内心的想</li></ol><p>不过博客搭起来只是第一步，能坚持下去，你才算赢了，希望你的博客能见证你的成长</p><h1 id="能做到啥样"><a href="#能做到啥样" class="headerlink" title="能做到啥样"></a>能做到啥样</h1><p>🥮是指明灯，指引你的前行，让你总是充满着动力<br>po几个网友的样品图，啥样式的基本都全了<br><img src="/img/15968016972657.jpg" alt="简约系"></p><p><img src="/img/15968017968960.jpg" alt="高级系"></p><p><img src="/img/15968021026230.jpg" alt="粉系"></p><p>如果这些都不能满足你，可以来这看一下，<a href="https://hexo.io/themes/">Hexo.io/theme</a>，该挑花你眼。</p><p>虽然搭建过程可能对新手来说不是很友好，不过先看一下效果图，我想你早就干劲儿满满了</p><h1 id="路有三条，我择其一"><a href="#路有三条，我择其一" class="headerlink" title="路有三条，我择其一"></a>路有三条，我择其一</h1><p>目前常规的博客制造方法，一般有三种：</p><ul><li>个人主页注册：<br>指的是在现有的博客网站CSDN、Cnblog等注册即用，门槛低，自定义程度低，部分充斥广告⛔️</li><li>静态网站生成：<br>利用hexo等框架生成静态网站，然后上传到Github等平台（或者自己服务器）托管展示，稍微有点麻烦，上限最高，You can do whatever you like😊!!!</li><li>内容管理系统：<br>带有后台管理的博客系统，有现成的可以装（wordpress、ghost等），装好了就和第一个一样。缺点：需要配置空间（服务器）、数据库以及域名等，经费在燃烧🔥</li></ul><p>如果你非说还有一种，手写html？？？<br>大型劝退现场🙄</p><pre><code class="lang-html">&lt;div class="container row center-align" style="margin-bottom: 15px !important;"&gt;        &lt;div class="col s12 m8 l8 copy-right"&gt;            Copyright&amp;nbsp;&amp;copy;            &lt;span id="year"&gt;2020&lt;/span&gt;            &lt;a href="/about" target="_blank"&gt;Tolshao&lt;/a&gt;            |&amp;nbsp;Powered by&amp;nbsp;&lt;a href="https://hexo.io/" target="_blank"&gt;Hexo&lt;/a&gt;            |&amp;nbsp;Theme&amp;nbsp;&lt;a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank"&gt;Matery&lt;/a&gt;            &lt;br&gt;            &amp;nbsp;&lt;i class="fas fa-chart-area"&gt;&lt;/i&gt;&amp;nbsp;站点总字数:&amp;nbsp;&lt;span                class="white-color"&gt;31.5k&lt;/span&gt;&amp;nbsp;字</code></pre><p>我只能说，连牛顿也是踩在巨人肩膀上的，以我的半斤八两，就不去硌别人脚了😂</p><p>时间有限，有关blog搭建的技术部分还未整理完成<br>就相约在下次的推送和大家再见</p><p>欢迎催更👀</p><h2 id="需要用到的工具-todo"><a href="#需要用到的工具-todo" class="headerlink" title="需要用到的工具(todo)"></a>需要用到的工具(todo)</h2><ul><li>Hexo</li></ul><ul><li><a href="https://git-scm.com/book/zh/v2/起步-安装-Git">Git</a></li></ul><ul><li>Node.js</li></ul><ul><li>SSH配置</li></ul><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
        <tags>
            
            <tag> test </tag>
            
            <tag> hello world </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ios黄页：可算让iPhone好用了点儿</title>
      <link href="/posts/ios-yellow-page/"/>
      <url>/posts/ios-yellow-page/</url>
      
        <content type="html"><![CDATA[<h1 id="张小跳-ios黄页"><a href="#张小跳-ios黄页" class="headerlink" title="张小跳-ios黄页"></a>张小跳-ios黄页</h1><p>分享一个ios黄页工具，领取方式见文末</p><h1 id="黄页是什么"><a href="#黄页是什么" class="headerlink" title="黄页是什么"></a>黄页是什么</h1><p>说白了，可以理解为指电话号码簿，几乎世界每一个城市都有过这种纸张为载体所印制的电话号码本。</p><p>【百度百科】定义：黄页是国际通用按企业性质和产品类别编排的工商企业电话号码簿，以刊登企业名称、地址、电话号码为主体内容，相当于一个城市或地区的工商企业的户口本，国际惯例用黄色纸张印制，故称黄页。黄页，起源于北美洲，1880年世界上第一本黄页电话号簿在美国问世，至今已有100多年的历史。<br>以前，它长这个样子：<br><img src="/img/15959053121203.jpg" alt="-w412"></p><p>后来，它长这个样子，上网了</p><p><img src="/img/15959047443292.jpg" alt="w500"></p><p>随着互联网等信息技术的发展，黄页逐渐退出了历史舞台，人们的浏览器被“百度”、“Bing”、“Sogou”、“Google”等搜索引擎替代，这符合人们的行为认知，也极大地提高了效率</p><p>再后来，手机成为了每个人随时随地就能上网的工具，手机厂商发现这里能赚“5毛钱”，所以Android的黄页应运而生</p><p><img src="/img/15959064265953.jpg" alt="-w341"></p><p>经过了服务商的整合，确实是要比某度搜索要快的，毕竟……<br><img src="/img/15959063542994.jpg" alt="-w701"><br>我们也不好多说什么了<br>不过作为外地开发商，Apple在这一点做的属实落后了半个世纪，所以</p><h1 id="干货奉上"><a href="#干货奉上" class="headerlink" title="干货奉上"></a>干货奉上</h1><p>导入常用联系人头像，优化 iOS 来电、信息界面体验。</p><p><img src="/img/15970556799481.png" alt=""></p><p>很醒目有木有，以后短信、电话更方便了</p><h2 id="使用指南"><a href="#使用指南" class="headerlink" title="使用指南"></a>使用指南</h2><ol><li>私信公众号“黄页”下载 <code>黄页.zip</code>；</li><li>解压后，根据不同平台的指南导入 <code>vcf</code> 文件至 iCloud 中，推荐单独创建「黄页」分组方便管理和隐藏。</li></ol><hr><h2 id="号码收录"><a href="#号码收录" class="headerlink" title="号码收录"></a>号码收录</h2><p>由于不同地区不同运营商的 106 短信推送号段存在差异，项目不作收录，建议将本项目作为一个基础模板，导入联系人后可以按以下方式自行补充其余号码</p><p><img src="https://user-images.githubusercontent.com/2666735/59747105-ccd33480-92aa-11e9-90e0-93f295dcb504.png" alt="Screenshot"></p><h2 id="图标设计"><a href="#图标设计" class="headerlink" title="图标设计"></a>图标设计</h2><ul><li>采用 <code>PNG</code> 编码</li><li>画布大小 <code>200w200h</code></li><li>logo 居中放置<ul><li>圆形尺寸 140w140h</li><li>正矩形尺寸 120w120h</li><li>长矩形尺寸 160w80h</li><li>无 svg 需要使用 Inkscape 改绘转换</li><li>特殊情况特殊处理</li></ul></li><li>图像大小压缩在 <code>20 kB</code> 内</li></ul><p><img src="/img/15970557154990.png" alt=""></p><h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><ul><li>项目来自github: metowolf/vCards</li><li><a href="http://www.114best.com/">114 百事通</a>提供查询接口</li><li><a href="https://haoma.baidu.com/yellowPage">百度手机卫士</a>提供查询接口</li><li><a href="https://www.kexinhaoma.org/">中国可信号码数据中心</a>提供查询接口</li></ul><p>====<br>推荐朋友关注公众号“探物及理”，谢谢各位<br>ios黄页，可以后台回复“黄页”领取。</p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 收藏 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ios </tag>
            
            <tag> 黄页 </tag>
            
            <tag> iPhone </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>为什么数值仿真里要用RK4（龙格库塔法）</title>
      <link href="/posts/rk4/"/>
      <url>/posts/rk4/</url>
      
        <content type="html"><![CDATA[<p>小跳最近在搭建一个数值仿真环境，由于需要用到python里面的一些库，所以不得不把simulink的模型搬过来，我们都知道在simulink里，仿真的时候设置仿真步长和微分方程求解器是必要的步骤。但是为什么要设置这个小跳却早已忘记了。</p><p>一年级的时候搬砖搬多了，数分课也没好好上，回头一看，这么简单的东西，当时竟然整的稀里糊涂的。</p><h1 id="为什么要用RK4"><a href="#为什么要用RK4" class="headerlink" title="为什么要用RK4"></a>为什么要用RK4</h1><p>先po一张图，直观感受一下仿真的误差。<br><img src="/img/15956439603281.jpg" alt="-w752"></p><p>对于给定线性常微分方程</p><script type="math/tex; mode=display">\dot x = x</script><p>易得，其解是</p><script type="math/tex; mode=display">x(t) = Ce^t</script><p>RK4是龙格库塔法曲线，None是一阶解法$x(t+dt) = x(t)+\dot x dt$<br>可以看到，线性常微分方程误差尚且如此之大，那么推广到非线性微分方程，像这种形式</p><script type="math/tex; mode=display">\dot x = f(x,t) = tx^2 - \frac{x}{t}...</script><p>那肯定误差直接起飞了。解析解求起来也挺麻烦，这里就不再引入分析了。</p><p>接下来把定义回顾一下，贴一下代码，有需自取，希望对大家有所帮助。</p><h1 id="定义回顾"><a href="#定义回顾" class="headerlink" title="定义回顾"></a>定义回顾</h1><p>数值分析中，龙格－库塔法（Runge-Kutta methods）是用于非线性常微分方程的解的重要的一类隐式或显式迭代法。这些技术由数学家卡尔·龙格和马丁·威尔海姆·库塔于1900年左右发明。该方法主要是在已知方程导数和初值信息，利用计算机仿真时应用，省去求解微分方程的复杂过程。</p><p>令初值问题表述如下。</p><script type="math/tex; mode=display">y' = f(t,y), y(t_0) = y_0</script><p>则，对于该问题的RK4由如下方程给出：</p><script type="math/tex; mode=display">y_{n+1}=y_{n}+\frac{h}{6}\left(k_{1}+2 k_{2}+2 k_{3}+k_{4}\right) \\</script><p>其中</p><script type="math/tex; mode=display">\begin{matrix}k_{1}=f\left(t_{n}, y_{n}\right) \\ k_{2}=f\left(t_{n}+\frac{h}{2}, y_{n}+\frac{h}{2} k_{1}\right) \\k_{3}=f\left(t_{n}+\frac{h}{2}, y_{n}+\frac{h}{2} k_{2}\right) \\k_{4}=f\left(t_{n}+h, y_{n}+h k_{3}\right)\end{matrix}</script><p>式中，$h$为仿真步长，满足$h&lt;\epsilon_1 \rightarrow error&lt;\epsilon_2$</p><h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><pre><code class="lang-python">import numpy as npimport matplotlib.pyplot as pltimport sympy as sy# 这里介绍一个符号运算的方法，可以用来求解方程什么的def diff_eq(t,x):    return sy.diff(x(t),t,1) - x(t)t = sy.symbols('t')x = sy.Function('x')sy.pprint(sy.dsolve(diff_eq(t,x),x(t)))def dot_x(t,x):    return xdef rk4(f,t,x,h):    k1 = f(t,x);    k2 = f(t+0.5*h,x + 0.5*h*k1)    k3 = f(t+0.5*h,x + 0.5*h*k2)    k4 = f(t+h,x + h*k3)    return h/6*(k1+2*k2+2*k3+k4)t_list = np.arange(0,5,0.1);#print(t)x1_list = np.exp(t_list)x2_list = []x3_list = []h = 0.1x2 = 1;x3 = 1;for t in t_list:#    print(t,idx)    x2_list.append(x2)    x3_list.append(x3)    x2 = x2 + rk4(dot_x,t, x2, h)    x3 = x3 + dot_x(t,x3) * h                error_2 = x1_list - x2_listerror_3 = x1_list - x3_listplt.figure()plt.subplot(2,1,1)plt.plot(t_list,x1_list, 'b-',label='Real')plt.plot(t_list,x2_list,'r--', label = 'RK4')plt.plot(t_list,x3_list,'g--', label = 'None')plt.legend()plt.subplot(2,1,2)plt.plot(t_list,error_2, 'r--',label='Error_RK4')plt.plot(t_list,error_3, 'g--',label='Error_none')plt.legend()plt.xlabel('Time(s)')plt.show()</code></pre><h1 id="闲话"><a href="#闲话" class="headerlink" title="闲话"></a>闲话</h1><p>这里推荐一个提高效率的工具Matplotlib cheat sheet</p><p>对于一个经常画图的科研狗来说，这张图真是太太太太有必要了，因为时常遇到以下场景，不记得colormap名字，打开文档查一番，不记得线宽关键词，打开文档查一番，不记得marker名字，打开文档查一番。。。。。等等等等<br><img src="/img/15956450473625.jpg" alt=""></p><p>所以，有了这张图，在平常画图的时候中遇到的95%需要查文档的问题都可以在这张图中找到答案。</p><p>===<br>这个速查表，可以关注微信公众号“探物及理”后台回复“python画图”领取。</p><p>===<br><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RK4 </tag>
            
            <tag> 数值仿真 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习笔记6：值函数估计Value function Approximation</title>
      <link href="/posts/rl-6/"/>
      <url>/posts/rl-6/</url>
      
        <content type="html"><![CDATA[<h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><h2 id="v、q表的问题"><a href="#v、q表的问题" class="headerlink" title="v、q表的问题"></a>v、q表的问题</h2><ul><li>解决离散化的s,a,导致q-table存储量、运算量大</li><li>解决连续s、a的表示问题</li></ul><h2 id="solution"><a href="#solution" class="headerlink" title="solution"></a>solution</h2><p>用带权重估计函数，估计v or q</p><script type="math/tex; mode=display">\begin{aligned}\hat{v}(s, \mathbf{w}) & \approx v_{\pi}(s) \\\text { or } \hat{q}(s, a, \mathbf{w}) & \approx q_{\pi}(s, a)\end{aligned}</script><h2 id="函数估计器"><a href="#函数估计器" class="headerlink" title="函数估计器"></a>函数估计器</h2><p>可谓函数逼近，需要函数式可微分的</p><ul><li>线性组合</li><li>神经网络</li></ul><p>这些<strong>不可微</strong></p><ul><li>决策树 decision tree</li><li>领域Nearest neighbour</li><li>傅里叶/ 小波Fourier/ wavelet bases</li></ul><h1 id="incremental-methods-递增方法"><a href="#incremental-methods-递增方法" class="headerlink" title="incremental methods 递增方法"></a>incremental methods 递增方法</h1><h2 id="Gradient-descent-梯度下降"><a href="#Gradient-descent-梯度下降" class="headerlink" title="Gradient descent 梯度下降"></a>Gradient descent 梯度下降</h2><p>值函数估计：随机梯度下降法SGD<br><img src="/img/15965268722996.jpg" alt="-w523"></p><h2 id="Table-lookup-是-GD的一种特例"><a href="#Table-lookup-是-GD的一种特例" class="headerlink" title="Table lookup 是 GD的一种特例"></a>Table lookup 是 GD的一种特例</h2><p>类似于机器学习的分类问题，将状态值写成0、1向量</p><p><img src="/img/15965277694513.jpg" alt="-w290"></p><h2 id="Find-a-target-for-value-function-approximation"><a href="#Find-a-target-for-value-function-approximation" class="headerlink" title="Find a target for value function approximation"></a>Find a target for value function approximation</h2><p>把估计函数作为一个监督学习<br>目标是谁呢，通过MC、TD方法，设定目标<br><img src="/img/15965279560154.jpg" alt="-w439"></p><h2 id="生成训练集"><a href="#生成训练集" class="headerlink" title="生成训练集"></a>生成训练集</h2><h3 id="For-linear-MC"><a href="#For-linear-MC" class="headerlink" title="For linear MC"></a>For linear MC</h3><p><img src="/img/15965286821264.jpg" alt="-w335"></p><ul><li>无偏目标估计</li><li>局部最优</li></ul><h3 id="For-linear-TD（0）"><a href="#For-linear-TD（0）" class="headerlink" title="For linear TD（0）"></a>For linear TD（0）</h3><p><img src="/img/15965287396993.jpg" alt="-w479"></p><ul><li>收敛趋向全局最优</li></ul><h3 id="For-linear-TD（-lambda-）"><a href="#For-linear-TD（-lambda-）" class="headerlink" title="For linear TD（$\lambda$）"></a>For linear TD（$\lambda$）</h3><p><img src="/img/15970471950069.jpg" alt="-w427"></p><p>$\delta$ scalar number<br>$E_t$ 维度和s维度一致</p><ul><li>前后向 相等</li></ul><h1 id="Incremental-Control-Algorithms"><a href="#Incremental-Control-Algorithms" class="headerlink" title="Incremental Control Algorithms"></a>Incremental Control Algorithms</h1><p>用q函数，替代v函数<br><img src="/img/15970492924377.jpg" alt="-w492"></p><p><img src="/img/15970496242583.jpg" alt="-w530"></p><h2 id="收敛性分析"><a href="#收敛性分析" class="headerlink" title="收敛性分析"></a>收敛性分析</h2><ul><li><p>预测学习</p><ul><li>On-policy：一般边训练，边执行，(s,a)是当前policy产生的</li><li>off-policy：离线训练，通过训练其他策略或者agent产生的(s,a)训练集</li></ul></li></ul><p><img src="/img/15970511491893.jpg" alt="-w527"><br>引入Gradient TD，完全满足贝尔曼方程，无差<br><img src="/img/15970539060941.jpg" alt="-w540"></p><ul><li>控制学习</li></ul><p><img src="/img/15970539922026.jpg" alt="-w503"></p><p>（√）表示在最优值函数附近振荡</p><h1 id="batch-methods"><a href="#batch-methods" class="headerlink" title="batch methods"></a>batch methods</h1><h2 id="For-least-squares-prediction"><a href="#For-least-squares-prediction" class="headerlink" title="For least squares prediction"></a>For least squares prediction</h2><p>LS定义，估计误差平方，求和<br><img src="/img/15970588911111.jpg" alt="-w495"></p><p>相当于经历重现（experience replay）</p><ul><li>从history中sample一个batch</li><li>用SGD更新参数w</li></ul><p><img src="/img/15970589362830.jpg" alt="-w526"><br>找到使LS最小的权重$w^\pi$</p><h2 id="Experience-Replay-in-Deep-Q-Networks-DQN"><a href="#Experience-Replay-in-Deep-Q-Networks-DQN" class="headerlink" title="Experience Replay in Deep Q-Networks (DQN)"></a>Experience Replay in Deep Q-Networks (DQN)</h2><h3 id="Two-features"><a href="#Two-features" class="headerlink" title="Two features"></a>Two features</h3><ul><li><strong>Experience Relpay</strong>：minibatch的数据采样自memory-D</li><li><strong>Fixed Q-targets</strong>：$w^-$ 在一个更新batch内 ，保持不变，让更新过程更稳定<br><img src="/img/15970708646292.jpg" alt="-w610"></li></ul><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><ol><li>Take action at according to ε-greedy policy</li><li>Store transition (st,at,rt+1,st+1) in replay memory D </li><li>Sample random mini-batch of transitions (s,a,r,s′) from D </li><li>Compute Q-learning targets w.r.t. old, fixed parameters $w^− $</li><li>Optimise MSE between Q-network and Q-learning targets</li></ol><script type="math/tex; mode=display">\mathcal{L}_{i}\left(w_{i}\right)=\mathbb{E}_{s, a, r, s^{\prime}} \sim \mathcal{D}_{i}\left[\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime} ; w_{i}^{-}\right)-Q\left(s, a ; w_{i}\right)\right)^{2}\right]</script><ol><li>用SGD更新<br>伪算法：<br><img src="/img/15971441168183.jpg" alt=""><br><strong>注意：</strong></li></ol><ul><li>Fixed Q-target $\theta$，每C steps 更新一次</li><li>Experience Replay： minibatch 从 memory D 采样</li></ul><p>Features：</p><ul><li>随机采样，打破了状态之间的联系</li><li>冻结参数，增加了算法的<strong>稳定性</strong>，选q的网络参数回合制更新</li></ul><ul><li>例子<br>DQN in Atari（构成）<ul><li>input: state s （4 frames pictures）</li><li>output: Q(s,a) </li><li>CNN： mapping input(s) to output(Q)</li></ul></li></ul><h3 id="LS-最小二乘法-总结"><a href="#LS-最小二乘法-总结" class="headerlink" title="LS 最小二乘法  总结"></a>LS 最小二乘法  总结</h3><ul><li>Experience replay -&gt; LS solution</li><li>迭代次数太多</li><li>用线性估计$\hat v(s,w) = x(s)^Tw$</li><li>直接求解LS</li></ul><h2 id="LSP-直接求解"><a href="#LSP-直接求解" class="headerlink" title="LSP 直接求解"></a>LSP 直接求解</h2><p>对于线性近似函数：</p><script type="math/tex; mode=display">\hat v(s,w) = x(s)^T w</script><p>最终的平衡状态，梯度=0<br>求解方程，得到w值关于状态s和v真值的函数关系<br><img src="/img/15970717288619.jpg" alt="-w592"><br>However，真值<strong>不知道</strong><br>缺点是复杂度高，引入了矩阵的逆</p><h3 id="Other-algorithms"><a href="#Other-algorithms" class="headerlink" title="Other algorithms"></a>Other algorithms</h3><p><img src="/img/15971205641184.jpg" alt="-w574"><br><img src="/img/15971205882497.jpg" alt="-w598"><br><img src="/img/15971207382795.jpg" alt="-w603"></p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> RL </tag>
            
            <tag> 值函数估计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keras &amp; Tensorflow 笔记</title>
      <link href="/posts/keras-tensorflow/"/>
      <url>/posts/keras-tensorflow/</url>
      
        <content type="html"><![CDATA[<p>Keras是一个高层神经网络API，Keras由纯Python编写而成并基于Tensorflow、Theano以及CNTK后端。Keras为支持快速实验而生，能够把你的idea迅速转换为结果，如果你有如下需求，请选择Keras：</p><ul><li>简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性）</li><li>支持CNN和RNN，或二者的结合</li><li>无缝CPU和GPU切换</li></ul><p>有串联式和函数式两种建模方式，串联式建模方式</p><ul><li>串联式Sequential：</li></ul><pre><code class="lang-python">model = Sequential()model.add(Dense(32, input_dim=784))model.add(Activation('relu'))</code></pre><ul><li>函数式：</li></ul><pre><code>def model_name(input_shape, output_shape):    inputs = Input(shape = input_shape, dtype = , name = '')    x = Dense(64 , activation='relu')(inputs)    x = Dense(64,activation='relu')(x)    predictions = Dense(output_shape,activation='softmax')(x)    model = Model(inputs=inputs, outputs=predictions)    return model</code></pre><h1 id="学习一般操作步骤"><a href="#学习一般操作步骤" class="headerlink" title="学习一般操作步骤"></a>学习一般操作步骤</h1><p>from keras import Model ……</p><ol><li>Generate：<br><code>model = Model(inputs = input, outputs = output)</code></li><li>Compile：<br>model.compile(配置优化器，学习率，误差等参数)</li><li>Fit \ Train：<br><code>model.fit(X_train, Y_train, (X_dev, Y_dev),metric = [])</code></li><li>Evaluate \ test：<br><code>model.predict(X_test, Y_test)</code><br>fit和predict函数有返回值的，最好用一个变量来接住，方便查看预测过程中的变量信息history。</li></ol><h1 id="Tricks-and-Snippets"><a href="#Tricks-and-Snippets" class="headerlink" title="Tricks and Snippets"></a>Tricks and Snippets</h1><h2 id="模型可视化"><a href="#模型可视化" class="headerlink" title="模型可视化"></a>模型可视化</h2><h3 id="命令行打印：keras自带的summary函数"><a href="#命令行打印：keras自带的summary函数" class="headerlink" title="命令行打印：keras自带的summary函数"></a>命令行打印：keras自带的summary函数</h3><p><code>model.summary()</code><br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15954994831618.jpg?x-oss-process=style/blog" alt="-w582"></p><h3 id="调用库，打印保存图片"><a href="#调用库，打印保存图片" class="headerlink" title="调用库，打印保存图片"></a>调用库，打印保存图片</h3><p>使用方法：</p><pre><code class="lang-python">Keras.utils.plot_model plot_model(model,to_file='a.png')</code></pre><p>结果如下，还可以保存为pdf等格式<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15955035723718.jpg?x-oss-process=style/blog" alt="-w425"></p><h3 id="PlotNeuralNet绘制latex风格的网络图"><a href="#PlotNeuralNet绘制latex风格的网络图" class="headerlink" title="PlotNeuralNet绘制latex风格的网络图"></a><a href="https://github.com/HarisIqbal88/PlotNeuralNet">PlotNeuralNet</a>绘制latex风格的网络图</h3><p>例图：<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15955111765714.jpg?x-oss-process=style/blog" alt="-w456"></p><p>使用方法：</p><ol><li>下载github源文件，安装pycore库，将目录中的python包，拷贝至<code>/usr/local/lib/python3.7/site-packages/pycore/</code></li><li>根据example搭建网络结构的python文件</li><li>运行python文件生成filename.tex文件</li><li><code>pdflatex filename.tex</code>，此步骤需要提前拷贝源文件layers中sty文件至tex文件目录，用pdflaetx编译需要texlive环境，请提前安装。</li></ol><h3 id="model-fit函数调用"><a href="#model-fit函数调用" class="headerlink" title="model.fit函数调用"></a>model.fit函数调用</h3><p>这个方法最为硬核，其中mandb还可以横纵向对比多个模型的各个参数，并方便debug和optimize<br>使用方法：</p><pre><code class="lang-python">from rl.callbacks import WandbLoggerimport tensorboardmodel.fig(巴拉巴拉, callbacks = [函数])</code></pre><p>``，在网页localhost可视化</p><ul><li>TensorBoard</li><li>Mandb：callbacks=[WandbLogger()]，需要提前进行wandb初始化并在config中定义需要log的变量。<br>Tensorboard作者没有去尝试，这里就先贴一张Wandb的可视化结果：<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15955742598518.jpg?x-oss-process=style/blog" alt="-w1436"></li></ul><h3 id="Netron软件"><a href="#Netron软件" class="headerlink" title="Netron软件"></a>Netron软件</h3><p>下载安装，导入keras模型.h5即可食用，也支持tf、pytorch等多种模型，界面如下<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15954993270061.jpg?x-oss-process=style/blog" alt="-w866"></p><h3 id="超参数调节"><a href="#超参数调节" class="headerlink" title="超参数调节"></a>超参数调节</h3><p>超参数就是模型权重以外的其他参数，比如层种类，层深度、宽度，优化器类型、学习率大小等等，它们都影响着模型的表现和上限，超参数一动，就是一个新的模型了。但是超参数却没有像构建神经网络一样有可遵照的理论指导，一直以来都是从业人员的难点。<br>虽然网上已经有很多关于超参数调节的帖子，但大多都为经验之谈，是研究人员在实践中摸索、发现并总结的。就像控制理论里最简单PID调节一样，三个参数就能调的人头大，有些模型遵照经验去调还可能不work。<br>其实这点早就为我们想到了，作者找到了几个超参数调节器</p><h4 id="keras-tunner"><a href="#keras-tunner" class="headerlink" title="keras tunner"></a><a href="https://blog.csdn.net/wmq104/article/details/105740497">keras tunner</a></h4><p>根据验证集的表现自动优化超参数<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15955749309209.jpg?x-oss-process=style/blog" alt=""></p><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15955749728608.jpg?x-oss-process=style/blog" alt=""></p><h4 id="keras-lr-finder"><a href="#keras-lr-finder" class="headerlink" title="keras-lr-finder"></a>keras-lr-finder</h4><p>使用方法：安装python库keras_lr_finder</p><p>代码：引用库，包装模型，绘制结果</p><pre><code>import keras_lr_finder# model is a Keras modellr_finder = LRFinder(model)# Train a model with batch size 512 for 5 epochs# with learning rate growing exponentially from 0.0001 to 1lr_finder.find(x_train, y_train, start_lr=0.0001, end_lr=1, batch_size=512, epochs=5)# Plot the loss, ignore 20 batches in the beginning and 5 in the endlr_finder.plot_loss(n_skip_beginning=20, n_skip_end=5)</code></pre><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15948027436905.png?x-oss-process=style/blog" alt=""></p><pre><code># Plot rate of change of the loss# Ignore 20 batches in the beginning and 5 in the end# Smooth the curve using simple moving average of 20 batches# Limit the range for y axis to (-0.02, 0.01)lr_finder.plot_loss_change(sma=20, n_skip_beginning=20, n_skip_end=5, y_lim=(-0.01, 0.01))</code></pre><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15948027304867.png?x-oss-process=style/blog" alt=""></p><h4 id="利用scikit-learn交互网格搜索超参数"><a href="#利用scikit-learn交互网格搜索超参数" class="headerlink" title="利用scikit-learn交互网格搜索超参数"></a><a href="https://blog.csdn.net/happytofly/article/details/80124813">利用scikit-learn交互网格搜索超参数</a></h4><h1 id="设置备忘"><a href="#设置备忘" class="headerlink" title="设置备忘"></a>设置备忘</h1><h2 id="Keras下载的预训练数据存放目录"><a href="#Keras下载的预训练数据存放目录" class="headerlink" title="Keras下载的预训练数据存放目录"></a>Keras下载的预训练数据存放目录</h2><p><code>root\\.keras\models</code></p><h1 id="错误记录"><a href="#错误记录" class="headerlink" title="错误记录"></a>错误记录</h1><ul><li><strong>非</strong>张量运算变量运算用内置函数，+ - 操作会把张量 转为 Tensorflow，报错</li><li>实数，不用tf. 或者 K. 函数库运算，报错“张量”</li><li>张量一定用内置函数，python支持@ + - 等操作，但是偶尔报错</li></ul><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> keras </tag>
            
            <tag> tensorflow </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习22张精炼图笔记总结</title>
      <link href="/posts/deep-learning-summary/"/>
      <url>/posts/deep-learning-summary/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习精炼图笔记总结"><a href="#深度学习精炼图笔记总结" class="headerlink" title="深度学习精炼图笔记总结"></a>深度学习精炼图笔记总结</h1><p>本文转自知乎（Sophia）公众号【计算机视觉联盟】<br>笔记图片由 TessFerrandez 整理，这套信息图优美地记录了深度学习课程的知识与亮点。因此它不仅仅适合初学者了解深度学习，还适合机器学习从业者和研究者复习基本概念。这不仅仅是一份课程笔记，同时还是一套信息图与备忘录。</p><p>从深度学习基础、卷积网络和循环网络三个方面介绍该笔记</p><h1 id="1-深度学习基本概念"><a href="#1-深度学习基本概念" class="headerlink" title="1. 深度学习基本概念"></a>1. 深度学习基本概念</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-1-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-1-1024"></p><p>监督学习：所有输入数据都有确定的对应输出数据，在各种网络架构中，输入数据和输出数据的节点层都位于网络的两端，训练过程就是不断地调整它们之间的网络连接权重。</p><p>左上：列出了各种不同网络架构的监督学习，比如标准的神经网络（NN）可用于训练房子特征和房价之间的函数，卷积神经网络（CNN）可用于训练图像和类别之间的函数，循环神经网络（RNN）可用于训练语音和文本之间的函数。</p><p>左下：分别展示了 NN、CNN 和 RNN 的简化架构。这三种架构的前向过程各不相同，NN 使用的是权重矩阵（连接）和节点值相乘并陆续传播至下一层节点的方式；CNN 使用矩形卷积核在图像输入上依次进行卷积操作、滑动，得到下一层输入的方式；RNN 记忆或遗忘先前时间步的信息以为当前计算过程提供长期记忆。</p><p>右上：NN 可以处理结构化数据（表格、数据库等）和非结构化数据（图像、音频等）。</p><p>右下：深度学习能发展起来主要是由于大数据的出现，神经网络的训练需要大量的数据；而大数据本身也反过来促进了更大型网络的出现。深度学习研究的一大突破是新型激活函数的出现，用 ReLU 函数替换sigmoid 函数可以在反向传播中保持快速的梯度下降过程，sigmoid 函数在正无穷处和负无穷处会出现趋于零的导数，这正是梯度消失导致训练缓慢甚至失败的主要原因。要研究深度学习，需要学会「idea—代码—实验—idea」的良性循环。</p><h1 id="2-logistic-回归"><a href="#2-logistic-回归" class="headerlink" title="2. logistic 回归"></a>2. logistic 回归</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-2-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-2-1024"></p><p>左上：logistic 回归主要用于二分类问题，如图中所示，logistic 回归可以求解一张图像是不是猫的问题，其中图像是输入（x），猫（1）或非猫（0）是输出。我们可以将 logistic 回归看成将两组数据点分离的问题，如果仅有线性回归（激活函数为线性），则对于非线性边界的数据点（例如，一组数据点被另一组包围）是无法有效分离的，因此在这里需要用非线性激活函数替换线性激活函数。在这个案例中，我们使用的是 sigmoid 激活函数，它是值域为（0, 1）的平滑函数，可以使神经网络的输出得到连续、归一（概率值）的结果，例如当输出节点为（0.2, 0.8）时，判定该图像是非猫（0）。</p><p>左下：神经网络的训练目标是确定最合适的权重 w 和偏置项 b，那这个过程是怎么样的呢？</p><p>这个分类其实就是一个优化问题，优化过程的目的是使预测值 y hat 和真实值 y 之间的差距最小，形式上可以通过寻找目标函数的最小值来实现。所以我们首先确定目标函数（损失函数、代价函数）的形式，然后用梯度下降逐步更新 w、b，当损失函数达到最小值或者足够小时，我们就能获得很好的预测结果。</p><p>右上：损失函数值在参数曲面上变化的简图，使用梯度可以找到最快的下降路径，学习率的大小可以决定收敛的速度和最终结果。学习率较大时，初期收敛很快，不易停留在局部极小值，但后期难以收敛到稳定的值；学习率较小时，情况刚好相反。一般而言，我们希望训练初期学习率较大，后期学习率较小，之后会介绍变化学习率的训练方法。</p><p>右下：总结整个训练过程，从输入节点 x 开始，通过前向传播得到预测输出 y hat，用 y hat 和 y 得到损失函数值，开始执行反向传播，更新 w 和 b，重复迭代该过程，直到收敛。</p><h1 id="3-浅层网络的特点"><a href="#3-浅层网络的特点" class="headerlink" title="3. 浅层网络的特点"></a>3. 浅层网络的特点</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-3-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-3-1024"></p><p>左上：浅层网络即隐藏层数较少，如图所示，这里仅有一个隐藏层。</p><p>左下：这里介绍了不同激活函数的特点：</p><p>sigmoid：sigmoid 函数常用于二分分类问题，或者多分类问题的最后一层，主要是由于其归一化特性。sigmoid 函数在两侧会出现梯度趋于零的情况，会导致训练缓慢。<br>tanh：相对于 sigmoid，tanh 函数的优点是梯度值更大，可以使训练速度变快。<br>ReLU：可以理解为阈值激活（spiking model 的特例，类似生物神经的工作方式），该函数很常用，基本是默认选择的激活函数，优点是不会导致训练缓慢的问题，并且由于激活值为零的节点不会参与反向传播，该函数还有稀疏化网络的效果。<br>Leaky ReLU：避免了零激活值的结果，使得反向传播过程始终执行，但在实践中很少用。<br>右上：为什么要使用激活函数呢？更准确地说是，为什么要使用非线性激活函数呢？</p><p>上图中的实例可以看出，没有激活函数的神经网络经过两层的传播，最终得到的结果和单层的线性运算是一样的，也就是说，没有使用非线性激活函数的话，无论多少层的神经网络都等价于单层神经网络（不包含输入层）。</p><p>右下：如何初始化参数 w、b 的值？</p><p>当将所有参数初始化为零的时候，会使所有的节点变得相同，在训练过程中只能学到相同的特征，而无法学到多层级、多样化的特征。解决办法是随机初始化所有参数，但仅需少量的方差就行，因此使用 Rand（0.01）进行初始化，其中 0.01 也是超参数之一。</p><h1 id="4-深度神经网络的特点"><a href="#4-深度神经网络的特点" class="headerlink" title="4. 深度神经网络的特点"></a>4. 深度神经网络的特点</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-4-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-4-1024"></p><p>左上：神经网络的参数化容量随层数增加而指数式地增长，即某些深度神经网络能解决的问题，浅层神经网络需要相对的指数量级的计算才能解决。</p><p>左下：CNN 的深度网络可以将底层的简单特征逐层组合成越来越复杂的特征，深度越大，其能分类的图像的复杂度和多样性就越大。RNN 的深度网络也是同样的道理，可以将语音分解为音素，再逐渐组合成字母、单词、句子，执行复杂的语音到文本任务。</p><p>右边：深度网络的特点是需要大量的训练数据和计算资源，其中涉及大量的矩阵运算，可以在 GPU 上并行执行，还包含了大量的超参数，例如学习率、迭代次数、隐藏层数、激活函数选择、学习率调整方案、批尺寸大小、正则化方法等。</p><h1 id="5-偏差与方差"><a href="#5-偏差与方差" class="headerlink" title="5. 偏差与方差"></a>5. 偏差与方差</h1><p>那么部署你的机器学习模型需要注意些什么？下图展示了构建 ML 应用所需要的数据集分割、偏差与方差等问题。<br><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-5-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-5-1024"></p><p>如上所示，经典机器学习和深度学习模型所需要的样本数有非常大的差别，深度学习的样本数是经典 ML 的成千上万倍。因此训练集、开发集和测试集的分配也有很大的区别，当然我们假设这些不同的数据集都服从同分布。</p><p>偏差与方差问题同样是机器学习模型中常见的挑战，上图依次展示了由高偏差带来的欠拟合和由高方差带来的过拟合。一般而言，解决高偏差的问题是选择更复杂的网络或不同的神经网络架构，而解决高方差的问题可以添加正则化、减少模型冗余或使用更多的数据进行训练。</p><p>当然，机器学习模型需要注意的问题远不止这些，但在配置我们的 ML 应用中，它们是最基础和最重要的部分。其它如数据预处理、数据归一化、超参数的选择等都在后面的信息图中有所体现。</p><h1 id="6-正则化"><a href="#6-正则化" class="headerlink" title="6. 正则化"></a>6. 正则化</h1><p>正则化是解决高方差或模型过拟合的主要手段，过去数年，研究者提出和开发了多种适合机器学习算法的正则化方法，如数据增强、L2 正则化（权重衰减）、L1 正则化、Dropout、Drop Connect、随机池化和提前终止等。<br><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-6-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-6-1024"></p><p>如上图左列所示，L1 和 L2 正则化也是是机器学习中使用最广泛的正则化方法。L1 正则化向目标函数添加正则化项，以减少参数的绝对值总和；而 L2 正则化中，添加正则化项的目的在于减少参数平方的总和。根据之前的研究，L1 正则化中的很多参数向量是稀疏向量，因为很多模型导致参数趋近于 0，因此它常用于特征选择设置中。此外，参数范数惩罚 L2 正则化能让深度学习算法「感知」到具有较高方差的输入 x，因此与输出目标的协方差较小（相对增加方差）的特征权重将会收缩。</p><p>在中间列中，上图展示了 Dropout 技术，即暂时丢弃一部分神经元及其连接的方法。随机丢弃神经元可以防止过拟合，同时指数级、高效地连接不同网络架构。一般使用了 Dropout 技术的神经网络会设定一个保留率 p，然后每一个神经元在一个批量的训练中以概率 1-p 随机选择是否去掉。在最后进行推断时所有神经元都需要保留，因而有更高的准确度。</p><p>Bagging 是通过结合多个模型降低泛化误差的技术，主要的做法是分别训练几个不同的模型，然后让所有模型表决测试样例的输出。而 Dropout 可以被认为是集成了大量深层神经网络的 Bagging 方法，因此它提供了一种廉价的 Bagging 集成近似方法，能够训练和评估值数据数量的神经网络。</p><p>最后，上图还描述了数据增强与提前终止等正则化方法。数据增强通过向训练数据添加转换或扰动来人工增加训练数据集。数据增强技术如水平或垂直翻转图像、裁剪、色彩变换、扩展和旋转通常应用在视觉表象和图像分类中。而提前终止通常用于防止训练中过度表达的模型泛化性能差。如果迭代次数太少，算法容易欠拟合（方差较小，偏差较大），而迭代次数太多，算法容易过拟合（方差较大，偏差较小）。因此，提前终止通过确定迭代次数解决这个问题。</p><h1 id="7-最优化"><a href="#7-最优化" class="headerlink" title="7. 最优化"></a>7. 最优化</h1><p>最优化是机器学习模型中非常非常重要的模块，它不仅主导了整个训练过程，同时还决定了最后模型性能的好坏和收敛需要的时长。以下两张信息图都展示了最优化方法需要关注的知识点，包括最优化的预备和具体的最优化方法。<br><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-7-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-7-1024"></p><p>以上展示了最优化常常出现的问题和所需要的操作。首先在执行最优化前，我们需要归一化输入数据，而且开发集与测试集归一化的常数（均值与方差）与训练集是相同的。上图也展示了归一化的原因，因为如果特征之间的量级相差太大，那么损失函数的表面就是一张狭长的椭圆形，而梯度下降或最速下降法会因为「锯齿」现象而很难收敛，因此归一化为圆形有助于减少下降方向的震荡。</p><p>后面的梯度消失与梯度爆炸问题也是十分常见的现象。「梯度消失」指的是随着网络深度增加，参数的梯度范数指数式减小的现象。梯度很小，意味着参数的变化很缓慢，从而使得学习过程停滞。梯度爆炸指神经网络训练过程中大的误差梯度不断累积，导致模型权重出现很大的更新，在极端情况下，权重的值变得非常大以至于出现 NaN 值。</p><p>梯度检验现在可能用的比较少，因为我们在 TensorFlow 或其它框架上执行最优化算法只需要调用优化器就行。梯度检验一般是使用数值的方法计算近似的导数并传播，因此它能检验我们基于解析式算出来的梯度是否正确。</p><p>下面就是具体的最优化算法了，包括最基本的小批量随机梯度下降、带动量的随机梯度下降和 RMSProp 等适应性学习率算法。<br><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-8-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-8-1024"></p><p>小批量随机梯度下降（通常 SGD 指的就是这种）使用一个批量的数据更新参数，因此大大降低了一次迭代所需的计算量。这种方法降低了更新参数的方差，使得收敛过程更为稳定；它也能利用流行深度学习框架中高度优化的矩阵运算器，从而高效地求出每个小批数据的梯度。通常一个小批数据含有的样本数量在 50 至 256 之间，但对于不同的用途也会有所变化。</p><p>动量策略旨在加速 SGD 的学习过程，特别是在具有较高曲率的情况下。一般而言，动量算法利用先前梯度的指数衰减滑动平均值在该方向上进行修正，从而更好地利用历史梯度的信息。该算法引入了变量 v 作为参数在参数空间中持续移动的速度向量，速度一般可以设置为负梯度的指数衰减滑动平均值。</p><p>上图后面所述的 RMSProp 和 Adam 等适应性学习率算法是目前我们最常用的最优化方法。RMSProp 算法（Hinton，2012）修改 AdaGrad 以在非凸情况下表现更好，它改变梯度累积为指数加权的移动平均值，从而丢弃距离较远的历史梯度信息。RMSProp 是 Hinton 在公开课上提出的最优化算法，其实它可以视为 AdaDelta 的特例。但实践证明 RMSProp 有非常好的性能，它目前在深度学习中有非常广泛的应用。</p><p>Adam 算法同时获得了 AdaGrad 和 RMSProp 算法的优点。Adam 不仅如 RMSProp 算法那样基于一阶矩均值计算适应性参数学习率，它同时还充分利用了梯度的二阶矩均值（即有偏方差/uncentered variance）。</p><h1 id="8-超参数"><a href="#8-超参数" class="headerlink" title="8. 超参数"></a>8. 超参数</h1><p>以下是介绍超参数的信息图，它在神经网络中占据了重要的作用，因为它们可以直接提升模型的性能。<br><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-9-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-9-1024"></p><p>众所周知学习率、神经网络隐藏单元数、批量大小、层级数和正则化系数等超参数可以直接影响模型的性能，而怎么调就显得非常重要。目前最常见的还是手动调参，开发者会根据自身建模经验选择「合理」的超参数，然后再根据模型性能做一些小的调整。而自动化调参如随机过程或贝叶斯优化等仍需要非常大的计算量，且效率比较低。不过近来关于使用强化学习、遗传算法和神经网络等方法搜索超参数有很大的进步，研究者都在寻找一种高效而准确的方法。</p><p>目前的超参数搜索方法有：</p><p>依靠经验：聆听自己的直觉，设置感觉上应该对的参数然后看看它是否工作，不断尝试直到累趴。<br>网格搜索：让计算机尝试一些在一定范围内均匀分布的数值。<br>随机搜索：让计算机尝试一些随机值，看看它们是否好用。<br>贝叶斯优化：使用类似 MATLAB bayesopt 的工具自动选取最佳参数——结果发现贝叶斯优化的超参数比你自己的机器学习算法还要多，累觉不爱，回到依靠经验和网格搜索方法上去。</p><p>因为篇幅有限，后面的展示将只简要介绍信息图，相信它们对各位读者都十分有帮助。</p><h1 id="9-结构化机器学习过程"><a href="#9-结构化机器学习过程" class="headerlink" title="9. 结构化机器学习过程"></a>9. 结构化机器学习过程</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-10-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-10-1024"></p><p>我们需要按过程或结构来设定我们的机器学习系统，首先需要设定模型要达到的目标，例如它的预期性能是多少、度量方法是什么等。然后分割训练、开发和测试集，并预期可能到达的优化水平。随后再构建模型并训练，在开发集和测试集完成验证后就可以用于推断了。</p><h1 id="10-误差分析"><a href="#10-误差分析" class="headerlink" title="10. 误差分析"></a>10. 误差分析</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-11-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-11-1024"></p><p>在完成训练后，我们可以分析误差的来源而改进性能，包括发现错误的标注、不正确的损失函数等。</p><h1 id="11-训练集、开发集与测试集"><a href="#11-训练集、开发集与测试集" class="headerlink" title="11. 训练集、开发集与测试集"></a>11. 训练集、开发集与测试集</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-12-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-12-1024"></p><p>上图展示了三个分割数据集及其表现所需要注意的地方，也就是说如果它们间有不同的正确率，那么我们该如何修正这些「差别」。例如训练集的正确率明显高于验证集与测试集表明模型过拟合，三个数据集的正确率都明显低于可接受水平可能是因为欠拟合。</p><h1 id="12-其它学习方法"><a href="#12-其它学习方法" class="headerlink" title="12. 其它学习方法"></a>12. 其它学习方法</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-13-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-13-1024"></p><p>机器学习和深度学习当然不止监督学习方法，还有如迁移学习、多任务学习和端到端的学习等。</p><p>卷积网络</p><h1 id="13-卷积神经网络基础"><a href="#13-卷积神经网络基础" class="headerlink" title="13. 卷积神经网络基础"></a>13. 卷积神经网络基础</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-14-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-14-1024"></p><p>计算机视觉任务涉及的数据体量是特别大的，一张图像就有上千个数据点，更别提高分辨率图像和视频了。这时用全连接网络的话，参数数量太大，因而改用卷积神经网络（CNN），参数数量可以极大地减小。CNN 的工作原理就像用检测特定特征的过滤器扫描整张图像，进行特征提取，并逐层组合成越来越复杂的特征。这种「扫描」的工作方式使其有很好的参数共享特性，从而能检测不同位置的相同目标（平移对称）。</p><p>卷积核对应的检测特征可以从其参数分布简单地判断，例如，权重从左到右变小的卷积核可以检测到黑白竖条纹的边界，并显示为中间亮，两边暗的特征图，具体的相对亮暗结果取决于图像像素分布和卷积核的相对关系。卷积核权重可以直接硬编码，但为了让相同的架构适应不同的任务，通过训练得到卷积核权重是更好的办法。</p><p>卷积运算的主要参数：</p><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-15-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-15-1024"></p><p>padding：直接的卷积运算会使得到的特征图越来越小，padding 操作会在图像周围添加 0 像素值的边缘，使卷积后得到的特征图大小和原图像（长宽，不包括通道数）相同。</p><p>常用的两个选项是：『VALID』，不执行 padding；『SAME』，使输出特征图的长宽和原图像相同。</p><p>stride：两次卷积操作之间的步长大小。</p><p>一个卷积层上可以有多个卷积核，每个卷积核运算得到的结果是一个通道，每个通道的特征图的长宽相同，可以堆叠起来构成多通道特征图，作为下一个卷积层的输入。</p><p>深度卷积神经网络的架构：</p><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-16-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-16-1024"></p><p>深度卷积神经网络的架构主要以卷积层、池化层的多级堆叠，最后是全连接层执行分类。池化层的主要作用是减少特征图尺寸，进而减少参数数量，加速运算，使其目标检测表现更加鲁棒。</p><h1 id="14-经典卷积神经网络"><a href="#14-经典卷积神经网络" class="headerlink" title="14. 经典卷积神经网络"></a>14. 经典卷积神经网络</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-17-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-17-1024"></p><p>LeNet·5：手写识别分类网络，这是第一个卷积神经网络，由 Yann LeCun 提出。<br>AlexNet：图像分类网络，首次在 CNN 引入 ReLU 激活函数。<br>VGG-16：图像分类网络，深度较大。</p><h1 id="15-特殊卷积神经网络"><a href="#15-特殊卷积神经网络" class="headerlink" title="15. 特殊卷积神经网络"></a>15. 特殊卷积神经网络</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-18-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-18-1024"></p><p>ResNet：引入残差连接，缓解梯度消失和梯度爆炸问题，可以训练非常深的网络。<br>Network in Network：使用 1x1 卷积核，可以将卷积运算变成类似于全连接网络的形式，还可以减少特征图的通道数，从而减少参数数量。<br>Inception Network：使用了多种尺寸卷积核的并行操作，再堆叠成多个通道，可以捕捉多种规模的特征，但缺点是计算量太大，可以通过 1x1 卷积减少通道数。</p><h1 id="16-实践建议"><a href="#16-实践建议" class="headerlink" title="16. 实践建议"></a>16. 实践建议</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-19-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-19-1024"></p><p>使用开源实现：从零开始实现时非常困难的，利用别人的实现可以快速探索更复杂有趣的任务。<br>数据增强：通过对原图像进行镜像、随机裁剪、旋转、颜色变化等操作，增加训练数据量和多样性。<br>迁移学习：针对当前任务的训练数据太少时，可以将充分训练过的模型用少量数据微调获得足够好的性能。<br>基准测试和竞赛中表现良好的诀窍：使用模型集成，使用多模型输出的平均结果；在测试阶段，将图像裁剪成多个副本分别测试，并将测试结果取平均。</p><h1 id="17-目标检测算法"><a href="#17-目标检测算法" class="headerlink" title="17. 目标检测算法"></a>17. 目标检测算法</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-20-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-20-1024"></p><p>目标检测即使用边界框检测图像中物体的位置，Faster R-CNN、R-FCN 和 SSD 是三种目前最优且应用最广泛的目标检测模型，上图也展示了 YOLO 的基本过程。</p><h1 id="18-人脸识别"><a href="#18-人脸识别" class="headerlink" title="18. 人脸识别"></a>18. 人脸识别</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-21-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-21-1024"></p><p>人脸识别有两大类应用：人脸验证（二分分类）和人脸识别（多人分类）。</p><p>当样本量不足时，或者不断有新样本加入时，需要使用 one-shot learning，解决办法是学习相似性函数，即确定两张图像的相似性。比如在 Siamese Network 中学习人脸识别时，就是利用两个网络的输出，减少同一个人的两个输出的差别，增大不同人的两个输出之间的差别。</p><h1 id="19-风格迁移"><a href="#19-风格迁移" class="headerlink" title="19. 风格迁移"></a>19. 风格迁移</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-22-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-22-1024"></p><p>风格迁移是一个热门话题，它会在视觉上给人耳目一新的感觉。例如你有一副图，然后将另一幅图的风格特征应用到这幅图上，比如用一位著名画家或某一副名画的风格来修改你的图像，因此我们可以获得独特风格的作品。</p><p>循环网络</p><h1 id="20-循环神经网络基础"><a href="#20-循环神经网络基础" class="headerlink" title="20. 循环神经网络基础"></a>20. 循环神经网络基础</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-23-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-23-1024"></p><p>如上所示，命名实体识别等序列问题在现实生活中占了很大的比例，而隐马尔可夫链等传统机器学习算法只能作出很强的假设而处理部分序列问题。但近来循环神经网络在这些问题上有非常大的突破，RNN 隐藏状态的结构以循环形的形式成记忆，每一时刻的隐藏层的状态取决于它的过去状态，这种结构使得 RNN 可以保存、记住和处理长时期的过去复杂信号。</p><p>循环神经网络（RNN）能够从序列和时序数据中学习特征和长期依赖关系。RNN 具备非线性单元的堆叠，其中单元之间至少有一个连接形成有向循环。训练好的 RNN 可以建模任何动态系统；但是，训练 RNN 主要受到学习长期依赖性问题的影响。</p><p>以下展示了 RNN 的应用、问题以及变体等：</p><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-23-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-24-1024"></p><p>循环神经网络在语言建模等序列问题上有非常强大的力量，但同时它也存在很严重的梯度消失问题。因此像 LSTM 和 GRU 等基于门控的 RNN 有非常大的潜力，它们使用门控机制保留或遗忘前面时间步的信息，并形成记忆以提供给当前的计算过程。</p><h1 id="21-NLP-中的词表征"><a href="#21-NLP-中的词表征" class="headerlink" title="21. NLP 中的词表征"></a>21. NLP 中的词表征</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-25-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-25-1024"></p><p>词嵌入在自然语言处理中非常重要，因为不论执行怎样的任务，将词表征出来都是必须的。上图展示了词嵌入的方法，我们可以将词汇库映射到一个 200 或 300 维的向量，从而大大减少表征词的空间。此外，这种词表征的方法还能表示词的语义，因为词义相近的词在嵌入空间中距离相近。</p><p>除了以上所述的 Skip Grams，以下还展示了学习词嵌入的常见方法：</p><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-26-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-26-1024"></p><p>GloVe 词向量是很常见的词向量学习方法，它学到的词表征可进一步用于语句分类等任务。</p><h1 id="22-序列到序列"><a href="#22-序列到序列" class="headerlink" title="22. 序列到序列"></a>22. 序列到序列</h1><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-27-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-27-1024"></p><p>序列到序列的方法使用最多的就是编码器解码器框架，其它还有束搜索等模块的介绍。</p><p>编码器解码器架构加上注意力机制可以解决非常多的自然语言处理问题，以下介绍了 BLEU 分值和注意力机制。它们在机器翻译的架构和评估中都是不能缺少的部分。</p><p><img src="/img/notes-from-coursera-deep-learning-courses-by-andrew-ng-28-1024.jpg" alt="notes-from-coursera-deep-learning-courses-by-andrew-ng-28-1024"></p><p>以上是所有关于吴恩达深度学习专项课程的信息图，由于它们包含的信息较多，我们只介绍了一部分，还有很多内容只是简单的一笔带过。所以各位读者最好可以下载该信息图，并在后面的学习过程中慢慢理解与优化。</p><p>===<br>关注微信公众号【探物及理】回复“深度学习笔记”下载</p><p>===<br><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习笔记5：无模型控制 Model-free control</title>
      <link href="/posts/rl-5/"/>
      <url>/posts/rl-5/</url>
      
        <content type="html"><![CDATA[<p>适用于：</p><ul><li>MDP model 未知：经验的采样可以获取</li><li>MDP model 已知：无法使用（e.g.原子级动力学），采样可以使用</li></ul><p>策略、非策略学习：</p><ul><li>On-policy：动作采样来自policy $\pi$</li><li>Off-policy：采样来自采样μ 或 来自于其他策略$\pi$，</li></ul><h1 id="On-policy-MC-control"><a href="#On-policy-MC-control" class="headerlink" title="On-policy MC control"></a>On-policy MC control</h1><p>贪婪策略梯度法如果用V(s)，需要MDP已知<br>对于已知MDP，可以通过策略迭代的方法，DP到最优策略<br><img src="/img/15972213696955.jpg" alt="-w536"></p><p>要实现不基于模型的控制，需要满足两个条件：</p><ul><li>引入q(s,a)函数，而不是v(s)</li><li>探索，避免局部最优，引入$\epsilon$，使$\pi$以小概率随机选择剩余动作，避免每次都选择已知较优动作</li></ul><h2 id="model-free-policy-using-action-value-function"><a href="#model-free-policy-using-action-value-function" class="headerlink" title="model-free policy using action-value function"></a>model-free policy using action-value function</h2><p>用Q（s，a），不需要已知MDP<br><img src="/img/15972213763038.jpg" alt="-w492"></p><p>每个箭头对应一个段，Prediction一次，Control一次<br><img src="/img/15972215371325.jpg" alt="-w343"></p><h2 id="GLIE-MC-control（Greedy-in-the-Limit-with-Infinite-Exploration）"><a href="#GLIE-MC-control（Greedy-in-the-Limit-with-Infinite-Exploration）" class="headerlink" title="GLIE MC control（Greedy in the Limit with Infinite Exploration）"></a>GLIE MC control（Greedy in the Limit with Infinite Exploration）</h2><p>保证试验进行一定次数是，所有a-s状态都被访问到很多次<br><img src="/img/15964296154206.jpg" alt="-w514"></p><p>随实验次数进行，减小$\epsilon$值<br><img src="/img/15964297028232.jpg" alt="-w505"></p><h1 id="ON-policy-TD-learning"><a href="#ON-policy-TD-learning" class="headerlink" title="ON-policy TD learning"></a>ON-policy TD learning</h1><ul><li>TD与MC control 区别，希望引入TD的特性到on-policy learning<br><img src="/img/15965079350024.jpg" alt="-w509"></li></ul><h2 id="Sasra"><a href="#Sasra" class="headerlink" title="Sasra"></a>Sasra</h2><h3 id="Sasra（one-step）"><a href="#Sasra（one-step）" class="headerlink" title="Sasra（one-step）"></a>Sasra（one-step）</h3><p>由贝尔曼公式推导<br><img src="/img/15964411373536.jpg" alt="-w451"></p><h3 id="算法实现过程"><a href="#算法实现过程" class="headerlink" title="算法实现过程"></a>算法实现过程</h3><p><img src="/img/15964401337385.jpg" alt="-w535"></p><p>要保证Q值收敛，需要服从下列2个条件</p><ul><li>策略符合GLIE特性</li><li>计算步长满足如图：<br><img src="/img/15964405409905.jpg" alt="-w443"></li></ul><h3 id="n-step-Sarsa"><a href="#n-step-Sarsa" class="headerlink" title="n-step Sarsa"></a>n-step Sarsa</h3><p>与TD（λ）类似，扩展q的视野</p><p><img src="/img/15964411018416.jpg" alt="-w576"></p><h2 id="Forward-view-Sarsa-λ"><a href="#Forward-view-Sarsa-λ" class="headerlink" title="Forward view Sarsa(λ)"></a>Forward view Sarsa(λ)</h2><p><img src="/img/15964499708276.jpg" alt="-w644"></p><h2 id="Backward-view-Sarsa-λ"><a href="#Backward-view-Sarsa-λ" class="headerlink" title="Backward view Sarsa(λ)"></a>Backward view Sarsa(λ)</h2><p>在正向视角中，迭代一次Q值，需要完整的一次episode<br>为了解决这个问题，引入迹的概念，实现incremental update<br><img src="/img/15964503883163.jpg" alt="-w621"></p><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p><img src="/img/15965030748824.jpg" alt="-w529"></p><p>Attention：迹E是属于episode的，切换episode后，E要归零</p><h1 id="Off-policy-learning"><a href="#Off-policy-learning" class="headerlink" title="Off-policy learning"></a>Off-policy learning</h1><ul><li><p>需求</p><ul><li>从人类和其他agents的表现中学习</li><li>从old policies $\pi_1, \pi_2…$中学习</li><li>从随机策略中，学习到最优策略</li><li>从一个策略中，学习到多个策略</li></ul></li><li><p>采样不同分布</p><script type="math/tex; mode=display">\begin{aligned}\mathbb{E}_{X \sim P}[f(X)] &=\sum P(X) f(X) \\&=\sum Q(X) \frac{P(X)}{Q(X)} f(X) \\&=\mathbb{E}_{X \sim Q}\left[\frac{P(X)}{Q(X)} f(X)\right]\end{aligned}</script></li></ul><h2 id="off-policy-MC-learning"><a href="#off-policy-MC-learning" class="headerlink" title="off-policy MC learning"></a>off-policy MC learning</h2><p>引入了概率缩放系数，判断两个策略动作概率函数<br><img src="/img/15965086023837.jpg" alt="-w484"></p><ul><li>缺点：<ul><li>方差会增加</li><li>$\mu =0$无法计算</li></ul></li></ul><h2 id="off-policy-TD-learning"><a href="#off-policy-TD-learning" class="headerlink" title="off-policy TD learning"></a>off-policy TD learning</h2><p>利用期望分布的概念，在更新目标前x一个系数，对当前策略的置信度<br><img src="/img/15965088051921.jpg" alt="-w426"></p><ul><li>优点：<ul><li>低方差</li><li>单步策略需要相似</li></ul></li></ul><h2 id="Q-learning"><a href="#Q-learning" class="headerlink" title="Q-learning"></a>Q-learning</h2><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>采用Q(s,a) instead of V(s)</li><li>不需要重要性采样 系数</li><li>下次动作用 $A_{t+1} ∼ μ(·|S_t)$</li><li>动作服从策略 as $A′ ∼ π(·|S_t)$</li></ul><p>更新方程如下</p><script type="math/tex; mode=display">Q\left(S_{t}, A_{t}\right) \leftarrow Q\left(S_{t}, A_{t}\right)+\alpha\left(R_{t+1}+\gamma Q\left(S_{t+1}, A^{\prime}\right)-Q\left(S_{t}, A_{t}\right)\right)</script><h2 id="off-policy-control-with-Q-learning"><a href="#off-policy-control-with-Q-learning" class="headerlink" title="off-policy control with Q-learning"></a>off-policy control with Q-learning</h2><p>在学习过程中：</p><ul><li>Q值的Update Target 被优化，target policies是$\epsilon-greedy$的</li><li>Actor 执行的策略$\pi$被优化，执行$\epsilon-greedy$</li></ul><p>采用下式更新策略：</p><script type="math/tex; mode=display">\pi\left(S_{t+1}\right)=\underset{a^{\prime}}{\operatorname{argmax}} Q\left(S_{t+1}, a^{\prime}\right)</script><p>Q-learning target 简化为：</p><script type="math/tex; mode=display">\begin{aligned}& R_{t+1}+\gamma Q\left(S_{t+1}, A^{\prime}\right) \\=& R_{t+1}+\gamma Q\left(S_{t+1}, \underset{a^{\prime}}{\operatorname{argmax}} Q\left(S_{t+1}, a^{\prime}\right)\right) \\=& R_{t+1}+\max _{a^{\prime}} \gamma Q\left(S_{t+1}, a^{\prime}\right)\end{aligned}</script><p><img src="/img/15965124141748.jpg" alt="-w535"></p><p>迭代使$Q(s,a) \rightarrow q_* (s,a)$<br>Attention：在迭代过程中，动作采用$\epsilon-greedy$策略，保证对位置环境的探索</p><h3 id="算法流程-1"><a href="#算法流程-1" class="headerlink" title="算法流程"></a>算法流程</h3><p><img src="/img/15965124556612.jpg" alt="-w538"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="DP-TD的关系"><a href="#DP-TD的关系" class="headerlink" title="DP TD的关系"></a>DP TD的关系</h2><p><img src="/img/15965127185793.jpg" alt="-w619"><br><img src="/img/15965134695436.jpg" alt="-w633"></p><h2 id="Q-learning-和-SARSA区别"><a href="#Q-learning-和-SARSA区别" class="headerlink" title="Q-learning 和 SARSA区别"></a>Q-learning 和 SARSA区别</h2><p><img src="/img/15965139448881.jpg" alt="-w711"></p><p>区别在于：</p><ul><li><p>Q-learning：</p><ul><li>update： $greedy$策略，评估过程的A’没有实际执行</li><li>control：$\epsilon-greedy$策略</li></ul></li><li><p>SARSA：更新和执行都用$\epsilon-greedy$策略</p></li></ul><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>gym 搭建 RL 环境</title>
      <link href="/posts/gym-rl-env/"/>
      <url>/posts/gym-rl-env/</url>
      
        <content type="html"><![CDATA[<h2 id="gym调用"><a href="#gym调用" class="headerlink" title="gym调用"></a>gym调用</h2><p>gym的调用遵从以下的顺序</p><ol><li>env = gym.make(‘x’)</li><li>observation = env.reset()</li><li>for i in range(time_steps):<br> env.render()<br> action = policy(observation)<br> observation, reward, done, info = env.step(action)<br> if done:<pre><code> …… break</code></pre></li><li>env.close()</li></ol><h3 id="例程"><a href="#例程" class="headerlink" title="例程"></a>例程</h3><p>例程是一个简单的策略，杆左斜车左移，右斜则右移。</p><pre><code>import gymimport numpy as npenv = gym.make('CartPole-v0')t_all = []action_bef = 0for i_episode in range(5):    observation = env.reset()    for t in range(100):        env.render()        cp, cv, pa, pv = observation        if abs(pa)&lt;= 0.1:            action = 1 -action_bef        elif pa &gt;= 0:            action = 1        elif pa &lt;= 0:            action = 0        observation, reward, done, info = env.step(action)        action_bef = action        if done:            # print("Episode finished after &amp;#123;&amp;#125; timesteps".format(t+1))            t_all.append(t)            break        if t ==99:            t_all.append(0)env.close()print(t_all)print(np.mean(t_all))</code></pre><h2 id="gym的搭建"><a href="#gym的搭建" class="headerlink" title="gym的搭建"></a>gym的搭建</h2><h3 id="函数接口"><a href="#函数接口" class="headerlink" title="函数接口"></a>函数接口</h3><p>一个完整的gym环境包括以下函数：</p><ul><li>class Cartpoleenv(gym.env)<ul><li><code>def __ init __(self)</code>：类构建</li><li><code>def reset(self)</code>：初始化</li><li><code>def seed(self, seed = None)</code>：随机初始条件种子<code>return [seed]</code></li><li><code>def step(self, action)</code>: 单步仿真<code>observation, reward, done, info</code></li><li><code>def render(self, mode='human')</code>：图像引擎调用绘制窗口<code>return self.viewer.render()</code></li><li><code>def close()</code>：关闭窗口</li></ul></li></ul><h2 id="功能函数"><a href="#功能函数" class="headerlink" title="功能函数"></a>功能函数</h2><ul><li>参数限位<br><code>vel = np.clip(vel, vel_min, vel_max)</code></li><li><p>action输入校验<br><code>self.action_space.contains(action)</code></p></li><li><p>action和observation空间定义<br>Discrete: 0,1,2<br>low = np.array([min_0,min_1],dtype=np.float32)<br>high = np.array([max_0,max_1],dtype=np.float32)</p><pre><code>self.action_space = spaces.Discrete(3)self.observation_space = spaces.Box(self.low, self.high, dtype=np.float32)</code></pre></li></ul><h2 id="Mac系统添加自己写的环境到gym"><a href="#Mac系统添加自己写的环境到gym" class="headerlink" title="Mac系统添加自己写的环境到gym"></a>Mac系统添加自己写的环境到gym</h2><ol><li>打开gym.envs目录：<code>/usr/local/lib/python3.7/site-packages/gym/envs</code></li><li>将自己编写的myenv.py拷贝至一个aa目录</li><li>envs/aa下<strong>init</strong>.py添加<br><code>from gym.envs.classic_control.myenv import MyEnv</code></li><li>env下<strong>init</strong>.py添加</li></ol><pre><code>register(140311199402071213='myenv-v0',entry_point='gym.envs.classic_control:MyEnv,max_episode_steps=999, )</code></pre><ul><li>注意：注册方法内 140311199402071213号不能省<br>然后就可以调用了</li></ul><pre><code>140311199402071213 = 'myenv-v0'env = gym.make('140311199402071213')env.reset()env.step()env.sloce()</code></pre><h2 id="agent-的构建"><a href="#agent-的构建" class="headerlink" title="agent 的构建"></a>agent 的构建</h2><p>agent与环境进行交互，输入是env的输出（observation），输出是env的输入（action）</p><pre><code>class Agent():    def __ init__(self,action_space):        self.action_space = action_space    def act(self, observation, reward, done):        return action</code></pre><h3 id="agent和env交互逻辑如下："><a href="#agent和env交互逻辑如下：" class="headerlink" title="agent和env交互逻辑如下："></a>agent和env交互逻辑如下：</h3><pre><code>nb_episodes = xxnb_steps = xxreward = 0done = False        for i in range(nb_episodes):    ob = env.reset()    sum_reward = 0    for j in range(nb_steps):        action = agent.act(ob, reward, done)        ob, reward, done, _ = env.step(action)        sum_reward += reward        if done:            break</code></pre><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> RL </tag>
            
            <tag> gym </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习-Coursera笔记</title>
      <link href="/posts/deep-learning/"/>
      <url>/posts/deep-learning/</url>
      
        <content type="html"><![CDATA[<h1 id="AI-gt-机器学习分类图"><a href="#AI-gt-机器学习分类图" class="headerlink" title="AI->机器学习分类图"></a>AI-&gt;机器学习分类图</h1><p><img src="/img/15936818055208.jpg" alt="-w669"></p><h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><h2 id="几种网络结构分类"><a href="#几种网络结构分类" class="headerlink" title="几种网络结构分类"></a>几种网络结构分类</h2><p>NN——回归预测<br>CNN（convolution NN）卷积神经网络——图片<br>RNN (Recurrent Neural Network）递归神经网络——声音、语言处理<br>LSTM长短期记忆网络——</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>sigmoid<br>ReLU——rectified linear unit 修正线性单元</p><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>Cost function 每个样本的误差均值<br>Loss function 单个样本的误差<br>贝叶斯误差<br>泛化——提取特征的能力？<br>归一化，不同变量分布尺度调整一致<br>正则化，减少过拟合<br>正交化，调整变量，不影响其他变量<br>迁移学习，把model从一个task1 应用到 task2<br>玻尔兹曼机-无监督学习</p><h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><h2 id="连式法则"><a href="#连式法则" class="headerlink" title="连式法则"></a>连式法则</h2><p><img src="/img/15937407378448.jpg" alt="-w720"></p><h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p><strong>General methodology</strong><br>As usual you will follow the Deep Learning methodology to build the model:</p><ol><li>Initialize parameters / Define hyperparameters</li><li>Loop for num_iterations:<br> a. Forward propagation<br> b. Compute cost function<br> c. Backward propagation<br> d. Update parameters (using parameters, and grads from backprop) </li><li>Use trained parameters to predict labels<br>Let’s now implement those two models!</li></ol><h2 id="2、加速训练的方法"><a href="#2、加速训练的方法" class="headerlink" title="2、加速训练的方法"></a>2、加速训练的方法</h2><h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><ol><li>L2，二范数</li><li>L1，绝对值——容易造成<strong>稀疏化</strong><br><img src="/img/15938728967496.jpg" alt="-w594"></li><li>dropout随机失活 正则化<br>对于神经网络来说，用其中的一部分预测结果，等同于正则化的效果。不要让网络过分依赖某个神经元<br>一般在靠前的层较低的存活率<br>输入层和后面的层，存活率较高<br><img src="/img/15938730869088.jpg" alt="-w815"></li><li>数据扩充Data augmentation</li><li>Early stopping<br><img src="/img/15939156078394.jpg" alt="-w554"><br>发</li></ol><p>扩展到高维，同样的道理，L2 的限定区域是平滑的，与中心点等距；而 L1 的限定区域是包含凸点的，尖锐的。这些凸点更接近 Ein 的最优解位置，而在这些凸点上，很多 wj 为 0。</p><h3 id="归一化输入变量X"><a href="#归一化输入变量X" class="headerlink" title="归一化输入变量X"></a>归一化输入变量X</h3><h3 id="参数初始化——避免梯度爆炸-消失"><a href="#参数初始化——避免梯度爆炸-消失" class="headerlink" title="参数初始化——避免梯度爆炸/消失"></a>参数初始化——避免梯度爆炸/消失</h3><ul><li>随机初始化 打破 对称性</li><li>初始化值不要太小或者太大，否则</li></ul><h3 id="梯度检验-Gradient-checking，但是不能和随机失活一起使用"><a href="#梯度检验-Gradient-checking，但是不能和随机失活一起使用" class="headerlink" title="梯度检验 Gradient checking，但是不能和随机失活一起使用"></a>梯度检验 Gradient checking，但是不能和随机失活一起使用</h3><h2 id="3、寻优方法加速训练"><a href="#3、寻优方法加速训练" class="headerlink" title="3、寻优方法加速训练"></a>3、寻优方法加速训练</h2><h3 id="batch-Gradient-Descent"><a href="#batch-Gradient-Descent" class="headerlink" title="batch Gradient Descent"></a>batch Gradient Descent</h3><h3 id="mini-batch-Gradient-Descent"><a href="#mini-batch-Gradient-Descent" class="headerlink" title="mini-batch Gradient Descent"></a>mini-batch Gradient Descent</h3><h3 id="stochastic-SGD随机梯度下降法"><a href="#stochastic-SGD随机梯度下降法" class="headerlink" title="stochastic SGD随机梯度下降法"></a>stochastic SGD随机梯度下降法</h3><h3 id="Exponentially-weighted-averages-指数加权滑动平均"><a href="#Exponentially-weighted-averages-指数加权滑动平均" class="headerlink" title="Exponentially weighted averages 指数加权滑动平均"></a>Exponentially weighted averages 指数加权滑动平均</h3><p>类似于信号滤波，造成延迟</p><p><strong>bias correction</strong><br>初始值：$v_0$设置为0导致的<br>处理办法，✖️$\frac{1}{(1-\beta)^t}$</p><h3 id="动量法-GD-with-momentum"><a href="#动量法-GD-with-momentum" class="headerlink" title="动量法 GD with momentum"></a>动量法 GD with momentum</h3><p>与指数加权滑动平均类似<br>对梯度加权滤波<img src="/img/15939964494351.jpg" alt="-w621"></p><h3 id="Root-mean-square-prop均方根传递"><a href="#Root-mean-square-prop均方根传递" class="headerlink" title="Root mean square prop均方根传递"></a>Root mean square prop均方根传递</h3><p>压制导数过大的项，使各个特征值上的导数尽可能<br>$(dw)^2$是element operation<br><img src="/img/15939972113707.jpg" alt="-w534"></p><h3 id="Adam算法——Adaptive-moment-estimation自适应矩估计"><a href="#Adam算法——Adaptive-moment-estimation自适应矩估计" class="headerlink" title="Adam算法——Adaptive moment estimation自适应矩估计"></a>Adam算法——Adaptive moment estimation自适应矩估计</h3><p>将 带动量GD 和 均方根RMS-prop 算法 结合<br><img src="/img/15939976636434.jpg" alt="-w785"><br>$\alpha$<br>$\beta_1 = 0.9$<br>$\beta_2 = 0.999$<br>$\epsilon = 10^{-8}$</p><h3 id="learning-rate-decay"><a href="#learning-rate-decay" class="headerlink" title="learning rate decay"></a>learning rate decay</h3><p><img src="/img/15939980880189.jpg" alt="-w712"></p><h2 id="优化过程问题"><a href="#优化过程问题" class="headerlink" title="优化过程问题"></a>优化过程问题</h2><p><img src="/img/15939982916740.jpg" alt="-w775"></p><h2 id="4、超参数调参过程Tuning-process"><a href="#4、超参数调参过程Tuning-process" class="headerlink" title="4、超参数调参过程Tuning process"></a>4、超参数调参过程Tuning process</h2><ol><li>try random values: don’t use grid</li><li>区域定位搜索过程，粗搜索，确定密度高的地方</li><li>搜索尺度，Log分布，对指数的幂平均</li><li><strong>BN归一化</strong>Normalizing activations in a network<br>通过γ和β，任意改变Z值的分布<br>原理：减少隐藏层 变量值分布的不确定性<br><img src="/img/15940226217605.jpg" alt="-w274"></li></ol><p>Predict时，用训练集得到的参数，进行同样的缩放</p><h2 id="多class回归分类"><a href="#多class回归分类" class="headerlink" title="多class回归分类"></a>多class回归分类</h2><h3 id="softmax-regression"><a href="#softmax-regression" class="headerlink" title="softmax regression"></a>softmax regression</h3><p>将线性变量的概率，用e幂增大分辨率，归一化到0-1<br>激活函数为<br>$func(Z) = np.exp(Z) \sum^{n^{l}} e^{Z_i}$</p><h3 id="Hardmax-regression"><a href="#Hardmax-regression" class="headerlink" title="Hardmax regression"></a>Hardmax regression</h3><p>将变量归一化到[1 0 0 0]</p><h1 id="Structuring-ML-project"><a href="#Structuring-ML-project" class="headerlink" title="Structuring ML project"></a>Structuring ML project</h1><h2 id="正交化Orthogonalization"><a href="#正交化Orthogonalization" class="headerlink" title="正交化Orthogonalization"></a>正交化Orthogonalization</h2><p>针对某个问题，作出调整，不改变其他特性<br>Training -&gt; Dev -&gt; Test -&gt; Real world</p><h2 id="评价准则"><a href="#评价准则" class="headerlink" title="评价准则"></a>评价准则</h2><h3 id="单一评价指标"><a href="#单一评价指标" class="headerlink" title="单一评价指标"></a>单一评价指标</h3><p>例如分类器存在多个评价指标<br>Precision精度 &amp; Recall查准率，<br>$F sore = \frac{PR}{P+R}$<br>多分类器，一般用均值</p><h3 id="优化和满意度矩阵Satisficing-and-Optimizing-metric"><a href="#优化和满意度矩阵Satisficing-and-Optimizing-metric" class="headerlink" title="优化和满意度矩阵Satisficing and Optimizing metric"></a>优化和满意度矩阵Satisficing and Optimizing metric</h3><p>精度、运行时间</p><h3 id="ML的上限"><a href="#ML的上限" class="headerlink" title="ML的上限"></a>ML的上限</h3><p>理论值：贝叶斯最优误差<br>人类performance距离上限不远，一旦ML表现超过人类，人类很难根据偏差和方差，指导算法提高。</p><h3 id="避免-偏差-和方差"><a href="#避免-偏差-和方差" class="headerlink" title="避免 偏差 和方差"></a>避免 偏差 和方差</h3><p><img src="/img/15941050602099.jpg" alt="-w1011"></p><h2 id="误差分析"><a href="#误差分析" class="headerlink" title="误差分析"></a>误差分析</h2><p>在错误集合中找到主要影响因素，对训练集做适应性改造</p><ul><li>大小</li><li>其他种类</li><li>清晰度</li><li>滤镜</li></ul><h2 id="数据分布改变（Train、D、T）"><a href="#数据分布改变（Train、D、T）" class="headerlink" title="数据分布改变（Train、D、T）"></a>数据分布改变（Train、D、T）</h2><h3 id="错误标签solution"><a href="#错误标签solution" class="headerlink" title="错误标签solution"></a>错误标签solution</h3><p>Robust，如果error比较大，则主要成分不是少量的错误标签</p><h3 id="新标签"><a href="#新标签" class="headerlink" title="新标签"></a>新标签</h3><p>训练集保留原数据<br>dev 和 test 集 去除原标签，得到新数据的精度<br><img src="/img/15941131936082.jpg" alt="-w663"></p><h3 id="不同分布下的变差和方差"><a href="#不同分布下的变差和方差" class="headerlink" title="不同分布下的变差和方差"></a>不同分布下的变差和方差</h3><p>添加新样本后，D、T分布改变，其误差已经无法反应变差和方差<br>从训练集T中，选出一小部分，作为Train-Dev集，验证训练，计算偏差和方差<br><img src="/img/15941140515319.jpg" alt="-w819"></p><p>如果误差在D、T集下降了，说明测试集较为简单<br>横坐标：原集合、新集合<br>纵坐标：人performance、新训练model、原训练model（训练集未加入新样本）<br><img src="/img/15941143755868.jpg" alt="-w1161"></p><h3 id="解决数据分布不匹配办法"><a href="#解决数据分布不匹配办法" class="headerlink" title="解决数据分布不匹配办法"></a>解决数据分布不匹配办法</h3><ul><li>获取数据</li><li>人工生成数据（参与合成成分数量级与被合成的一致、避免过度拟合）</li></ul><h2 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h2><p>在相似的任务重，将Task1训练好的模型Model1，稍作修改生成用于Task2的Model2，让新任务的模型参考之前模型已经学习到的经验。</p><p>预训练（pre-training）for Model1<br>细微训练（fine-tunning）for Model2</p><p>根据数据量，决定需要训练的层数<br>数据量较小，只训练Model1的末层</p><h4 id="限制条件"><a href="#限制条件" class="headerlink" title="限制条件"></a>限制条件</h4><p><img src="/img/15941159051232.jpg" alt="-w629"></p><h2 id="多任务学习Multi-task-learning"><a href="#多任务学习Multi-task-learning" class="headerlink" title="多任务学习Multi-task learning"></a>多任务学习Multi-task learning</h2><p>相比于多类别分类器，y向量不一定只有一个1，存在多个1</p><h3 id="限制条件-1"><a href="#限制条件-1" class="headerlink" title="限制条件"></a>限制条件</h3><p>任务之间的相似性<br><img src="/img/15941165734379.jpg" alt="-w569"></p><p>规模不够大时，多任务学习比单项学习  损害准确率</p><h2 id="端到端学习End-to-end"><a href="#端到端学习End-to-end" class="headerlink" title="端到端学习End-to-end"></a>端到端学习End-to-end</h2><p>Start -&gt; End，复杂任务不需要中间的各个模块<br>缺陷是数据量需求巨大</p><ul><li>传统方法，分模块，串联执行，完成任务</li></ul><p><img src="/img/15941175308325.jpg" alt="-w542"></p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> DL </tag>
            
            <tag> Coursera </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>控制理论笔记-2</title>
      <link href="/posts/advance-control-2/"/>
      <url>/posts/advance-control-2/</url>
      
        <content type="html"><![CDATA[<h1 id="高级控制理论"><a href="#高级控制理论" class="headerlink" title="高级控制理论"></a>高级控制理论</h1><p><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-1.jpg" alt="Advanced控制理论-1"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-3.jpg" alt="Advanced控制理论-3"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-4.jpg" alt="Advanced控制理论-4"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-5.jpg" alt="Advanced控制理论-5"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-6.jpg" alt="Advanced控制理论-6"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-7.jpg" alt="Advanced控制理论-7"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-8.jpg" alt="Advanced控制理论-8"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-9.jpg" alt="Advanced控制理论-9"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-10.jpg" alt="Advanced控制理论-10"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-11.jpg" alt="Advanced控制理论-11"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-12.jpg" alt="Advanced控制理论-12"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-13.jpg" alt="Advanced控制理论-13"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-14.jpg" alt="Advanced控制理论-14"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-15.jpg" alt="Advanced控制理论-15"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-16.jpg" alt="Advanced控制理论-16"><br><img src="/img/Advanced%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA-17.jpg" alt="Advanced控制理论-17"></p><h2 id="Dr-can-ARC-步骤"><a href="#Dr-can-ARC-步骤" class="headerlink" title="Dr_can   ARC 步骤"></a>Dr_can   ARC 步骤</h2><p><img src="/img/DR_can_NARC%E8%87%AA%E9%80%82%E5%BA%94%E5%8F%8D%E6%AD%A5%E6%8E%A7%E5%88%B6%E6%AD%A5%E9%AA%A4.jpg" alt="DR_can_NARC自适应反步控制步骤"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高级控制理论 </tag>
            
            <tag> 经典控制理论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>卷积神经网络CNN（convolutional）</title>
      <link href="/posts/cnn/"/>
      <url>/posts/cnn/</url>
      
        <content type="html"><![CDATA[<h1 id="卷积神经网络CNN（convolutional）"><a href="#卷积神经网络CNN（convolutional）" class="headerlink" title="卷积神经网络CNN（convolutional）"></a>卷积神经网络CNN（convolutional）</h1><p>卷积运算：原图像*卷积核=新图像，经常用来做边缘检测<br>人造核：手动指定权重，改善效果<br><img src="/img/15941711725552.jpg" alt="-w615"></p><p>指定核权重为变量，通过反向传播，学习卷积核的权重<br>补白和步幅决定了卷积后的</p><h2 id="补白Padding"><a href="#补白Padding" class="headerlink" title="补白Padding"></a>补白Padding</h2><ul><li>Valid convolution：p = 0<br>$n\times n * f\times f -&gt; (n-f+1)\times (n-f+1)$</li><li>Same convolution：n = n<br>$(n+2p)\times (n+2p) * f\times f -&gt; n\times n$<br>得到填充边缘宽度$p = \frac{f-1}{2}$<br>所以一般卷积核大小是奇数<h2 id="步幅strides"><a href="#步幅strides" class="headerlink" title="步幅strides"></a>步幅strides</h2>s&gt;1，图像也变小<br><img src="/img/15941720564251.jpg" alt="-w600"></li></ul><h2 id="三维卷积"><a href="#三维卷积" class="headerlink" title="三维卷积"></a>三维卷积</h2><p>对于RGB三通道图像，nc个滤波器，卷积叠加，得到深度为nc的图像<br><img src="/img/15941727037025.jpg" alt="-w710"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="/img/15941735838131.jpg" alt="-w697"></p><h3 id="趋势：缩减图片尺度，增加深度"><a href="#趋势：缩减图片尺度，增加深度" class="headerlink" title="趋势：缩减图片尺度，增加深度"></a>趋势：缩减图片尺度，增加深度</h3><p><img src="/img/15941743777673.jpg" alt="-w693"></p><h2 id="CNN分类"><a href="#CNN分类" class="headerlink" title="CNN分类"></a>CNN分类</h2><h3 id="卷积层Conv："><a href="#卷积层Conv：" class="headerlink" title="卷积层Conv："></a>卷积层Conv：</h3><p><img src="/img/15941767758613.jpg" alt="-w695"></p><h3 id="池化层Pool：减少图片宽度，用卷积核进行特征提取"><a href="#池化层Pool：减少图片宽度，用卷积核进行特征提取" class="headerlink" title="池化层Pool：减少图片宽度，用卷积核进行特征提取"></a>池化层Pool：减少图片宽度，用卷积核进行特征提取</h3><p>欠<strong>采样</strong>（下采样），特征降维，压缩数据和参数，减小过拟合<br>只有超参数，没有参数<br>主要分类：</p><ul><li>最大池化</li><li>平均池化</li></ul><p><img src="/img/15941793237584.jpg" alt="-w730"></p><h3 id="全连接层Fc：一般用来输出"><a href="#全连接层Fc：一般用来输出" class="headerlink" title="全连接层Fc：一般用来输出"></a>全连接层Fc：一般用来输出</h3><p><img src="/img/15941799685961.jpg" alt="-w743"><br><img src="/img/15941799984582.jpg" alt="-w732"><br><img src="/img/15941803310656.jpg" alt="-w661"></p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><ul><li>优势</li></ul><ol><li>参数共享：将卷积核的参数共享给每组被卷积对象运算</li><li>稀疏性联系：输出的值只与小部分输入相关<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3>CNN从前到后，维度缩减，参数增多</li></ol><h2 id="CNN案例"><a href="#CNN案例" class="headerlink" title="CNN案例"></a>CNN案例</h2><h3 id="经典CNN"><a href="#经典CNN" class="headerlink" title="经典CNN"></a>经典CNN</h3><ul><li><p>LeNet-5（sigmoid激活，softmax分类）<br><img src="/img/15942602914708.jpg" alt="-w767"></p></li><li><p>AlexNet</p></li></ul><p><img src="/img/15942603354885.jpg" alt="-w772"></p><ul><li>VGGNet<br><img src="/img/15942604999932.jpg" alt="-w775"></li></ul><h3 id="残差网络"><a href="#残差网络" class="headerlink" title="残差网络"></a>残差网络</h3><p>传统的plain network存在梯度指数现象<br><img src="/img/15942710882961.png" alt="-w596"></p><p>为了改善深度网络的梯度爆炸（消失）现象，使深度神经网训练可能</p><ul><li>Residual block<br><img src="/img/15942613601777.jpg" alt="-w777"></li></ul><p><img src="/img/15942613429827.jpg" alt="-w770"><br>维数不一致的问题，可以通过构建权重矩阵，填充0元素或者其他方法进行适配</p><p><img src="/img/15942620573952.jpg" alt="-w723"></p><h2 id="1x1-convolution"><a href="#1x1-convolution" class="headerlink" title="1x1 convolution"></a>1x1 convolution</h2><p>对image每个像素进行非线性函数映射，通过n个kernel，映射为n个特征，用于<strong>缩减图像特征深度</strong><br><img src="/img/15942632478404.jpg" alt="-w662"></p><h3 id="用法，生成中间量，减少运算量"><a href="#用法，生成中间量，减少运算量" class="headerlink" title="用法，生成中间量，减少运算量"></a>用法，生成中间量，减少运算量</h3><p>直接5x5卷积<br><img src="/img/15942634806609.jpg" alt="-w576"><br>采用1x1卷积中间量，再用5x5卷积<br><img src="/img/15942635070290.jpg" alt="-w685"></p><h2 id="Inception-network"><a href="#Inception-network" class="headerlink" title="Inception network"></a>Inception network</h2><h3 id="Main-idea"><a href="#Main-idea" class="headerlink" title="Main idea"></a>Main idea</h3><p><img src="/img/15942632298297.jpg" alt="-w667"></p><h3 id="Inception-module"><a href="#Inception-module" class="headerlink" title="Inception module"></a>Inception module</h3><p><img src="/img/15942639201675.jpg" alt="-w678"></p><h3 id="Inception-network-1"><a href="#Inception-network-1" class="headerlink" title="Inception network"></a>Inception network</h3><ul><li>Inception module 的串联</li><li>branches用于在中间预测结果，效果不差<br><img src="/img/15942640307997.jpg" alt="-w678"></li></ul><h2 id="Transfer-learning"><a href="#Transfer-learning" class="headerlink" title="Transfer learning"></a>Transfer learning</h2><p>步骤</p><ol><li>下载源码，模型，权重参数</li><li>修改末层结构，softmax分类或者</li><li>冻结前层参数</li><li>训练自己模型</li></ol><h2 id="Data-Augmentation数据增强"><a href="#Data-Augmentation数据增强" class="headerlink" title="Data Augmentation数据增强"></a>Data Augmentation数据增强</h2><p>可以预先处理，<br>也可以与训练并行处理</p><h3 id="1、形状"><a href="#1、形状" class="headerlink" title="1、形状"></a>1、形状</h3><ul><li>镜像Mirroring</li><li>随机裁剪Random Cropping</li><li>旋转Rotation</li><li>倾斜Shearing</li><li>扭曲Local warping</li></ul><h3 id="2、色彩Color-shifting"><a href="#2、色彩Color-shifting" class="headerlink" title="2、色彩Color shifting"></a>2、色彩Color shifting</h3><ul><li>增减RGB通道值，改变量随机</li><li>PCA，干扰主要元素</li></ul><h1 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>CV（computer vision）中，目标检测是并列与图像分类的一个重要应用<br>分类 -&gt; 分类+定位 = 目标检测 -&gt; 多目标检测<br><img src="/img/15942815091519.jpg" alt="-w788"></p><ul><li>输出和cost function构造<br>输出$Y = [p_c,b_x,b_y,b_h,b_w,c_1,c_2……]$<br>包含<strong>有没有</strong>物体、<strong>坐标</strong>和<strong>物体类别</strong></li><li>cost function<br>当$p_c$=1，计算均方根误差<br>$p_c$= 0,其他的不计算</li></ul><h2 id="Landmark-Detection"><a href="#Landmark-Detection" class="headerlink" title="Landmark Detection"></a>Landmark Detection</h2><p>人脸特征标记<br>姿态特征标记<br>特征构建Y = $[是不是脸,b_x{1},b_y{1},……,b_x{n},b_{yn}]$</p><h2 id="目标检测几种思路"><a href="#目标检测几种思路" class="headerlink" title="目标检测几种思路"></a>目标检测几种思路</h2><h3 id="Sliding-windows-detection"><a href="#Sliding-windows-detection" class="headerlink" title="Sliding windows detection"></a>Sliding windows detection</h3><ol><li>滑窗获取图像</li><li>传给Classification</li><li>增大windows size 和 stride 重复1</li></ol><h4 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h4><ul><li>小步长，计算量高</li><li>大步长，计算粗略，精度差<h3 id="用卷积实现Turning-FC-layer-into-convolutional-layers"><a href="#用卷积实现Turning-FC-layer-into-convolutional-layers" class="headerlink" title="用卷积实现Turning FC layer into convolutional layers"></a>用卷积实现Turning FC layer into convolutional layers</h3>用1x1卷积实现权重线性组合<br><img src="/img/15942833041786.jpg" alt="-w670"></li></ul><p><img src="/img/15942837667651.jpg" alt="-w669"></p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>定位不精确</p><h2 id="输出更精确的边界框——YOLO"><a href="#输出更精确的边界框——YOLO" class="headerlink" title="输出更精确的边界框——YOLO"></a>输出更精确的边界框——YOLO</h2><p>YOLO算法  you only look once<br>构造输出Y.shape = (h,w,l)<br>h是高度图像分割的个数<br>w是宽度图像分割的个数<br>l方向是物体定位信息$[p_c,b_x,b_y,b_h,b_w,c_1,c_2……]$<br><img src="/img/15942851221558.jpg" alt="-w668"></p><h2 id="非极大值抑制"><a href="#非极大值抑制" class="headerlink" title="非极大值抑制"></a>非极大值抑制</h2><ol><li>低于阈值，直接丢弃</li><li>找出最大值</li><li>与最大值重叠区域IoU&gt;0.5，丢弃。多目标检测的话，运行多次IoU算法</li></ol><p><img src="/img/15942863921030.jpg" alt="-w671"></p><h2 id="Anchor-Boxes"><a href="#Anchor-Boxes" class="headerlink" title="Anchor Boxes"></a>Anchor Boxes</h2><p>重叠物体检测，重建Y<br>矮胖，瘦长<br><img src="/img/15942868946435.jpg" alt="-w673"></p><h1 id="人脸识别——单样本学习"><a href="#人脸识别——单样本学习" class="headerlink" title="人脸识别——单样本学习"></a>人脸识别——单样本学习</h1><ul><li><p>Verification验证<br>input： 图片 姓名 140311199402071213<br>output：是否对应</p></li><li><p>Recognition识别<br>n个人的数据库<br>input：图片<br>output：140311199402071213 of person（如果图片在库里）</p></li></ul><p>相似度函数$d(img1,img2)$，函数和照片没关系</p><h2 id="孪生网络Siamese-network"><a href="#孪生网络Siamese-network" class="headerlink" title="孪生网络Siamese network"></a>孪生网络Siamese network</h2><p>核心思想：NN生成编码，比较不同样本编码的范数<br>CNN的参数相同，<br><img src="/img/15942958881883.jpg" alt="-w663"></p><h3 id="三重损耗函数-Triple-loss"><a href="#三重损耗函数-Triple-loss" class="headerlink" title="三重损耗函数 Triple loss"></a>三重损耗函数 Triple loss</h3><p>防止NN输出退化解，布置小于0<br>$\alpha$ is margin<br><img src="/img/15942962863559.jpg" alt="-w662"></p><h3 id="another相似性函数"><a href="#another相似性函数" class="headerlink" title="another相似性函数"></a>another相似性函数</h3><p><img src="/img/15943010618021.jpg" alt="-w413"></p><p><img src="/img/15943009025922.jpg" alt="-w672"></p><h1 id="风格转换Styler-transfer"><a href="#风格转换Styler-transfer" class="headerlink" title="风格转换Styler transfer"></a>风格转换Styler transfer</h1><p><img src="/img/15943016778419.jpg" alt="-w670"></p><h2 id="可视化hidden-unit"><a href="#可视化hidden-unit" class="headerlink" title="可视化hidden unit"></a>可视化hidden unit</h2><p>浅层学习基本特征<br>深层学习宏观特征<br><img src="/img/15943015979608.jpg" alt="-w667"></p><h2 id="cost-function"><a href="#cost-function" class="headerlink" title="cost function"></a>cost function</h2><p>Main idea: 和两张图片都很像<br>$J(G) = \alpha J_{content}(C,G) + \beta J_{style}(S,G)$</p><p><img src="/img/15943018797577.jpg" alt="-w682"></p><h3 id="content-cost-function"><a href="#content-cost-function" class="headerlink" title="content cost function"></a>content cost function</h3><p><img src="/img/15943020713953.jpg" alt="-w698"></p><h3 id="Style-cost-function"><a href="#Style-cost-function" class="headerlink" title="Style cost function"></a>Style cost function</h3><p><img src="/img/15943023722812.jpg" alt="-w603"><br>$\lambda$ 是 l 层的权重<br><img src="/img/15943032075944.jpg" alt="-w468"></p><h2 id="卷积1D和3D形式"><a href="#卷积1D和3D形式" class="headerlink" title="卷积1D和3D形式"></a>卷积1D和3D形式</h2><h3 id="1D形式"><a href="#1D形式" class="headerlink" title="1D形式"></a>1D形式</h3><p><img src="/img/15943038817548.jpg" alt="-w707"></p><h3 id="3D形式"><a href="#3D形式" class="headerlink" title="3D形式"></a>3D形式</h3><p><img src="/img/15943041391653.jpg" alt="-w695"></p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> CNN </tag>
            
            <tag> 卷积神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习笔记4：无模型预测 model-free prediction</title>
      <link href="/posts/rl-4/"/>
      <url>/posts/rl-4/</url>
      
        <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>这一章，解决的是用prediction的方法，来评估策略$\pi$的问题。</p><p>对于Env来说，不是参数已知的MDP<br>比如元组中a、s、P的关系不确定 or 未知</p><p>Prediction -&gt; Control<br>Evaluation -&gt; Optimization</p><h1 id="蒙特卡洛法-Monte-Carlo-learning"><a href="#蒙特卡洛法-Monte-Carlo-learning" class="headerlink" title="蒙特卡洛法 Monte-Carlo learning"></a>蒙特卡洛法 Monte-Carlo learning</h1><ul><li>定义：在不清楚MDP状态转移及即时奖励的情况下，直接从经历完整的Episode来学习状态价值，通常情况下某状态的价值等于在多个Episode中以该状态算得到的所有收获的平均。</li></ul><p>适用于MDP参数<strong>未知</strong>，回合制更新，遍历了所有状态s</p><p>MC是基于大数定律的：<br>当采样足够多时，就可以代表真值</p><script type="math/tex; mode=display">N(s)->\infty \Rightarrow V(s) -> V_\pi(s)</script><ul><li>说明：<ul><li>均值累计计算可以用$v = sum/N$</li><li>也可以用累进更新 Incremental Mean<script type="math/tex; mode=display">\begin{aligned}\mu_{k} &=\frac{1}{k} \sum_{j=1}^{k} x_{j} \\&=\frac{1}{k}\left(x_{k}+\sum_{j=1}^{k-1} x_{j}\right) \\&=\frac{1}{k}\left(x_{k}+(k-1) \mu_{k-1}\right) \\&=\mu_{k-1}+\frac{1}{k}\left(x_{k}-\mu_{k-1}\right)\end{aligned}</script></li></ul></li></ul><p>类似于PID的P 增益随着N增大，在逐步缩小<br>为了简化计算，改写方程，用$\alpha$代替$\frac{1}{N(s_t)}$<br>这样可以用固定步长来替代变步长$\frac{1}{k}$</p><script type="math/tex; mode=display">V(S_t) \leftarrow V(S_t)+\alpha(G_t - V(S_t))</script><p>可以看做是，$v_{new} = v_{old} + \alpha(v_{target} - v_{old})$，括号里面是误差<br>可以看到这里的$\alpha$和机器学习里面用的学习率是一个符号</p><h1 id="差分法Temporal-Difference-learning"><a href="#差分法Temporal-Difference-learning" class="headerlink" title="差分法Temporal-Difference learning"></a>差分法Temporal-Difference learning</h1><p>MC 在 episode遍历完之后，回合更新，效率低<br>TD 实现边走边更新</p><p>引入时间t的概念</p><ul><li>直接从episodes 的经验学习</li><li>model-free：<strong>不知道</strong>MDP的Transition转移和Reward回报</li><li>Bootstrapping自举学习，从部分例子学习</li></ul><p>Goal：学习$v_{\pi}$ 的值，under policy $\pi$</p><h2 id="时序分析法-TD-0）："><a href="#时序分析法-TD-0）：" class="headerlink" title="时序分析法 TD(0）："></a>时序分析法 TD(0）：</h2><script type="math/tex; mode=display">V\left(S_{t}\right) \leftarrow V\left(S_{t}\right)+\alpha\left(R_{t+1}+\gamma V\left(S_{t+1}\right)-V\left(S_{t}\right)\right)</script><ul><li>TD target 是 下一个时刻的$R_{t+1}+\gamma V\left(S_{t+1}\right)$</li><li>TD误差：$\left(R_{t+1}+\gamma V\left(S_{t+1}\right)-V\left(S_{t}\right)\right)$</li></ul><p>Bootstrapping：根据episode表现来更新V值，自举（依靠自己努力获得）</p><h2 id="与MC方法区别"><a href="#与MC方法区别" class="headerlink" title="与MC方法区别"></a>与MC方法区别</h2><div class="table-container"><table><thead><tr><th>项目</th><th>MC</th><th>TD</th></tr></thead><tbody><tr><td>不完整片段学习能力</td><td>无</td><td>有</td></tr><tr><td>在线学习(every step)能力</td><td>update until the end</td><td>有</td></tr><tr><td>loop环境学习能力</td><td>无，必须terminating</td><td>有</td></tr><tr><td>收敛性好</td><td>是</td><td></td></tr><tr><td>初值敏感</td><td>否</td><td>是</td></tr><tr><td>偏差bias</td><td>zero</td><td>some</td></tr><tr><td>方差variance</td><td>high</td><td>low</td></tr></tbody></table></div><h2 id="估计方法背后的理论"><a href="#估计方法背后的理论" class="headerlink" title="估计方法背后的理论"></a>估计方法背后的理论</h2><ul><li>MC方法：最小化均方根MSE<script type="math/tex; mode=display">\sum_{k=1}^{K} \sum_{t=1}^{T_{k}}\left(G_{t}^{k}-V\left(s_{t}^{k}\right)\right)^{2}</script></li><li>TD（0）方法：<strong>最大似然估计</strong> max likelihood Markov model<br>Solution to the MDP $\langle\mathcal{S}, \mathcal{A}, \hat{\mathcal{P}}, \hat{\mathcal{R}}, \gamma\rangle$ that best fits the data<script type="math/tex; mode=display">\hat{\mathcal{P}}_{s, s^{\prime}}^{a} =\frac{1}{N(s, a)} \sum_{k=1}^{K} \sum_{t=1}^{T_{k}} 1\left(s_{t}^{k}, a_{t}^{k}, s_{t+1}^{k}=s, a, s^{\prime}\right)</script><script type="math/tex; mode=display">\hat{\mathcal{R}}_{s}^{a} =\frac{1}{N(s, a)} \sum_{k=1}^{K} \sum_{t=1}^{T_{k}} 1\left(s_{t}^{k}, a_{t}^{k}=s, a\right) r_{t}^{k}</script></li></ul><p><img src="/img/15972187186144.jpg" alt="MC-TD收敛速度对比"></p><h2 id="总结：DP、MC、TD"><a href="#总结：DP、MC、TD" class="headerlink" title="总结：DP、MC、TD"></a>总结：DP、MC、TD</h2><ul><li>Bootstrapping自举：利用自己估计值update</li><li>Sampling采样 ：更新样本期望</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">项目</th><th style="text-align:center">动态规划DP</th><th style="text-align:center">蒙特卡洛MC</th><th style="text-align:center">差分TD</th></tr></thead><tbody><tr><td style="text-align:center">自举Bootstrapping</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">采样Sampling</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">1</td></tr></tbody></table></div><ul><li>TD用了Markov特性，因此在MP过程高效</li><li>MC相反，统计规律，非MP过程同样有效</li></ul><p>MC: 采样，一次完整经历，用实际收获更新状态预估价值</p><p><img src="/img/15972190302462.png" alt="MC-深度"></p><p>TD：采样，经历可不完整，用喜爱状态的预估状态价值预估收获再更新预估价值<br><img src="/img/15972190329229.png" alt="TD-窄而浅"></p><p>DP：没有采样，根据完整模型，依靠预估数据更新状态价值<br><img src="/img/15972190846702.png" alt="DP-宽度"></p><p><img src="/img/15961728958158.jpg" alt="全尺度搜索、动态规划、MC、TD 对比"></p><h1 id="TD-λ-法"><a href="#TD-λ-法" class="headerlink" title="TD(λ)法"></a>TD(λ)法</h1><p>视野（深度）影响TD算法的稳定性，但是视野去多深，不知道<br>因此，综合不同深度的视野，加权求和，即TD$(\lambda)$</p><p>扩展TD(0)，视野扩展到N个step，N=全过程时，变为MC<br><img src="/img/15961732715990.jpg" alt=""></p><p>TD（N）推导<br><img src="/img/15961732821137.jpg" alt="TD（N）"><br><img src="/img/15972192509726.jpg" alt="不同深度TD效果对比"></p><p>对于某个问题来说，没有那个N值是最优的<br>因此，用几何加权的方法来对视野做平均</p><h2 id="Forward-前向视角认知-TD-lambda"><a href="#Forward-前向视角认知-TD-lambda" class="headerlink" title="Forward 前向视角认知 $TD(\lambda)$"></a>Forward 前向视角认知 $TD(\lambda)$</h2><ul><li><p>例子：<br>老鼠在连续接受了3次响铃和1次亮灯信号后遭到了电击，那么在分析遭电击的原因时，到底是响铃的因素较重要还是亮灯的因素更重要呢？<br><img src="/img/15972196164084.png" alt=""></p></li><li><p>两个启发：</p><ul><li>出现频率高的状态</li><li>出现频率低的状态</li></ul></li></ul><p><img src="/img/15962140900575.jpg" alt="-w561"></p><p>$\lambda$：对视野的平均<br>for iteration： t -&gt; t+1<br>update value function</p><p><img src="/img/15961782979683.jpg" alt="-w621"></p><p>引入权重概念，前面的重要，指数衰减<br><img src="/img/15961783140794.jpg" alt="-w533"></p><h2 id="Backward-反向认知TD-λ-：提供了单步更新的机制"><a href="#Backward-反向认知TD-λ-：提供了单步更新的机制" class="headerlink" title="Backward 反向认知TD(λ)：提供了单步更新的机制"></a>Backward 反向认知TD(λ)：提供了<strong>单步</strong>更新的机制</h2><p>Credit assignment：<br>引入 Eligibility Traces：状态s的权重，是一个时间序列<br>当s重复出现，E值升高，不出现，指数下降<br>$E_{0}(s)=0$<br>$E_{t}(s)=\gamma \lambda E_{t-1}(s)+\mathbf{1}\left(S_{t}=s\right)$</p><p>Backward步骤：</p><ul><li>对每个状态s 创建 迹值</li><li>对每个状态s 更新 V(s)</li><li>与 TD-error($\delta_t$) 和 Eligibility trace $E_t(s)$ 成比例</li></ul><script type="math/tex; mode=display">\begin{aligned}\delta_{t} &=R_{t+1}+\gamma V\left(S_{t+1}\right)-V\left(S_{t}\right)\\V(s) & \leftarrow V(s)+\alpha \delta_{t} E_{t}(s)\end{aligned}</script><p><img src="/img/15962140598528.jpg" alt="-w426"></p><script type="math/tex; mode=display">\sum_{t=1}^{T} \alpha \delta_{t} E_{t}(s)=\sum_{t=1}^{T} \alpha\left(G_{t}^{\lambda}-V\left(S_{t}\right)\right) 1\left(S_{t}=s\right)</script><p><img src="/img/15964228971321.jpg" alt="-w605"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="/img/15964233494644.jpg" alt="-w627"></p><ul><li>Offline update：TD(0) = TD($\lambda$) = TD(1)</li><li>Online update： TD($\lambda$)前后向视图不一致，引入Exact online TD($\lambda$)可以解决这个问题</li><li>TD(0) 向后看一步</li><li>TD($\lambda$) 视野距离按$\lambda$指数衰减，叠加</li><li>TD(1) 视野不按指数衰减</li><li>能在RL中被应用，看中了TD的自举特性</li></ul><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习笔记3：动态规划 planning by dynamic programming（DP）</title>
      <link href="/posts/rl-3/"/>
      <url>/posts/rl-3/</url>
      
        <content type="html"><![CDATA[<p>规划，适用于MDP模型参数<strong>已知</strong><br>学习，适用于Env未知或部分未知</p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>动态规划分为两步，Prediction、Control</p><ul><li>（Prediction）Value:是对策略$\pi$的评价<script type="math/tex; mode=display"><s,P^\pi,R^\pi,\gamma>, \pi \rightarrow V_\pi</script></li><li>（Control）Policy $\pi$:是对Value的选择<script type="math/tex; mode=display"><s,P^\pi,R^\pi,\gamma>, V \rightarrow \pi</script></li></ul><h2 id="方法："><a href="#方法：" class="headerlink" title="方法："></a>方法：</h2><ul><li>prediction：迭代法<br>对所有状态s，应用贝尔曼公式<script type="math/tex; mode=display">v_{k+1}(s)=\sum_{a \in A} \pi(a \mid s)\left(R_{s}^{a}+\gamma \sum_{s^{\prime} \in S} P_{s s^{\prime}}^{a} v_{k}\left(s^{\prime}\right)\right)</script></li></ul><p>右边的$v_k$不确定，但是迭代下去，因为$R^a_s$确定，所以收敛到真值$v_\pi$</p><ul><li>Control：greedly，每次都选基于上次预测最好的那个a</li></ul><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>问题：每走一步，r = -1，走到出口可以停止<br>在随机策略下，迭代k，最使v收敛<br>得到$v^{\pi}(s)$<br><img src="/img/15959276754125.jpg" alt="-w395"><br>然后最简单的策略，greedy，往v值高的地方走。<br><img src="/img/15959300701562.jpg" alt="-w562"></p><h1 id="Policy-iteration：-O-mn-2"><a href="#Policy-iteration：-O-mn-2" class="headerlink" title="Policy iteration：$O(mn^2)$"></a>Policy iteration：$O(mn^2)$</h1><p>每一步，遍历动作A</p><p>Find optim policy：<br>以Greedy为例，迭代：$\pi’ = greedy(v_{\pi})$<br>策略更新为：</p><script type="math/tex; mode=display">\pi^{\prime}(s)=\underset{a \in \mathcal{A}}{\operatorname{argmax}} q_{\pi}(s, a)</script><p>值函数更新为：</p><script type="math/tex; mode=display">v_{\pi}(s)=\max _{a \in \mathcal{A}} q_{\pi}(s, a)</script><p><strong>主动</strong>改变策略，策略改变之后进行评估<br>根据q值，从集合A中选a，更新策略$\pi$，使新q大于之前一步</p><script type="math/tex; mode=display">q_{\pi}\left(s, \pi^{\prime}(s)\right)=\max _{a \in \mathcal{A}} q_{\pi}(s, a) \geq q_{\pi}(s, \pi(s))=v_{\pi}(s)</script><p>证明：</p><script type="math/tex; mode=display">\begin{aligned}v_{\pi}(s) & \leq q_{\pi}\left(s, \pi^{\prime}(s)\right)=\mathbb{E}_{\pi^{\prime}}\left[R_{t+1}+\gamma v_{\pi}\left(S_{t+1}\right) \mid S_{t}=s\right] \\& \leq \mathbb{E}_{\pi^{\prime}}\left[R_{t+1}+\gamma q_{\pi}\left(S_{t+1}, \pi^{\prime}\left(S_{t+1}\right)\right) \mid S_{t}=s\right] \\& \leq \mathbb{E}_{\pi^{\prime}}\left[R_{t+1}+\gamma R_{t+2}+\gamma^{2} q_{\pi}\left(S_{t+2}, \pi^{\prime}\left(S_{t+2}\right)\right) \mid S_{t}=s\right] \\& \leq \mathbb{E}_{\pi^{\prime}}\left[R_{t+1}+\gamma R_{t+2}+\ldots \mid S_{t}=s\right]=v_{\pi^{\prime}}(s)\end{aligned}</script><p>所以保证了每次迭代，价值函数 与 策略 增长</p><h1 id="Value-iteration：-O-m-2n-2"><a href="#Value-iteration：-O-m-2n-2" class="headerlink" title="Value iteration：$O(m^2n^2)$"></a>Value iteration：$O(m^2n^2)$</h1><p>每一步，遍历了状态S和动作A</p><p>最优策略：</p><ul><li>当前状态s下，所有动作a产生回报的最大值</li><li>采取动作a后，状态由s -&gt; s’的期望<br>公式：<script type="math/tex; mode=display">v_{*}(s)=\max _{a} \mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} v_{*}\left(s^{\prime}\right)</script></li></ul><p>根据值函数，选择策略</p><h1 id="值迭代和policy迭代的区别"><a href="#值迭代和policy迭代的区别" class="headerlink" title="值迭代和policy迭代的区别"></a>值迭代和policy迭代的区别</h1><ul><li>policy iteration每次迭代v(s)都会变大；而value iteration则不是。</li><li>价值迭代不需要策略参与，依据MDP 模型，直接迭代，需要P矩阵、r 等<strong>已知</strong><ul><li>policy iteration： policy-&gt;value-&gt;policy</li><li>value iteration：value-&gt;value</li></ul></li></ul><h1 id="Trick"><a href="#Trick" class="headerlink" title="Trick:"></a>Trick:</h1><p>三种值迭代方法:<br>常规的值迭代，要遍历过所有s之后，才进行一次迭代，因此存在old、new两个v(s)</p><ul><li>in-place DP：新值直接替换旧值，只存储一个v(s)，<ul><li>异步更新，提高效率</li><li>缺点：更新顺序影响收敛性</li></ul></li><li>Prioritised sweeping：state的影响力排序<ul><li>比较贝尔曼误差绝对值，大的更新，小的忽略</li></ul></li><li>Real-time DP：遍历过的才更新<ul><li>省去了agent 未遍历的状态s，对于稀疏任务效率提升极大</li></ul></li></ul><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MBSE 基于模型的系统工程</title>
      <link href="/posts/mbse/"/>
      <url>/posts/mbse/</url>
      
        <content type="html"><![CDATA[<h1 id="MBSE"><a href="#MBSE" class="headerlink" title="MBSE"></a>MBSE</h1><p>根据国际系统工程协会（INCOSE）在 2007 年发布的《SE 愿景 2020》中的定义，MBSE 是建模方法在系统工程中的形式化应用，用以支持在系统全生命周期内开展需求、设计、分析、验证和确认相关的活动。从定义可以看到，MBSE 是基于文档的传统系统工程工作模式的演进，力求以多视角的系统模型做为桥梁，将跨学科/领域的模型关联起来，实现跨学科/领域的模型追溯，从而驱动大型复杂系统生存周期内各阶段的工程活动，最终实现以模型驱动的方法来采集、捕获和提炼数据、信息和知识。<br>《INCOSE 系统工程手册》、《NASA 系统工程手册》、《FAA 系统工程手册》以及《中国商用飞机有限责任公司系统工程手册》中对系统工程实践有完善的描述，如果需要深入了解系统工程相关概念和具体实践，请参阅这些手册。<br>MBSE 是采用模型驱动的方式对系统工程的实践，本文就从系统工程要做的几个典型任务入手，介绍 MBSE 都做什么，帮助大家理解MBSE的内涵，并进一步开展 MBSE 的实践。</p><h2 id="系统工程的主要活动包括："><a href="#系统工程的主要活动包括：" class="headerlink" title="系统工程的主要活动包括："></a>系统工程的主要活动包括：</h2><ul><li><p>任务/目标定义</p></li><li><p>需求工程</p></li><li><p>系统架构</p></li><li><p>系统集成</p></li><li><p>验证与确认</p></li><li><p>技术分析</p></li><li><p>范围管理</p></li></ul><p>技术领导力和技术管理</p><p>下面就来看看每一项活动的具体内容。为了清晰展示各项活动的关联关系，下图展示了各项活动在我们熟知 V 流程中的位置。</p><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15942030645422.jpg?x-oss-process=style/blog" alt=""></p><p>◆  ◆  ◆  ◆</p><h2 id="任务-目标定义"><a href="#任务-目标定义" class="headerlink" title="任务/目标定义"></a>任务/目标定义</h2><p>创造新系统或对现有系统进行修改，都是从任务/目标定义开始，也就是捕获涉众需求。任务或目标定义并不聚焦在特定的待开发系统上，而是在一个更大的背景中识别潜在的需求，这种需求将成为开发某个系统的理由。这种需求通常用系统使用者的语言进行描述，而不是技术语言，很多时候也会包括一定程度的定量描述。一般通过 CONOPS（Concept of Operations）文件来描述待开发系统的任务和目标。</p><h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p>系统工程中的架构设计主要是指定义其组成和各部分的关系，通常以示意图（Diagrams）的形式体现.包括在一定环境下的系统高层概念描述、系统的组成部分、系统各部分的交互、系统与环境的交互等。同时，系统架构设计也要描述系统产生的过程和对各备选方案的评估过程，并基于系统需求来定义低层需求，从而将需求分配到各组成部分。<br>工程实践过程中，我们常常会将待设计的系统或产品按照物理形式进行分解，称为产品分解结构 PBS（Product Breakdown Structure），同时也会根据任务/目标定义的内容以及需求工程中获取的功能要求进行逻辑分解，形成功能分解结构 FBS（Function Breakdown Structure），简单直观的可将 PBS 与 FBS 之间的映射关系称为系统架构。</p><h2 id="需求工程"><a href="#需求工程" class="headerlink" title="需求工程"></a>需求工程</h2><p>即需求生成和管理，通过正式的技术语言对系统的功能、属性以及质量因素等进行阐述，通常叫做“需求管理”或“需求工程”，包括对需求的定义、分析、确认和管理。需求工程的输入是任务/目标定义的输出，通过分析、综合、验证的迭代过程将涉众需求通过技术语言进行形式化表示，形成高层需求和底层需求，是需求工程的主要任务。</p><h2 id="系统集成"><a href="#系统集成" class="headerlink" title="系统集成"></a>系统集成</h2><p>系统集成包含设计、购买和创造各类系统组件，对系统组件进行测试，而系统组件包括硬件、软件或过程。这些组件由于庞大和复杂，而通常也被当作系统看待。系统集成主要完成构建符合预期系统框架要求的系统组件，这部分任务通常由一系列的组装和测试操作组成。</p><h2 id="确认与验证"><a href="#确认与验证" class="headerlink" title="确认与验证"></a>确认与验证</h2><p>确认，是对开发完成的系统（或像需求和架构这样的开发成果）与系统的预期任务或目标进行比对，即要确定“做正确的事”，提供需求一致性和完整性的证明；验证，是通过检查，分析，展示，测试或其他的客观证据，来对系统（开发成果）和需求进行比对，以此来展示“正确的做事”。确认和验证是整个系统生命周期过程中需要持续进行的系统工程活动，分析、测试、评审是进行验证的常用方法，追溯、分析、建模、测试、相似性度量（或经验）和评审是进行确认的常用方法。</p><h2 id="技术分析"><a href="#技术分析" class="headerlink" title="技术分析"></a>技术分析</h2><p>这里的技术分析是指系统级技术分析，尤其是对系统性能满足需求的满足度进行评估；包括性能分析，时序分析，容量分析，质量分析，趋势，敏感度，失效模式和影响性分析等，主要涉及技术性能度量，以及其他类似的对系统配置和组件的多学科评价；除非是与需求工程或系统架构设计不可分割，可能还需要进行功能分析，预测分析，权衡分析等。<br>这些技术分析一般都是基于不同的系统层级，使用不同的定量建模技术构建不同逼真度的分析模型进行计算和仿真而开展的，是为技术理解和决策提供严格的数据和信息基础的必要手段。</p><h2 id="范围管理"><a href="#范围管理" class="headerlink" title="范围管理"></a>范围管理</h2><p>采购和供应链问题的技术定义和管理，主要关注与上下游的合同关系：向上是开发合同，对整个系统开发的范围进行定义，主要涉及系统需求，向下是对委托出去开发的系统组件的范围进行定义。</p><h2 id="技术领导力和技术管理"><a href="#技术领导力和技术管理" class="headerlink" title="技术领导力和技术管理"></a>技术领导力和技术管理</h2><p>技术领导力和技术管理活动主要包括项目策划，技术过程评估，技术控制，团队建设，交叉协同，提供通用语言和目标，风险管理和接口管理等；与项目管理不同的是，技术领导力和技术管理主要关注技术目标和技术指导。</p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 系统 </tag>
            
            <tag> MBSE </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习笔记2：Markov decision process(MDP)</title>
      <link href="/posts/rl-2/"/>
      <url>/posts/rl-2/</url>
      
        <content type="html"><![CDATA[<h1 id="马尔科夫过程（Markov-Process，MP）"><a href="#马尔科夫过程（Markov-Process，MP）" class="headerlink" title="马尔科夫过程（Markov Process，MP）"></a>马尔科夫过程（Markov Process，MP）</h1><p>我们说一个state若满足 ，则其具有马尔可夫性，即该state完全包含了历史中的所有信息。马尔科夫过程是无记忆的随机过程，即随机状态序列 具有马尔可夫属性。</p><p>一个马尔科夫过程可以由一个元组组成$\langle\mathcal{S}, \mathcal{P}\rangle$</p><p>$\mathcal{S}$为（有限）的状态（state）集；<br>$\mathcal{P}$为状态转移矩阵， $$<br>P_{s s^{\prime}}=\mathbb{P}\left(S_{t+1}=s^{\prime} \mid S_{t}=s\right)</p><script type="math/tex; mode=display">。所谓状态转移矩阵就是描述了一个状态到另一个状态发生的概率，所以**_矩阵每一行元素之和为1_**。## 马尔科夫奖励过程（Markov Reward Process，MRP）在MP上加入了 奖励Reward 和 折扣系数$\gamma$![-w460](/img/15961148196502.jpg)对于状态转移概率矩阵确定的情况，Value值可以显式计算得到![-w238](/img/15961148266893.jpg)对于MDP，并不适用，因为$\mathbb{P}$**非线性**### 解析解对于理想的的MDP，且参数已知，其解析解可以直接逆运算得到状态在策略下的value值，可以由一下的公式计算得到</script><p>\begin{array}{c}<br>v_{\pi}=\mathcal{R}^{\pi}+\gamma \mathcal{P}^{\pi} v_{\pi} \\<br>v_{\pi}=\left(I-\gamma \mathcal{P}^{\pi}\right)^{-1} \mathcal{R}^{\pi}<br>\end{array}</p><script type="math/tex; mode=display">## 马尔科夫决策过程（Markov Decision Process，MDP）MDP相对于MP加入了瞬时奖励 $R$(Immediate reward）、动作集合$A$和折扣因子 $\gamma$ （Discount factor），这里的瞬时奖励说的是从一个状态 s到下一个状态 s' 即可获得的rewards，虽然是“奖励”，但如果这个状态的变化对实现目标不利，就是一个负值，变成了“惩罚”，所以reward就是我们告诉agent什么是我们想要得到的，但不是我们如何去得到。MDP由元组 $\langle\mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R}, \gamma\rangle$ 定义。其中$\mathcal{S}$为（有限）的状态（state）集；$\mathcal{A}$为有限的动作集；$\mathcal{P}$为状态转移矩阵。所谓状态转移矩阵就是描述了一个状态到另一个状态发生的概率，所以矩阵每一行元素之和为1。[公式]$\mathcal{R}$为回报函数（reward function), [公式]$\gamma$为折扣因子，范围在[0,1]之间， 越大，说明agent看得越“远”。对于每一个$\pi$,$a\in A$</script><p>\begin{aligned}<br>\mathcal{P}_{s, s^{\prime}}^{\pi} &amp;=\sum_{a \in \mathcal{A}} \pi(a \mid s) \mathcal{P}_{s s^{\prime}}^{a} \\<br>\mathcal{R}_{s}^{\pi} &amp;=\sum_{a \in \mathcal{A}} \pi(a \mid s) \mathcal{R}_{s}^{a}<br>\end{aligned}</p><script type="math/tex; mode=display">### 收获 Return定义：收获$G_t$为在一个马尔科夫奖励链上从t时刻开始往后所有的奖励的有衰减的总和。也有翻译成“收益”或"回报"。G值，从t时刻起，包括了**未来**，计算了**折扣**的总奖励：</script><p>G_t = R_{t+1}+\gamma R_{t+2} + … = \sum^\infty_{k=0}\gamma^k R_{t+k+1}</p><script type="math/tex; mode=display">- 考虑了未来的不确定性- 给与较近的未来更高权重### 价值函数和动作值函数![-w397](/img/15959184331156.jpg)- 价值函数：在状态s，策略π下的值函数</script><p>v_{\pi}(s)=\mathbb{E}_{\pi}\left[G_{t} \mid S_{t}=s\right]</p><script type="math/tex; mode=display">- 动作值函数（action-value function）：在状态s，执行动作a，遵循策略π，回报期望</script><p>q_{\pi}(s, a)=\mathbb{E}_{\pi}\left[G_{t} \mid S_{t}=t, A_{t}=a\right]</p><script type="math/tex; mode=display"># 贝尔曼方程状态值函数可以分解为即刻回报+未来回报x折扣值分解 -> 迭代实现</script><p>v_{\pi}(s)=\mathbb{E}_{\pi}\left[R_{t+1}+\gamma v_{\pi}\left(S_{t+1}\right) \mid S_{t}=s\right]</p><script type="math/tex; mode=display">动作值函数类似：</script><p>q_{\pi}(s, a)=\mathbb{E}_{\pi}\left[R_{t+1}+\gamma q_{\pi}\left(S_{t+1}, A_{t+1}\right) \mid S_{t}=s, A_{t}=a\right]</p><script type="math/tex; mode=display">在每个状态，会存在多个备选动作；每个动作，也可能会导致不一样的状态，因此存在下图。![](/img/15958154132177.jpg)</script><p>v_{\pi}(s)=\sum_{a \in \mathcal{A}} \pi(a \mid s) q_{\pi}(s, a) \\ q_{\pi}(s, a)=\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} v_{\pi}\left(s^{\prime}\right) \\ </p><script type="math/tex; mode=display">于是$$v_{\pi}(s)=\sum_{a \in \mathcal{A}} \pi(a \mid s)\left(\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} v_{\pi}\left(s^{\prime}\right)\right) \\ q_{\pi}(s, a)=\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} \sum_{a^{\prime} \in \mathcal{A}} \pi\left(a^{\prime} \mid s^{\prime}\right) q_{\pi}\left(s^{\prime}, a^{\prime}\right)</script><p>描述了当前状态值函数和其后续状态值函数之间的关系，即状态值函数（动作值函数）等于瞬时回报的期望加上下一状态的（折扣）状态值函数（动作值函数）的期望。</p><h2 id="贝尔曼最优方程"><a href="#贝尔曼最优方程" class="headerlink" title="贝尔曼最优方程"></a>贝尔曼最优方程</h2><p>学习的目的是优化一个策略π使得值函数v or q最大</p><script type="math/tex; mode=display">v_{*}(s)=\max _{\pi} v_{\pi}(s)</script><script type="math/tex; mode=display"> q_{*}(s, a)=\max _{\pi} q_{\pi}(s, a)</script><p> 对于任意一个MDPs，存在一个$\pi_<em>$使得$ v_{\pi_{</em>}}(s)=v_{<em>}(s), \quad q_{\pi_{</em>}}(s, a)=q_{*}(s, a) $<br>可得，贝尔曼最优方程：</p><script type="math/tex; mode=display">v_{*}(s)=\max _{a} \mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} v_{*}\left(s^{\prime}\right)</script><script type="math/tex; mode=display">q_{*}(s, a)=\mathcal{R}_{s}^{a}+\gamma \sum_{s^{\prime} \in \mathcal{S}} \mathcal{P}_{s s^{\prime}}^{a} \max _{a^{\prime}} q_{*}\left(s^{\prime}, a^{\prime}\right)</script><h3 id="求解最优方程方法"><a href="#求解最优方程方法" class="headerlink" title="求解最优方程方法"></a>求解最优方程方法</h3><ul><li>Value iteration</li><li>Policy iteration</li><li>Q-learning</li><li>Sarsa</li><li>等</li></ul><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习笔记1：基本概念</title>
      <link href="/posts/rl-1/"/>
      <url>/posts/rl-1/</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>强化学习是一门多学科交叉的技术<br><img src="/img/%E6%88%AA%E5%B1%8F2020-07-27%20%E4%B8%8B%E5%8D%885.35.46-1.png" alt="截屏2020-07-27 下午5.35.46"><br><img src="/img/15973090963916.jpg" alt=""></p><h2 id="与传统控制的关系："><a href="#与传统控制的关系：" class="headerlink" title="与传统控制的关系："></a>与传统控制的关系：</h2><ul><li>相似性：</li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">RL</th><th style="text-align:center">traditional control</th></tr></thead><tbody><tr><td style="text-align:center">agent</td><td style="text-align:center">controller</td></tr><tr><td style="text-align:center">env</td><td style="text-align:center">plant + enviroment</td></tr><tr><td style="text-align:center">reward</td><td style="text-align:center">feedback（error signals）</td></tr><tr><td style="text-align:center">value</td><td style="text-align:center">optimize function</td></tr></tbody></table></div><ul><li>不同点：<ul><li>传统的控制：将任务分解成多个任务的串并联，设计（子）控制器</li><li>机器学习：将控制器压缩成黑盒Black box<br><img src="/img/15953218263369.jpg" alt="-w1354"></li></ul></li></ul><p>强化学习不同于 监督、非监督学习（与静态数据交互），与环境产生交互，产生最优结果的动作序列。</p><h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><p>RL组成要素Agent、Env<br><img src="/img/15972068404024.png" alt=""></p><h2 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h2><p>组成要素：Policy、Value function、Model其中至少一个<br><img src="/img/15958481757170.jpg" alt="-w410"></p><h3 id="策略-Policy-：observation-to-action的映射"><a href="#策略-Policy-：observation-to-action的映射" class="headerlink" title="策略(Policy)：observation to action的映射"></a>策略(Policy)：observation to action的映射</h3><ul><li>固定策略：$a = \pi(s)$给定状态$s$，对应fixed的action $a$</li><li>随机策略：当Agent处于某一个state的时候，它做的Action是不确定的，例如你可以选择study也可以选择game，也就是说你在某一个状态是以一定的概率去选择某一个action。也就是说，策略的选择是一个条件概率$\pi(a|s)$，这里的$\pi$与数序中的$\pi$没有任何关系，他只是代表一个函数而已（其实就是$f(a|s)$）。<script type="math/tex; mode=display">\pi(a \mid s)=P\left(A_{t}=a \mid S_{t}=s\right)</script>函数代表：在状态$s$时采取动作$a$的概率分布。</li></ul><p><img src="/img/%E6%88%AA%E5%B1%8F2020-07-27%20%E4%B8%8B%E5%8D%887.07.57-1.png" alt="截屏2020-07-27 下午7.07.57"></p><h3 id="价值-value-function-：未来奖励的预测（期望）"><a href="#价值-value-function-：未来奖励的预测（期望）" class="headerlink" title="价值(value function)：未来奖励的预测（期望）"></a>价值(value function)：未来奖励的预测（期望）</h3><p>前面我们说到过奖励，当Agent在$t$时刻执行某个动作时，会得到一个$\mathcal{R_{t+1}}$。我们可以想一下蝴蝶效应，这个Action会影响$\mathcal{R_{t+1}}$，那么他会不会影响$\mathcal{R_{t+2}},\mathcal{R_{t+3}}…$呢？很可能会的，比如说在电游中，你所做的某个选择肯定会对接下来的游戏产生影响，这个影响可以深远，也可以没那么深渊（对，我说的就是隐形守护者，mmp），因此状态价值函数可以表示为：</p><script type="math/tex; mode=display">v_{\pi}(s)=\mathbb{E}_{\pi}\left(R_{t+1}+\gamma R_{t+2}+\gamma^{2} R_{t+3}+\ldots \mid S_{t}=s\right)</script><p>$v_{\pi}(s)$与策略函数$\pi$有关，可以理解为当Agent以策略$\pi$运行时，状态$s$的价值是多少。也就是在此状态下，我能够得到多少回报。<br><img src="/img/15958481422216.png" alt="-w425"></p><h2 id="模型Model："><a href="#模型Model：" class="headerlink" title="模型Model："></a>模型Model：</h2><p>对未知env的预测，包括状态s、奖励r</p><h3 id="预测状态：s-gt-s’的概率"><a href="#预测状态：s-gt-s’的概率" class="headerlink" title="预测状态：s->s’的概率"></a>预测状态：s-&gt;s’的概率</h3><script type="math/tex; mode=display">\mathcal{P}_{s s^{\prime}}^{a} =\mathbb{P}  \left(S_{t+1}=s^{\prime} \mid S_{t}=s, A_{t}=a\right)</script><h3 id="预测奖励：R的期望"><a href="#预测奖励：R的期望" class="headerlink" title="预测奖励：R的期望"></a>预测奖励：R的期望</h3><script type="math/tex; mode=display">\mathcal{R}_{s}^{a} =\mathbb{E} R_{t+1} \left( \mid S_{t}=s, A_{t}=a\right)</script><h2 id="环境Env"><a href="#环境Env" class="headerlink" title="环境Env"></a>环境Env</h2><h3 id="完全可观测环境"><a href="#完全可观测环境" class="headerlink" title="完全可观测环境"></a>完全可观测环境</h3><p>个体观测=个体状态=环境状态<br>标准的<strong>MDP </strong></p><h3 id="部分可观测环境"><a href="#部分可观测环境" class="headerlink" title="部分可观测环境"></a>部分可观测环境</h3><p>环境不完全可观测</p><h4 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h4><ul><li>Beliefs of environment state：用个体的经验，记录历史状态并创建概率分布函数<script type="math/tex; mode=display">S_{t}^{a}=\left(\mathbb{P}\left[S_{t}^{e}=s^{1}\right], \ldots, \mathbb{P}\left[S_{t}^{e}=s^{n}\right]\right)</script></li><li>Recurrent neural network：用循环神经网络，表示为，上个状态和当前观测的函数<script type="math/tex; mode=display">S_{t}^{a}=\sigma\left(S_{t-1}^{a} W_{s}+O_{t} W_{o}\right)</script></li></ul><h1 id="概念区分"><a href="#概念区分" class="headerlink" title="概念区分"></a>概念区分</h1><h2 id="学习和规划-Learning-amp-Planning"><a href="#学习和规划-Learning-amp-Planning" class="headerlink" title="学习和规划 Learning &amp; Planning"></a>学习和规划 Learning &amp; Planning</h2><ul><li>学习：环境初始时是<strong>未知</strong>的，个体不知道环境如何工作，个体通过与环境进行交互，逐渐改善其行为策略。</li><li>规划: 环境如何工作对于个体是<strong>已知</strong>或<strong>近似已知</strong>的，个体并不与环境发生实际的交互，而是利用其构建的模型进行计算，在此基础上改善其行为策略。<br>一个常用的强化学习问题解决思路是，先学习环境如何工作，也就是了解环境工作的方式，即学习得到一个模型，然后利用这个模型进行规划。</li></ul><h2 id="预测和控制-Prediction-amp-Control"><a href="#预测和控制-Prediction-amp-Control" class="headerlink" title="预测和控制 Prediction &amp; Control"></a>预测和控制 Prediction &amp; Control</h2><p>在强化学习里，我们经常需要先解决关于预测（prediction）的问题，而后在此基础上解决关于控制（Control）的问题。</p><ul><li>预测：给定一个策略，<strong>评价</strong>未来。可以看成是求解在给定策略下的价值函数（value function）的过程。How well will I(an agent) do if I(the agent) follow a specific policy?</li><li>控制：<strong>找到</strong>一个好的<strong>策略</strong>来最大化未来的奖励。</li></ul><h2 id="探索和利用-Exploration-amp-Exploitation"><a href="#探索和利用-Exploration-amp-Exploitation" class="headerlink" title="探索和利用 Exploration &amp; Exploitation"></a>探索和利用 Exploration &amp; Exploitation</h2><p>试错的学习，个体需要从其与环境的交互中<strong>发现并执行</strong>一个好的策略，同时又不至于在<strong>试错</strong>的过程中丢失太多的奖励。探索和利用是个体进行决策时需要平衡的两个方面</p><h3 id="探索率-epsilon"><a href="#探索率-epsilon" class="headerlink" title="探索率$\epsilon$"></a>探索率$\epsilon$</h3><p>怎么说的探索率呢？它主要是为了防止陷入局部最优。比如说目前在$s_1$状态下有两个$a_1,a_2$。我们通过计算出，发现执行$a_1$的动作比较好，但是为了防止陷入局部最优，我们会选择以$\epsilon$的概率来执行$a_2$，以$1-\epsilon$的概率来执行$a_1$。一般来说，$\epsilon$ 随着训练次数的增加而逐渐减小。</p><h2 id="其他概念"><a href="#其他概念" class="headerlink" title="其他概念"></a>其他概念</h2><h3 id="gamma-奖励衰减因子"><a href="#gamma-奖励衰减因子" class="headerlink" title="$\gamma$奖励衰减因子"></a>$\gamma$奖励衰减因子</h3><p>在上面的价值函数中，有一个变量$\gamma$ ，即奖励衰减因子，在[0，1]之间。如果为0，则是贪婪法，即价值只由当前的奖励决定，如果是1，则所有的后续状态奖励和当前奖励一视同仁。一般来说取0到1之间的数。</p><h3 id="环境的状态转化模型"><a href="#环境的状态转化模型" class="headerlink" title="环境的状态转化模型"></a>环境的状态转化模型</h3><p>由于在某个状态下，执行一定的action，能够达到新的一个状态$S_{t+1}$，但是$S_{t+1}$不一定是唯一的。环境的状态转化模型，可以理解为一个概率状态机，它是一个概率模型，即在状态$t$下采取动作$a$,转到下一个状态$s’$的概率，表示为$P^a_{ss’}$。</p><p>具体在RL_2，MP 中讲解</p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> RL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习-Coursera笔记</title>
      <link href="/posts/machine-learning/"/>
      <url>/posts/machine-learning/</url>
      
        <content type="html"><![CDATA[<h1 id="AI-gt-机器学习分类图"><a href="#AI-gt-机器学习分类图" class="headerlink" title="AI->机器学习分类图"></a>AI-&gt;机器学习分类图</h1><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15936818055208.jpg?x-oss-process=style/blog" alt="-w669"></p><h1 id="矩阵补课"><a href="#矩阵补课" class="headerlink" title="矩阵补课"></a>矩阵补课</h1><h2 id="特征值分解EVD，奇异值分解SVD"><a href="#特征值分解EVD，奇异值分解SVD" class="headerlink" title="特征值分解EVD，奇异值分解SVD"></a>特征值分解EVD，奇异值分解SVD</h2><p>$A$是矩阵<br>$x_i$ 是单位特征向量<br>$\lambda_i$是特征值<br>$\Lambda$ 是矩阵特征值</p><h3 id="EVD特征值分解（The-eigenvalue-value-decomposition）"><a href="#EVD特征值分解（The-eigenvalue-value-decomposition）" class="headerlink" title="EVD特征值分解（The eigenvalue value decomposition）"></a>EVD特征值分解（The eigenvalue value decomposition）</h3><p>针对方阵，特征值<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15921997636239.jpg?x-oss-process=style/blog" alt="-w397"><br>$A = U\Lambda U^{-1} = U\Lambda U^T$<br>进行矩阵运算时，Ax，先对x分解$x =aU^T= a_1 x_1+…a_mx_m$<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922013862028.jpg?x-oss-process=style/blog" alt="-w366"></p><p>则$U\Lambda U^T x = U\Lambda U^T U a^T = U\Lambda a^T$<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922013786257.jpg?x-oss-process=style/blog" alt="-w698"></p><p>$U\Lambda a^T = U(\lambda a)^T$<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922013718111.jpg?x-oss-process=style/blog" alt="-w712"><br>效果如下，将向量在单位特征向量上，伸长为$\lambda$倍<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922016553419.jpg?x-oss-process=style/blog" alt="-w554"></p><h3 id="SVD奇异值分解（Singularly-Valuable-Decomposition）"><a href="#SVD奇异值分解（Singularly-Valuable-Decomposition）" class="headerlink" title="SVD奇异值分解（Singularly Valuable Decomposition）"></a>SVD奇异值分解（Singularly Valuable Decomposition）</h3><p>矩阵A，mxn维，将n维的向量映射到m维空间中,k&lt;=m<br>正交基，$(v_1,v_2…v_n)$<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922032144227.jpg?x-oss-process=style/blog" alt="-w624"><br>$A^T A = \lambda_j$<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922033896848.jpg?x-oss-process=style/blog" alt="-w730"><br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922036689443.jpg?x-oss-process=style/blog" alt="-w722"><br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922038887667.jpg?x-oss-process=style/blog" alt="-w725"></p><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922052033790.jpg?x-oss-process=style/blog" alt="-w697"></p><p>存储领域，选取u，v正交基矩阵，计算奇异值矩阵，使奇异值矩阵尽量集中，即可取到</p><h1 id="机器学习"><a href="#机器学习" class="headerlink" title="机器学习"></a>机器学习</h1><h2 id="1、Introduction"><a href="#1、Introduction" class="headerlink" title="1、Introduction"></a>1、Introduction</h2><p>E：经验<br>T：任务<br>P：概率</p><h3 id="机器学习分类"><a href="#机器学习分类" class="headerlink" title="机器学习分类"></a>机器学习分类</h3><ul><li>监督学习(supervisor learning)：分类（classification）、回归（regression）</li><li>无监督学习(unsupervisor learning)：</li><li>强化学习Reinforcement learning</li></ul><h2 id="2、Linear-regression线型回归"><a href="#2、Linear-regression线型回归" class="headerlink" title="2、Linear regression线型回归"></a>2、Linear regression线型回归</h2><h3 id="Cost-funciton-代价函数"><a href="#Cost-funciton-代价函数" class="headerlink" title="Cost funciton-代价函数"></a>Cost funciton-代价函数</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922084781269.jpg?x-oss-process=style/blog" alt="-w444"><br>矩阵表达<br>$J(\theta) = \frac{1}{2m}(X\theta-Y)^T(X\theta-Y)$</p><ul><li>梯度下降法（Gradient Descent）<br>$\theta_{i+1} =\theta_i - \alpha\nabla J(\theta) $<br>$\frac{\partial J(\theta)}{\partial\theta} = \frac{1}{m}X^T(X\theta-Y)$<br>推导过程<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923078000390.jpg?x-oss-process=style/blog" alt="-w787"><br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923078144953.jpg?x-oss-process=style/blog" alt="-w607"></li></ul><ul><li>正规方程法（Normal Equation）<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922203884161.jpg?x-oss-process=style/blog" alt="-w601"><br>图中公式，theta的维是n，不是m<br>另一种理解方式<br>相当于求解$Y = X\theta$<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922219982331.jpg?x-oss-process=style/blog" alt="-w714"></li></ul><p>b相当于y，a相当于x组成的矩阵，<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922210683035.jpg?x-oss-process=style/blog" alt="-w189"><br>求导过程<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922218251765.jpg?x-oss-process=style/blog" alt="-w598"></p><h3 id="线性代数回顾"><a href="#线性代数回顾" class="headerlink" title="线性代数回顾"></a>线性代数回顾</h3><p>矩阵、向量使用规范<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922243037001.jpg?x-oss-process=style/blog" alt="-w860"></p><h3 id="加速梯度下降方法，让-x-i-尺度一致"><a href="#加速梯度下降方法，让-x-i-尺度一致" class="headerlink" title="加速梯度下降方法，让$x_i$尺度一致"></a>加速梯度下降方法，让$x_i$尺度一致</h3><ul><li>Feature Scaling<br>将输入值归一化，缩放到[-1,1]之间，梯度下降法更快收敛</li><li>Mean Normalization<br>$x_i = \frac{x_i - \mu_i}{s_i}$,其中$\mu_i$是input的平均值，$s_i$是取值的范围，或者标准偏差</li></ul><h3 id="回归问题方法选择"><a href="#回归问题方法选择" class="headerlink" title="回归问题方法选择"></a>回归问题方法选择</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922433025100.jpg?x-oss-process=style/blog" alt="-w869"><br>正规方程法行不通：</p><ul><li>$X^TX$不可逆</li></ul><ol><li>元素中有redundant features,linearly dependent</li><li>过多的features，导致input维度n&gt;m</li></ol><h3 id="回归问题的矩阵表达"><a href="#回归问题的矩阵表达" class="headerlink" title="回归问题的矩阵表达"></a>回归问题的矩阵表达</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15922713533207.jpg?x-oss-process=style/blog" alt="-w650"></p><h2 id="3、Logistic-Regression逻辑回归"><a href="#3、Logistic-Regression逻辑回归" class="headerlink" title="3、Logistic Regression逻辑回归"></a>3、Logistic Regression逻辑回归</h2><p>分类classification</p><h3 id="函数表达式"><a href="#函数表达式" class="headerlink" title="函数表达式"></a>函数表达式</h3><p>$z = \theta^T x$<br>$h(z) = sigmoid(z)$<br>处理regression函数：连续变离散-&gt;Hypothesis </p><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>h(z)代表着一个边界，将值分为&gt;0和&lt;0<br>由于sigmoid函数的特性，程序最终会优化到z取值远离零点</p><h3 id="Cost-function-的选择"><a href="#Cost-function-的选择" class="headerlink" title="Cost function 的选择"></a>Cost function 的选择</h3><p>不能选择最小二乘法，因为目标是一个非凸函数<br>凸函数才能最好利用梯度下降法<br>所以对于，y-0，1的分类问题，改写cost function为<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923134620258.jpg?x-oss-process=style/blog" alt="-w375"><br>进一步改写为一个式子<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923135710044.jpg?x-oss-process=style/blog" alt="-w696"><br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923571866503.jpg?x-oss-process=style/blog" alt="-w902"></p><p>推导过程中，利用了sigmoid的求导法则<br>$\sigma’(x) = \sigma(x)(1-\sigma(x))$</p><p>特殊设计过的sigmoid函数 和 cost function<br>使得，满足$\theta$参数更新可以矢量化<br>$\theta_{i+1} = \theta_i - \alpha  \nabla J(\theta)=\theta_i - \alpha X^T(g(X\theta) - Y)$<br>$g(X\theta)$是sigmoid函数对$\X\theta$矩阵每个元素进行操作<br>特征缩放，</p><h2 id="其他参数优化方法"><a href="#其他参数优化方法" class="headerlink" title="其他参数优化方法"></a>其他参数优化方法</h2><ul><li>Conjugate gradient 共轭下降法</li><li>BFGS</li><li>L_BFGS<br>优点：</li><li>不需要选择学习速率$\alpha$</li><li>收敛速度快<br>缺点：复杂<br>可以直接调用</li></ul><pre><code>1.设置优化参数 optimset = 初始参数，方法，强制结束迭代次数2.设置初始条件，Initialpara = 3.[Jval, theta'] = Cost_function (X,Y)4.调用优化函数[Jval，theta'] = (@Cost_function,Initialpara,optimset)，</code></pre><h2 id="多类别分类"><a href="#多类别分类" class="headerlink" title="多类别分类"></a>多类别分类</h2><p>构建i个分类器，利用i个h(z)，处理<br>分别给出属于某个分类的几率值</p><p>X 特征矩阵</p><h2 id="3-2回归遇到的问题，解决方案，正则化"><a href="#3-2回归遇到的问题，解决方案，正则化" class="headerlink" title="3.2回归遇到的问题，解决方案，正则化"></a>3.2回归遇到的问题，解决方案，正则化</h2><ul><li><p>过拟合<br>拟合特征数&gt;&gt;样本量，</p></li><li><p>欠拟合<br>特征数不够&lt;&lt;样本量，不能正确预测，回归</p><h3 id="办法"><a href="#办法" class="headerlink" title="办法"></a>办法</h3><p>1、 减少无关特征</p></li><li>手动减少无关特征</li><li>模型选择算法，自动选择相关变量<br>2、 regularization 正则化<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923657698696.jpg?x-oss-process=style/blog" alt="-w452"><br>正则化参数，使特征拟合参数减小权重</li></ul><h4 id="线性回归正则化"><a href="#线性回归正则化" class="headerlink" title="线性回归正则化"></a>线性回归正则化</h4><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923660929388.jpg?x-oss-process=style/blog" alt="-w784"><br><strong>对于逻辑回归正则化，式子一样</strong></p><h2 id="4、神经网络——Nonlinear-Hypotheses"><a href="#4、神经网络——Nonlinear-Hypotheses" class="headerlink" title="4、神经网络——Nonlinear Hypotheses"></a>4、神经网络——Nonlinear Hypotheses</h2><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923834646377.jpg?x-oss-process=style/blog" alt="-w591"><br>输入层、隐藏层、输出层<br>g 激活函数$\in[0,1]$：<br>h 输出函数</p><ul><li>阶跃</li><li>逻辑函数，sigmoid，无限可微</li><li>斜坡函数</li><li>高斯函数<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923839870398.jpg?x-oss-process=style/blog" alt="-w709"><h3 id="multiclass-classification"><a href="#multiclass-classification" class="headerlink" title="multiclass classification"></a>multiclass classification</h3>输出层y不是一个数字，[1;0;0;0] [0;1;0;0]instead<h3 id="Forward-propagation"><a href="#Forward-propagation" class="headerlink" title="Forward propagation"></a>Forward propagation</h3>$a^{(j+1)} = g(\Theta ^ {(j})a^{(j)})$</li></ul><h3 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h3><p>Cost function<br><strong>符号约定</strong><br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923869999391.jpg?x-oss-process=style/blog" alt="-w788"><br><a href="https://github.com/halfrost/Halfrost-Field/blob/master/contents/Machine_Learning/Neural_Networks_Learning.ipynb">传播计算推导</a></p><h3 id="BP神经网络——算法步骤"><a href="#BP神经网络——算法步骤" class="headerlink" title="BP神经网络——算法步骤"></a>BP神经网络——算法步骤</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15923952253210.jpg?x-oss-process=style/blog" alt="-w822"><br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15924600046523.jpg?x-oss-process=style/blog" alt="-w536"></p><p><strong>调用函数的时候 unroll矩阵-&gt;Vector</strong><br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15924602839093.jpg?x-oss-process=style/blog" alt="-w702"></p><p>gradient check<br>引入 $\epsilon$，数值计算，缺点太慢，只用于编程时的校验</p><p>$\Theta$初始化<br>随机初始化，零值代入会有问题，权重难更新<br>我们将初始化权值 $\Theta_{ij}^{(l)}$ 的范围限定在 $[-\Phi ,\Phi ]$ 。</p><h2 id="6、Advice-for-applying-machine-learning"><a href="#6、Advice-for-applying-machine-learning" class="headerlink" title="6、Advice for applying machine learning"></a>6、Advice for applying machine learning</h2><h3 id="评价拟合函数hypothesis"><a href="#评价拟合函数hypothesis" class="headerlink" title="评价拟合函数hypothesis"></a>评价拟合函数hypothesis</h3><ol><li>分类数据集（training set、test set）</li><li>用训练集的theta 计算测试集的误差（分类问题，误差定义为0/1，最终统计结果表现为错误率）<h3 id="模型选择——（Train-Validation-Test-sets）"><a href="#模型选择——（Train-Validation-Test-sets）" class="headerlink" title="模型选择——（Train/ Validation/ Test sets）"></a>模型选择——（Train/ Validation/ Test sets）</h3></li></ol><ul><li>训练多个模型，在测试集中找到表现最优</li><li>偏差和方差（Bias/ Variance）<br>关于 模型种类<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925327225783.jpg?x-oss-process=style/blog" alt="-w335"><br>关于 正则化参数<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925342959750.jpg?x-oss-process=style/blog" alt="-w808"></li></ul><h2 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h2><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925410355870.jpg?x-oss-process=style/blog" alt="-w400"></p><p>High bias<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925413495753.jpg?x-oss-process=style/blog" alt="-w732"></p><p>High Variance<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925414621124.jpg?x-oss-process=style/blog" alt="-w696"></p><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925415469599.jpg?x-oss-process=style/blog" alt="-w537"></p><h2 id="6-2-设计神经网络"><a href="#6-2-设计神经网络" class="headerlink" title="6.2 设计神经网络"></a>6.2 设计神经网络</h2><ol><li><strong>快速部署</strong>、设计简单网络</li><li>plot 学习曲线，发现问题</li><li>误差分析（验证集）：数值被错误分类的特征，度量误差</li></ol><h3 id="误差度量-for-skewed-classes-偏斜类"><a href="#误差度量-for-skewed-classes-偏斜类" class="headerlink" title="误差度量 for skewed classes 偏斜类"></a>误差度量 for skewed classes 偏斜类</h3><p>precision/recall<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925459953399.jpg?x-oss-process=style/blog" alt="-w789"><br>针对最后一级h(x)，<br>防止错判，阈值提高，设定逻辑判断阈值0.9  instead of 0.5<br>防止漏过1，阈值放低</p><h4 id="综合评定标准"><a href="#综合评定标准" class="headerlink" title="综合评定标准"></a>综合评定标准</h4><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925496319235.jpg?x-oss-process=style/blog" alt="-w779"></p><h2 id="7、支持向量机SVM（support-vector-machine）"><a href="#7、支持向量机SVM（support-vector-machine）" class="headerlink" title="7、支持向量机SVM（support vector machine）"></a>7、支持向量机SVM（support vector machine）</h2><h3 id="7-1-SVM-大间距分类器（Large-Margin-Classification）"><a href="#7-1-SVM-大间距分类器（Large-Margin-Classification）" class="headerlink" title="7.1 SVM 大间距分类器（Large Margin Classification）"></a>7.1 SVM 大间距分类器（Large Margin Classification）</h3><p><strong>重写了cost function 和 h（z）</strong></p><p>支持向量机的代价函数为：</p><script type="math/tex; mode=display">min_{\theta} C[\sum_{i=1}^{m}{y^{(i)}}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum_{j=1}^{n}{\theta_j^2}</script><p><img src="/img/15970703768252.jpg" alt="-w578"></p><p>有别于逻辑回归假设函数输出的是概率，支持向量机它是直接预测 y 的值是0还是<br><strong>假设函数</strong></p><script type="math/tex; mode=display">h_{\theta}(x)=\left\{\begin{matrix}1,\;\;if\; \theta^{T}x\geqslant 0\\ 0,\;\;otherwise\end{matrix}\right.</script><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925640229783.jpg?x-oss-process=style/blog" alt="-w889"><br>最小化$\theta$的模，相当于最大化样本在$\theta$上的投影长度，图中直观表现为，绿色边界在$\theta$方向上距离样本距离最远。<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925718971038.jpg?x-oss-process=style/blog" alt="-w549"><br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15925719456841.jpg?x-oss-process=style/blog" alt="-w587"></p><h2 id="7-2-kernels核函数"><a href="#7-2-kernels核函数" class="headerlink" title="7.2 kernels核函数"></a>7.2 kernels核函数</h2><p>核函数满足$κ(xi·xj)=φ(xi)T·φ(xj)$<br>低维线性不可分（欠拟合）-&gt;映射到高维<br>避免维度灾难，引入核函数（Kernels），用样本去构造特征<br>适用于n&lt;&lt;m, 增加特征数量变为m</p><h3 id="高斯核函数"><a href="#高斯核函数" class="headerlink" title="高斯核函数"></a>高斯核函数</h3><p>参数：$l(i),\sigma$<br>$f = exp^{(-\frac{||x-l^{(i)}||^2}{2\sigma^2})}$<br>取值[0,1]</p><h3 id="注意的点"><a href="#注意的点" class="headerlink" title="注意的点"></a>注意的点</h3><p>核函数用于逻辑回归，运算很慢<br>核函数优化算法仅适用于SVM<br>使用前，一定归一化处理</p><h2 id="分类模型的选择"><a href="#分类模型的选择" class="headerlink" title="分类模型的选择"></a>分类模型的选择<a href=""></a></h2><p>7.3 分类模型的选择<br>目前，我们学到的分类模型有：<br>（1）逻辑回归；<br>（2）神经网络；<br>（3）SVM<br>怎么选择在这三者中做出选择呢？我们考虑特征维度 n 及样本规模 m ：</p><ol><li>如果 n 相对于 m 非常大，例如 n=10000 ，而 $m\in(10,1000)$ ：此时选用逻辑回归或者无核的 SVM。</li><li>如果 n 较小，m 适中，如  $n\in(1,1000)$ ，而  $m\in(10,10000)$ ：此时选用核函数为高斯核函数的 SVM。</li><li>如果 n 较小，m 较大，如  $n\in(1,1000)$ ，而 m&gt;50000 ：此时，需要创建更多的特征（比如通过多项式扩展），再使用逻辑回归或者无核的 SVM。 神经网络对于上述情形都有不错的适应性，但是计算性能上较慢。</li></ol><h2 id="8、无监督学习（Unsupervised-learning）"><a href="#8、无监督学习（Unsupervised-learning）" class="headerlink" title="8、无监督学习（Unsupervised learning）"></a>8、无监督学习（Unsupervised learning）</h2><h3 id="8-1-分类K-means-algorithm-Clustering"><a href="#8-1-分类K-means-algorithm-Clustering" class="headerlink" title="8.1 分类K-means algorithm(Clustering)"></a>8.1 分类K-means algorithm(Clustering)</h3><ol><li>cluster 分类，计算到$\mu_k$距离将下表k分配给$c_i$的</li><li>移动cluster central到，分类的平均点<h4 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h4>Cost function<br>找到$c_i$ 和 $\mu_k$，使函数：<script type="math/tex; mode=display">J(c^{(1)},c^{(2)},\cdots ,c^{(m)};\mu_1,\mu_2,\cdots ,\mu_k)=\frac{1}{m}\sum_{i=1}^m\left \| x^{(i)}-\mu_c(i) \right \|^2</script></li></ol><p>$c_i\in[1,K]$</p><h4 id="mu-k-随机初始化，避免局部最优"><a href="#mu-k-随机初始化，避免局部最优" class="headerlink" title="$\mu_k$随机初始化，避免局部最优"></a>$\mu_k$随机初始化，避免局部最优</h4><ol><li>k&lt;m</li><li>随机指定$\mu_k = x(i)$</li><li>多次运算，找最优结果<br>小k时，多次初始化进行运算<h4 id="选择cluster-数量"><a href="#选择cluster-数量" class="headerlink" title="选择cluster 数量"></a>选择cluster 数量</h4>plot cluster 数量 为横坐标，找突变点</li></ol><h3 id="8-2-Dimensionality-reduction"><a href="#8-2-Dimensionality-reduction" class="headerlink" title="8.2 Dimensionality reduction"></a>8.2 Dimensionality reduction</h3><h4 id="数据压缩-Data-Compression"><a href="#数据压缩-Data-Compression" class="headerlink" title="数据压缩 Data Compression"></a>数据压缩 Data Compression</h4><p>减少冗余特征变量</p><h4 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h4><h4 id="PCA主成分分析法（Principal-Component-Analysis）"><a href="#PCA主成分分析法（Principal-Component-Analysis）" class="headerlink" title="PCA主成分分析法（Principal Component Analysis）"></a>PCA主成分分析法（Principal Component Analysis）</h4><h3 id="PCA算法流程"><a href="#PCA算法流程" class="headerlink" title="PCA算法流程"></a>PCA算法流程</h3><ol><li><p>特征压缩<br>假定我们需要将特征维度从 n 维降到 k 维。则 PCA 的执行流程如下：<br>特征标准化，平衡各个特征尺度：</p><script type="math/tex; mode=display">x^{(i)}_j=\frac{x^{(i)}_j-\mu_j}{s_j}</script><p>$\mu_j$ 为特征 j 的均值，sj 为特征 j 的标准差。<br>计算协方差矩阵 $\Sigma $ ：</p><script type="math/tex; mode=display">\Sigma =\frac{1}{m}\sum_{i=1}{m}(x^{(i)})(x^{(i)})^T=\frac{1}{m} \cdot  X^TX</script><p>通过奇异值分解（SVD），求取 $\Sigma $ 的特征向量（eigenvectors）：</p><script type="math/tex; mode=display">(U,S,V^T)=SVD(\Sigma )</script><p>从 U 中取出前 k 个左奇异向量，构成一个约减矩阵 Ureduce :</p><script type="math/tex; mode=display">U_{reduce}=(\mu^{(1)},\mu^{(2)},\cdots,\mu^{(k)})</script><p>计算新的特征向量： $z^{(i)}$</p><script type="math/tex; mode=display">z^{(i)}=U^{T}_{reduce} \cdot  x^{(i)}</script></li><li><p>特征还原<br>因为 PCA 仅保留了特征的主成分，所以 PCA 是一种有损的压缩方式，假定我们获得新特征向量为：</p><script type="math/tex; mode=display">z=U^T_{reduce}x</script><p>那么，还原后的特征 $x_{approx}$ 为：</p><script type="math/tex; mode=display">x_{approx}=U_{reduce}z</script></li><li>信息保留评价<br>降维多少才合适？<br>从 PCA 的执行流程中，我们知道，需要为 PCA 指定目的维度 k 。如果降维不多，则性能提升不大；如果目标维度太小，则又丢失了许多信息。通常，使用如下的流程的来评估 k 值选取优异：<br>求各样本的投影均方误差:<script type="math/tex; mode=display">\min \frac{1}{m}\sum_{j=1}^{m}\left \| x^{(i)}-x^{(i)}_{approx} \right \|^2</script>求数据的总方差variance：<script type="math/tex; mode=display">\frac{1}{m}\sum_{j=1}^{m}\left \| x^{(i)} \right \|^2</script>评估下式是否成立:<script type="math/tex; mode=display">\frac{\min \frac{1}{m}\sum_{j=1}^{m}\left \| x^{(i)}-x^{(i)}_{approx} \right \|^2}{\frac{1}{m}\sum_{j=1}^{m}\left \| x^{(i)} \right \|^2} \leqslant \epsilon</script>其中， $\epsilon $ 的取值可以为 0.01,0.05,0.10,⋯，假设  $\epsilon = 0.01 $ ，我们就说“特征间 99% 的差异性得到保留”。<br><strong>看$\Sigma$矩阵的二范数占比就知道</strong><br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15928009747208.jpg?x-oss-process=style/blog" alt="-w710"></li></ol><h3 id="PCA-point"><a href="#PCA-point" class="headerlink" title="PCA-point"></a>PCA-point</h3><p>协方差矩阵$\Sigma$看主成分<br>取前k个u构成向量<br>$U_{reduce}\in \mathbb{R}^{n\times k}$<br>PCA 不能解决过拟合，要用正则化的方式</p><h2 id="9、异常检测"><a href="#9、异常检测" class="headerlink" title="9、异常检测"></a>9、异常检测</h2><h3 id="9-1高斯分布-Gaussian-normal-distribution"><a href="#9-1高斯分布-Gaussian-normal-distribution" class="headerlink" title="9.1高斯分布(Gaussian normal distribution)"></a>9.1高斯分布(Gaussian normal distribution)</h3><p>$x\sim N(\mu,\sigma^2)$<br>其分布概率为：</p><script type="math/tex; mode=display">p(x;\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(x-\mu)^2}{2\sigma^2})</script><p>其中 $\mu$ 为期望值（均值）， $\sigma^2$ 为方差。<br>在概率论中，对有限个样本进行参数估计</p><script type="math/tex; mode=display">\mu_j = \frac{1}{m} \sum_{i=1}^{m}x_j^{(i)}\;\;\;,\;\;\; \delta^2_j = \frac{1}{m} \sum_{i=1}^{m}(x_j^{(i)}-\mu_j)^2</script><p>这里对参数 $\mu$ 和参数 $\delta^2$ 的估计就是二者的极大似然估计。<br>假定每一个特征 $x_{1}$ 到 $x_{n}$ 均服从正态分布，则其模型的概率为：</p><script type="math/tex; mode=display">\begin{align*}p(x)&amp;=p(x_1;\mu_1,\sigma_1^2)p(x_2;\mu_2,\sigma_2^2) \cdots p(x_n;\mu_n,\sigma_n^2)\\&amp;=\prod_{j=1}^{n}p(x_j;\mu_j,\sigma_j^2)\\&amp;=\prod_{j=1}^{n} \frac{1}{\sqrt{2\pi}\sigma_{j}}exp(-\frac{(x_{j}-\mu_{j})^2}{2\sigma_{j}^2})\end{align*}</script><p>当 $p(x)&lt;\varepsilon$时，$x$ 为异常样本。</p><h3 id="算法评价"><a href="#算法评价" class="headerlink" title="算法评价"></a>算法评价</h3><p>由于异常样本是非常少的，所以整个数据集是非常偏斜的，我们不能单纯的用预测准确率来评估算法优劣，所以用我们之前的查准率（Precision）和召回率（Recall）计算出 F 值进行衡量异常检测算法了。<br>真阳性、假阳性、真阴性、假阴性<br>查准率（Precision）与 召回率（Recall）<br>F1 Score<br>我们还有一个参数 $\varepsilon$ ，这个 $\varepsilon$ 是我们用来决定什么时候把一个样本当做是异常样本的阈值。我们应该试用多个不同的 $\varepsilon$ 值，选取一个使得 F 值最大的那个 $\varepsilon$ 。</p><h3 id="异常检测与逻辑回归的区别"><a href="#异常检测与逻辑回归的区别" class="headerlink" title="异常检测与逻辑回归的区别"></a>异常检测与逻辑回归的区别</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15928075440417.jpg?x-oss-process=style/blog" alt="-w790"></p><p>异常检测数据特点是：</p><ol><li>数据偏斜，y=1数据量极少</li><li>异常数据特征不聚类（不稳定），难以预测</li></ol><h3 id="多元高斯函数"><a href="#多元高斯函数" class="headerlink" title="多元高斯函数"></a>多元高斯函数</h3><p>其概率模型为： <script type="math/tex">p(x;\mu,\Sigma)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))</script><br>（其中 $|\Sigma|$ 是 $\Sigma$ 的行列式，$\mu$ 表示样本均值，$\Sigma$ 表示样本协方差矩阵。）。<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15930031190056.jpg?x-oss-process=style/blog" alt="-w740"><br>其中$\Sigma$参数估计：</p><script type="math/tex; mode=display">\mu=\frac{1}{m}\sum_{i=1}^{m}{x^{(i)}}$$$$\Sigma=\frac{1}{m}\sum_{i=1}^{m}{(x^{(i)}-\mu)(x^{(i)}-\mu)^T}</script><h3 id="算法流程-多元高斯分布异常检测"><a href="#算法流程-多元高斯分布异常检测" class="headerlink" title="算法流程-多元高斯分布异常检测"></a>算法流程-多元高斯分布异常检测</h3><p>采用了多元高斯分布的异常检测算法流程如下：<br>选择一些足够反映异常样本的特征 $x_j$ 。<br>对各个样本进行参数估计： <script type="math/tex">\mu=\frac{1}{m}\sum_{i=1}^{m}{x^{(i)}}$$$$\Sigma=\frac{1}{m}\sum_{i=1}^{m}{(x^{(i)}-\mu)(x^{(i)}-\mu)^T}</script><br>当新的样本 x 到来时，计算 $p(x)$ ：</p><script type="math/tex; mode=display">p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}exp(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))</script><p>如果 $p(x)&lt;\varepsilon $ ，则认为样本 x 是异常样本。</p><h3 id="相关性"><a href="#相关性" class="headerlink" title="相关性"></a>相关性</h3><p>一般高斯模型：<br>需要手动创建一些特征来描述某些特征的相关性<br>多元高斯模型：<br>利用协方差矩阵$\Sigma$获得了各个特征相关性</p><h3 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h3><p>一般高斯模型：<br>计算复杂度低，适用于高维特征<br>多元高斯模型：<br>计算复杂</p><h3 id="效果¶"><a href="#效果¶" class="headerlink" title="效果¶"></a>效果¶</h3><p>一般高斯模型：<br>在样本数目 m 较小时也工作良好<br>多元高斯模型：<br>需要 $\Sigma$ 可逆，亦即需要 $m&gt;n$ ，(通常会考虑 $ m \geqslant 10*n $，确保有足够多的数据去拟合这些变量，更好的去评估协方差矩阵 $\Sigma$ )且各个特征不能线性相关，如不能存在 $x_2=3x_1$ 或者 $x_3=x_1+2x_2$</p><h3 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h3><p>基于多元高斯分布模型的异常检测应用十分有限。</p><h3 id="9、2-推荐器-Recommender-system"><a href="#9、2-推荐器-Recommender-system" class="headerlink" title="9、2 推荐器 Recommender system"></a>9、2 推荐器 Recommender system</h3><h4 id="Content-based-recommendations"><a href="#Content-based-recommendations" class="headerlink" title="Content based recommendations"></a>Content based recommendations</h4><p>$y(i,j) = \theta_{j}^T x_i$评分等于电影特征成分*用户喜好<br>前提：电影特征$x_i$已知，求解用户喜好$\theta_j$</p><p>为了对用户 j 打分状况作出最精确的预测，我们需要：</p><script type="math/tex; mode=display">\min_{(\theta^{(j)})}=\frac{1}{2}\sum_{i:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}</script><p>计算出所有的 $\theta$ 为：</p><script type="math/tex; mode=display">J(\theta^{(1)},\cdots,\theta^{(n_u)})=\min_{(\theta^{(1)},\cdots,\theta^{(n_u)})}=\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}</script><p>与前面所学线性回归内容的思路一致，为了计算出 $J(\theta^{(1)},\cdots,\theta^{(n_u)})$，使用梯度下降法来更新参数：<br>更新偏置（插值）：</p><script type="math/tex; mode=display">\theta^{(j)}_0=\theta^{(j)}_0-\alpha \sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x^{(i)}_0</script><p>更新权重：</p><script type="math/tex; mode=display">\theta^{(j)}_k=\theta^{(j)}_k-\alpha \left( \sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x^{(i)}_k+\lambda \theta^{(j)}_k \right),\;\;\; k \neq 0</script><h4 id="协同过滤Collaborative-filtering"><a href="#协同过滤Collaborative-filtering" class="headerlink" title="协同过滤Collaborative filtering"></a>协同过滤Collaborative filtering</h4><p>电影特征成分$x_i$和用户喜好$\theta_j$均未知</p><h4 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h4><ol><li>目标优化<br>当用户给出他们喜欢的类型，即 $\theta^{(1)},\cdots,\theta^{(n_u)}$ ，我们可以由下列式子得出 $x^{(i)}$ ：<script type="math/tex; mode=display">\min_{(x^{(i)})}=\frac{1}{2}\sum_{j:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{k=1}^{n}{(x_k^{(i)})^2}</script>可出所有的 x 则为：<script type="math/tex; mode=display">\min_{(x^{(1)},\cdots,x^{(n_m)})}=\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}{(x_k^{(i)})^2}</script>只要我们得到 $\theta$ 或者 x ，都能互相推导出来。<br>协同过滤算法基本思想就是当我们得到其中一个数据的时候，我们推导出另一个，然后根据推导出来的再推导回去进行优化，优化后再继续推导继续优化，如此循环协同推导。</li><li>协同过滤的目标优化<br>推测用户喜好：给定$x^{(1)},\cdots,x^{(n_m)}$ ，估计$\theta^{(1)},\cdots,\theta^{(n_\mu)}$ ： <script type="math/tex">\min_{(\theta^{(1)},\cdots,\theta^{(n_\mu)})}=\frac{1}{2}\sum_{j=1}^{n_\mu}\sum_{i:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{j=1}^{n_\mu}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}</script><br>推测商品内容：给定$\theta^{(1)},\cdots,\theta^{(n_\mu)}$ ，估计$x^{(1)},\cdots,x^{(n_m)}$ ： <script type="math/tex">\min_{(x^{(1)},\cdots,x^{(n_m)})}=\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j:r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}{(x_k^{(i)})^2}</script><br>协同过滤：同时优化$x^{(1)},\cdots,x^{(n_m)}$ ，估计$\theta^{(1)},\cdots,\theta^{(n_\mu)}$： <script type="math/tex">\min \; J(x^{(1)},\cdots,x^{(n_m)};\theta^{(1)},\cdots,\theta^{(n_\mu)})</script><br>即：<script type="math/tex; mode=display">\min_{(x^{(1)},\cdots,x^{(n_m)};\theta^{(1)},\cdots,\theta^{(n_\mu)})}=\frac{1}{2}\sum_{(i,j):r(i,j)=1}^{}{((\theta^{(j)})^T(x^{(i)})-y^{(i,j)})^2}+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}{(x_k^{(i)})^2}+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}{(\theta_k^{(j)})^2}</script>因为正则化的原因在这里面不再有之前的 $x_0=1$,$\theta_0=0$ 。</li><li>协同过滤算法的步骤为：<br>随机初始化$x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_\mu)} $为一些较小值，与神经网络的参数初始化类似，为避免系统陷入僵死状态，不使用 0 值初始化。<br>通过梯度下降的算法计算出$J(x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_\mu)})$,参数更新式为： <script type="math/tex">x^{(i)}_k=x^{(i)}_k-\alpha \left( \sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})\theta^{(j)}_k+\lambda x^{(i)}_k \right)$$$$\theta^{(j)}_k=\theta^{(j)}_k-\alpha \left( \sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x^{(i)}_k+\lambda \theta^{(j)}_k \right)</script><br>如果用户的偏好向量为$\theta$，而商品的特征向量为 x ，则可以预测用户评价为 $\theta^Tx$ 。<br>因为协同过滤算法 $\theta$ 和 x 相互影响，因此，二者都没必要使用偏置 $\theta_0$ 和 $x_0$，即，$x \in \mathbb{R}^n$、 $\theta \in \mathbb{R}^n$ 。<h4 id="低秩分解（Low-Rank-Matrix-Factorization）"><a href="#低秩分解（Low-Rank-Matrix-Factorization）" class="headerlink" title="低秩分解（Low Rank Matrix Factorization）"></a>低秩分解（Low Rank Matrix Factorization）</h4>$Y = X\Theta^T$<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15933132737330.jpg?x-oss-process=style/blog" alt="-w712"></li></ol><h4 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h4><ol><li>$\lambda$正则化，使$\theta$趋向0</li><li>平均值正则化(mean normalization)<br>将平均值作为0点，让Y偏置<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15933144020810.jpg?x-oss-process=style/blog" alt="-w704"></li></ol><h2 id="10、大数据集——提升运算速度"><a href="#10、大数据集——提升运算速度" class="headerlink" title="10、大数据集——提升运算速度"></a>10、大数据集——提升运算速度</h2><h3 id="Stochastic-Gradient-Descent（随机梯度下降法）"><a href="#Stochastic-Gradient-Descent（随机梯度下降法）" class="headerlink" title="Stochastic Gradient Descent（随机梯度下降法）"></a>Stochastic Gradient Descent（随机梯度下降法）</h3><p>不用全部数据集进行运算</p><ol><li>预处理，随机排序</li><li>内循环，单个特征修改拟合参数<br>每次使用一个样本<h4 id="SGD收敛性"><a href="#SGD收敛性" class="headerlink" title="SGD收敛性"></a>SGD收敛性</h4>每隔1000个样本画cost函数</li></ol><ul><li>小$\alpha$让曲线慢，准</li><li>大样本采样间距-&gt;曲线更光滑</li><li>随着迭代次数，减小α</li></ul><h3 id="Mini-Batch-Gradient-Descent"><a href="#Mini-Batch-Gradient-Descent" class="headerlink" title="Mini-Batch Gradient Descent"></a>Mini-Batch Gradient Descent</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15933256124873.jpg?x-oss-process=style/blog" alt="-w672"><br>矢量化-&gt;并行计算，提高效率</p><h3 id="在线学习Online-learning"><a href="#在线学习Online-learning" class="headerlink" title="在线学习Online learning"></a>在线学习Online learning</h3><p>数据集连续，减少存储成本</p><h3 id="Map-reduce-and-data-parallelism"><a href="#Map-reduce-and-data-parallelism" class="headerlink" title="Map reduce and data parallelism"></a>Map reduce and data parallelism</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15933397359609.jpg?x-oss-process=style/blog" alt="-w728"><br>代数计算库自动implement</p><h2 id="12、Photo-OCR-pipeline"><a href="#12、Photo-OCR-pipeline" class="headerlink" title="12、Photo OCR pipeline"></a>12、Photo OCR pipeline</h2><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15933522420345.jpg?x-oss-process=style/blog" alt="-w684"></p><ol><li>文本检测</li><li>特征分割</li><li>特征识别</li><li>修正C1eaning-&gt;cleaning<h3 id="Sliding-window-滑窗分类器"><a href="#Sliding-window-滑窗分类器" class="headerlink" title="Sliding window 滑窗分类器"></a>Sliding window 滑窗分类器</h3><h4 id="文本检测"><a href="#文本检测" class="headerlink" title="文本检测"></a>文本检测</h4>步长step size<br>不同大小，按照比例缩放</li></ol><p>检测到特征，相邻互联</p><h4 id="特征分割"><a href="#特征分割" class="headerlink" title="特征分割"></a>特征分割</h4><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15933520905301.jpg?x-oss-process=style/blog" alt="-w656"></p><h3 id="获取数据，人造数据"><a href="#获取数据，人造数据" class="headerlink" title="获取数据，人造数据"></a>获取数据，人造数据</h3><ol><li>加背景噪音</li><li>字体处理</li><li>人工扭曲</li></ol><p>加入高斯噪声没用</p><h3 id="大量数据获取建议"><a href="#大量数据获取建议" class="headerlink" title="大量数据获取建议"></a>大量数据获取建议</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15933538670382.jpg?x-oss-process=style/blog" alt="-w667"></p><h3 id="Ceiling-analysis上限分析"><a href="#Ceiling-analysis上限分析" class="headerlink" title="Ceiling analysis上限分析"></a>Ceiling analysis上限分析</h3><p>找到提升最大的Module<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15933549643205.jpg?x-oss-process=style/blog" alt="-w725"></p><h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p><a href="https://blog.csdn.net/xyk_hust/article/details/86649104">连接</a></p><h3 id="一些概念"><a href="#一些概念" class="headerlink" title="一些概念"></a>一些概念</h3><ul><li><p>向量机</p></li><li><p>核函数<br>作用：<br>减小计算量，解决多维输入问题<br>无需知道非线性变换函数的形式和参数</p></li></ul><p><a href="https://blog.csdn.net/weixin_42137700/article/details/81479322">核函数种类</a></p><ul><li>贝叶斯滤波器：概率滤波器</li></ul><h2 id="处理微分的手段"><a href="#处理微分的手段" class="headerlink" title="处理微分的手段"></a>处理微分的手段</h2><ol><li>微分+一阶惯性环节，$tf = s/(T_s s +1)$</li><li>TD微分跟踪器<img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15892146432096.jpg?x-oss-process=style/blog" alt="-w635"></li><li>状态观测器</li><li>卡尔曼滤波器</li></ol><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN 序列模型 sequence model</title>
      <link href="/posts/sequence-model/"/>
      <url>/posts/sequence-model/</url>
      
        <content type="html"><![CDATA[<h1 id="Sequence-model"><a href="#Sequence-model" class="headerlink" title="Sequence model"></a>Sequence model</h1><p>概述：处理样本数不规则的模型</p><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15943710523088.jpg?x-oss-process=style/blog" alt="-w769"></p><h2 id="recurrent-neural-network递归神经网络"><a href="#recurrent-neural-network递归神经网络" class="headerlink" title="recurrent neural network递归神经网络"></a>recurrent neural network递归神经网络</h2><p>参数共享,前-&gt;后<br>样本逐个扫描<br>a激活用一套参数<br>y激活用一套参数<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15943708867352.jpg?x-oss-process=style/blog" alt="-w777"></p><h3 id="参数流"><a href="#参数流" class="headerlink" title="参数流"></a>参数流</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15943568179775.jpg?x-oss-process=style/blog" alt="-w731"></p><h3 id="x、y个数不一致的RNN"><a href="#x、y个数不一致的RNN" class="headerlink" title="x、y个数不一致的RNN"></a>x、y个数不一致的RNN</h3><p>序列样本分类问题<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15943713488434.jpg?x-oss-process=style/blog" alt="-w775"><br>音乐生成、机器翻译<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15943715537565.jpg?x-oss-process=style/blog" alt="-w774"></p><h3 id="RNN类型总结"><a href="#RNN类型总结" class="headerlink" title="RNN类型总结"></a>RNN类型总结</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15943716830777.jpg?x-oss-process=style/blog" alt="-w765"></p><h2 id="language-model-with-RNN"><a href="#language-model-with-RNN" class="headerlink" title="language model with RNN"></a>language model with RNN</h2><p>输出P(sentence),并按照y(i)展开为字符串<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15943725690344.jpg?x-oss-process=style/blog" alt="-w774"></p><h3 id="从训练模型采样"><a href="#从训练模型采样" class="headerlink" title="从训练模型采样"></a>从训练模型采样</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15943750855765.jpg?x-oss-process=style/blog" alt="-w776"></p><p>在训练过程中，结局梯度爆炸<br>gradient clipping：梯度过大时，重新缩放梯度向量</p><h2 id="GRU-gated-recurrent-unit"><a href="#GRU-gated-recurrent-unit" class="headerlink" title="GRU gated recurrent unit"></a>GRU gated recurrent unit</h2><p>解决了梯度爆炸问题<br>新建c^{<t>} = a^{<t>} </t></t></p><p>c的估计值<br>$\tilde C^{<t>} = tanh(w_c[c^{<t-1>},x^{<t>}]+b_c)$</t></t-1></t></p><p>Gata，门限值，0 or 1，选择是否记忆<br>$\Gamma_u = \sigma(w_u[c^{<t-1>},x^{<t>}]+b_u)$$</t></t-1></p><p>c的实际值更新函数<br>$c^{<t>} = \Gamma_u * \tilde c ^{<t>} + (1-\Gamma_u) c^{<t-1>}$</t-1></t></t></p><ul><li>GRU单元<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15943765663495.jpg?x-oss-process=style/blog" alt="-w365"></li></ul><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15943771234112.jpg?x-oss-process=style/blog" alt="-w545"></p><h2 id="LSTM-（Long-Short-Term-Memory）"><a href="#LSTM-（Long-Short-Term-Memory）" class="headerlink" title="LSTM （Long Short Term Memory）"></a>LSTM （Long Short Term Memory）</h2><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15944389576811.jpg?x-oss-process=style/blog" alt="-w712"></p><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15944388078864.jpg?x-oss-process=style/blog" alt="-w788"></p><h2 id="Bidirectional双向-RNN-BRNN"><a href="#Bidirectional双向-RNN-BRNN" class="headerlink" title="Bidirectional双向 RNN  BRNN"></a>Bidirectional双向 RNN  BRNN</h2><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15944392852666.jpg?x-oss-process=style/blog" alt="-w782"></p><h2 id="Deep-RNN"><a href="#Deep-RNN" class="headerlink" title="Deep RNN"></a>Deep RNN</h2><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15944397105651.jpg?x-oss-process=style/blog" alt="-w790"></p><h2 id="word-representation"><a href="#word-representation" class="headerlink" title="word representation"></a>word representation</h2><p>只用 one-hot，无法表征单词之间的关系<br>点积为0<br>构建词向量 word vec<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946185176380.jpg?x-oss-process=style/blog" alt="-w647"></p><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946183444304.jpg?x-oss-process=style/blog" alt="-w668"></p><p>man - women<br>king - queen</p><p>词向量库 E 泛化negligible不错<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946186629440.jpg?x-oss-process=style/blog" alt="-w669"></p><p>相似度函数<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946189996342.jpg?x-oss-process=style/blog" alt="-w672"></p><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946193246812.jpg?x-oss-process=style/blog" alt="-w670"><br>应对大词典的softmax运算慢问题，构建二叉树数据结构，常用的放上面，不用每次计算概率<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946209191942.jpg?x-oss-process=style/blog" alt="-w656"></p><p>平衡P(t|c),避免the of 等 词频繁运算出现</p><h3 id="负采样法Negative-sampling"><a href="#负采样法Negative-sampling" class="headerlink" title="负采样法Negative sampling"></a>负采样法Negative sampling</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946217618512.jpg?x-oss-process=style/blog" alt="-w654"></p><h3 id="Glove-global-vectors-for-word-representation"><a href="#Glove-global-vectors-for-word-representation" class="headerlink" title="Glove global vectors for word representation"></a>Glove global vectors for word representation</h3><h2 id="情感分类sentiment-classification"><a href="#情感分类sentiment-classification" class="headerlink" title="情感分类sentiment classification"></a>情感分类sentiment classification</h2><p>问题描述：<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946227091045.jpg?x-oss-process=style/blog" alt="-w658"></p><h2 id="平均数-词向量分类"><a href="#平均数-词向量分类" class="headerlink" title="平均数 词向量分类"></a>平均数 词向量分类</h2><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946228651974.jpg?x-oss-process=style/blog" alt="-w660"></p><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946229353440.jpg?x-oss-process=style/blog" alt="-w660"></p><p>词编码向量的偏差消除<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946235846181.jpg?x-oss-process=style/blog" alt="-w659"></p><h2 id="变输入输出架构"><a href="#变输入输出架构" class="headerlink" title="变输入输出架构"></a>变输入输出架构</h2><p>主要应用在语言识别和机器翻译</p><p>架构：编码器 + 解码器各用了一个<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946322380539.jpg?x-oss-process=style/blog" alt="-w493"></p><h3 id="Beam-search"><a href="#Beam-search" class="headerlink" title="Beam search"></a>Beam search</h3><p>对于翻译算法来说，一次得到整个句子的最优概率对应翻译，搜索量太大，而贪心算法，每次只选一个，随机误差太大，效果差，因此引入Beam search 算法<br>每次考虑2步，第一步选B个，第二部全选n个，从B x n个中寻优</p><h3 id="概率估计值数值稳定性"><a href="#概率估计值数值稳定性" class="headerlink" title="概率估计值数值稳定性"></a>概率估计值数值稳定性</h3><ul><li>概率$\in [0,1]$，连乘，数值稳定性差</li><li>转化为log函数求和，越加越小</li><li>平均值，比求和好</li><li>用$\frac{1}{T_y^\alpha}$<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946358060953.jpg?x-oss-process=style/blog" alt="-w703"></li></ul><h3 id="Error-analysis"><a href="#Error-analysis" class="headerlink" title="Error analysis"></a>Error analysis</h3><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946364822178.jpg?x-oss-process=style/blog" alt="-w702"></p><h2 id="注意力集中-Attention-model-intution"><a href="#注意力集中-Attention-model-intution" class="headerlink" title="注意力集中 Attention model intution"></a>注意力集中 Attention model intution</h2><ul><li>长序列模型的问题<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946392688436.jpg?x-oss-process=style/blog" alt="-w703"><br>without 注意力模型，$y^{<t>}$ 取决于 $a^{<t>}$<br>带有注意力的系统，将权重，分散给其他的几个激活值$a^{<t>}$<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946399130903.jpg?x-oss-process=style/blog" alt="-w696"></t></t></t></li></ul><h3 id="注意力权重计算"><a href="#注意力权重计算" class="headerlink" title="注意力权重计算"></a>注意力权重计算</h3><p>用softmax保证和为1<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946403850376.jpg?x-oss-process=style/blog" alt="-w703"></p><h2 id="语音识别"><a href="#语音识别" class="headerlink" title="语音识别"></a>语音识别</h2><p>声音预处理，频谱<br><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946409369067.jpg?x-oss-process=style/blog" alt="-w700"></p><p><img src="http://hao-blog.oss-cn-hangzhou.aliyuncs.com/2020/08/05/15946409126527.jpg?x-oss-process=style/blog" alt="-w700"></p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 强化学习 </tag>
            
            <tag> RL </tag>
            
            <tag> sequence model </tag>
            
            <tag> rnn </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>科学写作</title>
      <link href="/posts/paper-writting/"/>
      <url>/posts/paper-writting/</url>
      
        <content type="html"><![CDATA[<h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><ol><li>理论创新</li><li>结果创新</li><li>方法创新</li></ol><h2 id="写作规范—符号"><a href="#写作规范—符号" class="headerlink" title="写作规范—符号"></a>写作规范—符号</h2><h2 id="Latex"><a href="#Latex" class="headerlink" title="Latex"></a>Latex</h2><ul><li>智能引用clerveref，引用格式带标题，可改引用格式，图、表、式:label 要在caption 之后，才可以正确引用</li><li>bib文件参考文献</li><li>\section*{acknowledgement}致谢无章节编号 </li></ul><h2 id="markdown"><a href="#markdown" class="headerlink" title="markdown"></a>markdown</h2><p><code>[TOC]是目录</code></p><h1 id="SCI论文"><a href="#SCI论文" class="headerlink" title="SCI论文"></a>SCI论文</h1><h2 id="1-事实汇总"><a href="#1-事实汇总" class="headerlink" title="1. 事实汇总"></a>1. 事实汇总</h2><h3 id="Paper-Structure"><a href="#Paper-Structure" class="headerlink" title="Paper Structure"></a>Paper Structure</h3><p><img src="/img/15966331937167.jpg" alt=""></p><h3 id="Review-Process"><a href="#Review-Process" class="headerlink" title="Review Process"></a>Review Process</h3><p><img src="/img/15966332078087.jpg" alt=""></p><p><img src="/img/15966332147634.jpg" alt=""></p><h3 id="文章第一印象"><a href="#文章第一印象" class="headerlink" title="文章第一印象"></a>文章第一印象</h3><ul><li>图</li><li>表</li><li>引用：数量20个、时间新</li></ul><h2 id="2-Introduction"><a href="#2-Introduction" class="headerlink" title="2. Introduction"></a>2. Introduction</h2><p><img src="/img/15966332219322.jpg" alt=""></p><p><img src="/img/15966332275940.jpg" alt=""></p><p><img src="/img/15966332337510.jpg" alt=""></p><h2 id="3-Method"><a href="#3-Method" class="headerlink" title="3. Method"></a>3. Method</h2><p>理论：推导过程<br>实证：调查方法，数据处理<br>工程应用：理论-&gt;实践</p><p>提供<strong>足够的、准确的，技术细节</strong><br>包括：架设、数学推导、验证、实验设备<br><img src="/img/15966332460219.jpg" alt=""></p><p>注意：<br>符号一致性，符号、单位、描述<br><img src="/img/15966332525954.jpg" alt=""></p><p>编号更新</p><h2 id="4-Result-and-Discussion（结果和讨论）"><a href="#4-Result-and-Discussion（结果和讨论）" class="headerlink" title="4. Result and Discussion（结果和讨论）"></a>4. Result and Discussion（结果和讨论）</h2><p><img src="/img/15966332610267.jpg" alt=""></p><h2 id="5-图表-Figure-and-Table-——第一印象"><a href="#5-图表-Figure-and-Table-——第一印象" class="headerlink" title="5. 图表(Figure and Table)——第一印象"></a>5. 图表(Figure and Table)——第一印象</h2><ol><li>Author’s guide </li><li>图表必须在论文中解释</li><li>引用规范，编号(Fig or Figure)</li><li>一致性</li><li>Caption清晰、准确、完整，不怕标题过长</li><li>区分数据</li><li>副标题（a）</li><li>杜绝一图多投</li><li><strong>保留原始数据</strong></li></ol><h2 id="6-结论conclusion、摘要abstract、题目title"><a href="#6-结论conclusion、摘要abstract、题目title" class="headerlink" title="6. 结论conclusion、摘要abstract、题目title"></a>6. 结论conclusion、摘要abstract、题目title</h2><h3 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h3><p>总结 Result and discussion，重写，not copy</p><h3 id="摘要："><a href="#摘要：" class="headerlink" title="摘要："></a>摘要：</h3><p><img src="/img/15966332705655.jpg" alt=""></p><h3 id="题目："><a href="#题目：" class="headerlink" title="题目："></a>题目：</h3><p><img src="/img/15966332770401.jpg" alt=""></p><h2 id="7-回复审稿人"><a href="#7-回复审稿人" class="headerlink" title="7. 回复审稿人"></a>7. 回复审稿人</h2><h3 id="调整心态："><a href="#调整心态：" class="headerlink" title="调整心态："></a>调整心态：</h3><p>两个审稿人给大修：录用比例超过50%</p><p>论文没有3天可见</p><p>逐一回答每一条意见，每个人可能5页纸</p><h3 id="清晰标明所有文章中的修改"><a href="#清晰标明所有文章中的修改" class="headerlink" title="清晰标明所有文章中的修改"></a>清晰标明所有文章中的修改</h3><p>Each comment will be directly addressed regarding the modified manuscript with changes highlighted in yellow</p><h3 id="礼貌客气"><a href="#礼貌客气" class="headerlink" title="礼貌客气"></a>礼貌客气</h3><p>peer review 没有报酬，感谢和评审时间($$$)<br>The co-authors and I would like to thank you for the time and effort spent in reviewing the manuscript.</p><p>同意：The authors would like to thank the reviewer for the suggestion, ……<br>The authors would like to thank the reviewer’s comment on this problem,……</p><p>不同意：委婉表达，不要怼回去<br>The reviewer’s statement is correct in that …… However, the authors wish to ……<br>corresponding work in the near future and will publish it at a later time.<br>The reviewer’s comment is very useful and profound. However, the current effort</p><h3 id="问题分类"><a href="#问题分类" class="headerlink" title="问题分类"></a>问题分类</h3><h4 id="最多的问题："><a href="#最多的问题：" class="headerlink" title="最多的问题："></a>最多的问题：</h4><p>文字、图标样式修改<br>研究背景：abstract introduction conclusion<br>添加引用文献的要求：<br>忽略了重要工作，慎重对待，讨论并引用<br>添加审稿人的研究工作</p><h4 id="最难的问题："><a href="#最难的问题：" class="headerlink" title="最难的问题："></a>最难的问题：</h4><p>创新性：别人做过，方法新，没有支撑</p><p>实验细节问题：加补实验</p><ol><li>设计其他实验的实验结果解释审稿人的问题，</li><li>文献说明实验困难</li><li>有其他证据证明文中观点 </li></ol><h4 id="回复Reviewers-时间"><a href="#回复Reviewers-时间" class="headerlink" title="回复Reviewers 时间"></a>回复Reviewers 时间</h4><p>1week-1month</p><h4 id="必问问题"><a href="#必问问题" class="headerlink" title="必问问题"></a>必问问题</h4><p>文章背景相关<br>整个领域的贡献<br>与重要文献的关系</p><p>浏览文章图表<br>novelty创新性<br>重视<strong>Introduction</strong><br>实验细节<br>每一句话都有实验数据或者文献支撑</p><h4 id="Rejection的冲动"><a href="#Rejection的冲动" class="headerlink" title="Rejection的冲动"></a>Rejection的冲动</h4><p>数学工程错误<br>明显剽窃<br>错字错词多，图表潦草<br>一稿多投，明显雷同</p><p>不要夸大其词<br>图片信息量太小，灌水</p><h4 id="文章好感度爆棚"><a href="#文章好感度爆棚" class="headerlink" title="文章好感度爆棚"></a>文章好感度爆棚</h4><p>描述问题清楚，逻辑清楚<br>格式标准，图表清晰<br>模拟实验均具备<br>尽力按照审稿人修改</p><h4 id="怼回去"><a href="#怼回去" class="headerlink" title="怼回去"></a>怼回去</h4><p>基础：审稿人吹毛求疵拒稿、编辑很欣赏</p><ul><li>回答好意见，补充漏洞</li><li>只批评没建议，结合其他审稿人正面的意见来反驳</li><li>审稿人的漏洞</li><li>礼貌不谦卑，反驳不吵架</li></ul><h1 id="审稿时间进度"><a href="#审稿时间进度" class="headerlink" title="审稿时间进度"></a>审稿时间进度</h1><p><img src="https://i.loli.net/2020/06/23/GeDM7k1pxFJlSHN.jpg" alt="-w670"></p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 科学写作 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac必备软件推荐，让你效率起飞🚀</title>
      <link href="/posts/mac-app/"/>
      <url>/posts/mac-app/</url>
      
        <content type="html"><![CDATA[<h1 id="系统工具效率"><a href="#系统工具效率" class="headerlink" title="系统工具效率"></a>系统工具效率</h1><ul><li>Alfred<br>置顶，比spotlight高效，支持各种插件，没有上限</li><li>Appcleaner<br>mac卸载软件就靠它，一键拖入，彻底清理干净。想想CleanMyMac、Dr.Cleaner还收费，真是笑死人</li><li>istate menus<br>监控你的电脑，cpu、内存、网络、硬盘，你能想到的都有了</li><li>handshaker<br>老罗确实改变了世界，锤子出品必属精品，mac和手机连接的神器，有线和无线均可，Android和iPhone都可以用，itunes是个啥？？？</li><li>Duet<br>Mac下<code>mac os 10.15</code>有随航(Sidecar)，谁用这个，Windows可以用这个把ipad变为第二个屏幕，超好用，支持无线连接</li><li>Parallel Desktop<br>Mac下的虚拟机，比<code>vitural box</code> <code>VMware</code>好用太多</li><li>坚果云<br>最好用的网盘，已经入了4年个人专业版会员，用来多终端同步工作资料，不要太方便</li><li>休息一下<br>20min提醒你休息一下眼睛，坐办公室挺需要的</li><li>Anydesk<br>即开即用的轻量化远程协助工具，teamviewer还要注册账号</li><li>Etcher<br>U盘刻录工具，大佬都在用</li><li>Blackmagic Disk Speed Test<br>磁盘测速，mac下都用这个，baseline一样，参数对比才有意义</li><li>CleanMyMac<br>mac下的鲁大师，虽然mac不用怎么管理，也没中过病毒，硬盘小的话，可以用来清垃圾什么的</li><li>DaisyDisk<br>清理电脑磁盘必备，可视化做的很不错</li><li>Folx<br>挺好用的下载管理工具</li><li>Transmission<br>种子下载下载</li><li>μ torrent<br>种子下载工具</li><li>kaka<br>压缩包工具</li><li>Mosaic<br>比Magnet定制程度高，实现windows下<code>win + →</code>等功能</li></ul><h1 id="音视频工具"><a href="#音视频工具" class="headerlink" title="音视频工具"></a>音视频工具</h1><ul><li>Downie<br>它支持1000+网站视频下载，包括YouTube、B站等，而且可以设置4K分辨率下载，几乎无所不能，绝对的神器</li><li>Permute<br>通用格式转换软件，包括视频、音频，图片乃至pdf，不仅效率高，而且完美配合downie、iTunes，可以连接Downie使用</li><li>IINA<br>最好用的视频播放器，轻量、简洁、支持云播放、字幕在线搜索</li><li>Adobe Zii<br>Adobe全家桶都可以通过它来白嫖，再说就说多了</li><li>Picgo<br>支持多家图床(github、阿里、七牛、腾讯、smms、imgur等)的管理工具</li><li>Pixelmator Pro<br>mac下的Photoshop，300Mb，比ps轻量，功能足够且易用</li><li>VideoGif<br>功能如其名，快速视频转gif工具，支持简单的尺寸和时间轴编辑</li><li>PicGif<br>功能如其名，快速图片转gif工具，win下美图秀秀就挺好😂</li><li>imageOptim<br>快速压缩图片用，支持Terminal Command<code>imageoptim image_url</code></li><li>Inpaint<br>快速图片除背景</li><li>remove.bg<br>快速图片除背景</li><li>iShot<br>截长图工具，还有很多其他截图功能</li><li>sip<br>快速获取屏幕上颜色，输出可以是各种格式</li></ul><h1 id="阅读与写作"><a href="#阅读与写作" class="headerlink" title="阅读与写作"></a>阅读与写作</h1><ul><li>SCI hub<br>必须置顶，配合<code>google scholar</code>下文献效率提升100倍是有的</li><li>texpad<br>mac下<code>latex</code>写作工具，支持<code>live edit</code>模式，好用，谁用谁知道系列</li><li>Mweb<br>mac下<code>markdown</code>编辑器，个人感觉最好用，自带图床插件，发布<code>blog</code>效率不要太高</li><li>skim<br>最清凉的pdf预览工具，可以配合<code>atom</code> <code>vs code</code>实现latex的pdf预览，开大体积pdf超快</li><li>PDF Expert<br>Mac下的<code>adobe acrobat</code>，</li><li>caj viewer<br>知网文献打开必备，其实还有一个网址可以下载pdf版的知网文献，私信获取</li><li>Mendeley<br><code>Zotero</code>、<code>Endnote</code>也挺好，各有所长吧，习惯了一个就行<br>配合坚果云使用更佳，毕竟免费的云同步不挂代理，有点慢</li><li>Mathpix snipping tool<br>latex 公式 OCR 最强软件，准确率一流，识别完自动复制，多种样式任你挑选</li><li>copy translator<br>整合了<code>google</code> <code>baidu</code> <code>bing</code> 翻译的英文文献阅读工具</li><li>Reeder<br>RSS阅读管理工具，订阅阅读，不用看广告了</li><li>PDF Squeezer<br>pdf压缩工具，有一个网站也挺好用的</li><li>small pdf<br>就是上面说的那个网站，功能齐全，免费有次数限制</li></ul><h1 id="网络和代理"><a href="#网络和代理" class="headerlink" title="网络和代理"></a>网络和代理</h1><ul><li>Little Snitch Configuration<br>监控、管理电脑应用网络权限</li><li>shadowsocks R<br>经典的网络自由工具，</li><li>clash x<br>新一代网络自由工具，支持订阅管理，支持<code>ssr</code>、<code>V2-ray</code>协议，UI友好，我也在用</li></ul><h1 id="画图"><a href="#画图" class="headerlink" title="画图"></a>画图</h1><ul><li>draw.io<br>开源流程图，mac下的visio，轻量化，支持google drive、onedrive等，office插件支持</li><li>OmniGraffle<br>流程图高级编辑工具</li></ul><h1 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h1><ul><li>VS Code<br>轻量多语言IDE，定制性高，插件丰富，现在可以云开发了，NB</li><li>Pycharm<br>python高级IDE，比<code>VS Code</code>有点重，大项目会用这个吧</li><li>Kite<br>高级代码自动补全插件，支持<code>js</code>、<code>python</code>语言和<code>VS code</code>和 <code>pycharm</code>等IDE</li><li>Dash<br>代码文档查阅工具</li><li>CodeRunner<br>轻量化的IDE，所有语言都支持，NB</li><li>Sourcetrail<br><code>git</code>的 UI软件，个人感觉比官方的<code>github desktop</code>功能强大</li><li>pynsource<br><code>python</code>源码阅读工具，显示<code>uml</code>图，快速理解项目结构</li></ul><h1 id="游戏"><a href="#游戏" class="headerlink" title="游戏"></a>游戏</h1><ul><li>OpenEmu<br>小霸王玩过吧，任天堂系列的主机这里都支持</li><li>Dolphin<br>模拟器，同上</li><li>RetroArch<br>模拟器，同上，对手柄支持最好，fake PS 3手柄也可以</li><li>controller lite<br>快速测试你的手柄可用否</li></ul><h1 id="浏览器插件"><a href="#浏览器插件" class="headerlink" title="浏览器插件"></a>浏览器插件</h1><ul><li>Polyglot<br>safari翻译插件</li><li>AdBlock<br>safari广告屏蔽插件</li></ul><h1 id="英语"><a href="#英语" class="headerlink" title="英语"></a>英语</h1><ul><li>Grammarly<br>查重就别用<code>1改</code>什么的了，差距还是有一点的</li><li>欧路词典<br>词库专业，UI漂亮</li></ul><h1 id="有趣的工具"><a href="#有趣的工具" class="headerlink" title="有趣的工具"></a>有趣的工具</h1><ul><li><a href="goodness for free">十分钟邮箱- BccTo.ME</a></li><li>Fliqlo<br>颜值屏保，颜值一级</li></ul><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
        <tags>
            
            <tag> tricks </tag>
            
            <tag> 工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>控制理论笔记</title>
      <link href="/posts/advanced-control/"/>
      <url>/posts/advanced-control/</url>
      
        <content type="html"><![CDATA[<h1 id="经典控制理论"><a href="#经典控制理论" class="headerlink" title="经典控制理论"></a>经典控制理论</h1><h2 id="动态系统建模"><a href="#动态系统建模" class="headerlink" title="动态系统建模"></a>动态系统建模</h2><p>通过配置系统输入u(t)，使u(s)G(s)的极点使系统满足一定特性</p><h3 id="一阶系统特性"><a href="#一阶系统特性" class="headerlink" title="一阶系统特性"></a>一阶系统特性</h3><p>$G(s) = \frac{a}{s+a}$<br>$\frac{1}{a}$是时间常数$\tau$，对应上升为0.63<br>$4\tau$对应阶跃响应0.98</p><h3 id="二阶系统特性"><a href="#二阶系统特性" class="headerlink" title="二阶系统特性"></a>二阶系统特性</h3><p>$m\ddot x+B\dot x+kx=F$<br>$\ddot x+2\omega_n\xi \dot x+\omega_n^2x=\frac{F}{m}$</p><p>阻尼比固有频率:$\omega_n\sqrt{1-\xi^2}$</p><p>单位化：$u(t)=\frac{F}{\omega_n^2}$<br>$H(s) = \frac{\omega_n^2}{s^2+2\xi\omega_ns+\omega_n^2}$</p><p><img src="/img/15744291457149.jpg" alt=""></p><p>零极点图：<br>极点全部在左，系统稳定<br>虚轴长度代表<strong>振荡周期</strong><br>实轴长度代表<strong>衰减速度</strong><br>$\cos \theta$代表<strong>阻尼比</strong></p><h2 id="SISO-system稳定性判据"><a href="#SISO-system稳定性判据" class="headerlink" title="SISO system稳定性判据"></a>SISO system稳定性判据</h2><p>特征多项式系数判断传递函数稳定性</p><ol><li>Hurwitz霍尔维兹判据：构建霍尔维兹行列式，全部为正</li></ol><p>$D1 = a_1$</p><p>$D2 = \begin{pmatrix}<br>a_1&amp;a_3\\<br>a_0&amp;a_2<br>\end{pmatrix}$</p><p>$D3 = \begin{pmatrix}<br>a_{1}&amp; a_{3}&amp; a_{5}\\<br>a_{0}&amp; a_{2}&amp; a_{4}\\<br>0&amp; a_{1}&amp; a_{3}<br>\end{pmatrix}$</p><ol><li>Lienard-Chipard林纳德-齐帕特判据：系数都大于零，奇数或偶数阶次行列式</li><li>Routh劳斯判据：<br>求$e_{ss}$时顺序，1判断稳定性、2求E(s)，3应用终值定理$e_{ss} = \lim \limits_{s\rightarrow0}sE(s)$</li><li>频率稳定判据：<br>H. Nyquist奈奎斯特判据，开环频率特性，判断闭环稳定性<br>$F(s) = 1 +G(s)H(s)$的p，极点，是开环传函极点<br>z零点，闭环传递函数的极点封闭曲线内$R=P-Z$</li></ol><h2 id="频率特性"><a href="#频率特性" class="headerlink" title="频率特性"></a>频率特性</h2><ul><li>只适用于线性定常模型，否则不能拉式变换</li><li>稳定条件下使用</li><li>bode图单位用dB：20log(Mo/Mi)，表征了能量</li></ul><ol><li>幅值相应:magnitude response<br>$\frac{M_o}{M_i} = \left | G(j\omega)\right |$</li><li>幅角响应:Phase response<br>$\phi_o-\phi_i = \angle G(j\omega)$</li><li><p>带阻尼比的共振频率:<br>$\omega = \omega_n \sqrt{1-2\zeta^2}\$<br>此时的极值：$\frac{1}{2\zeta\sqrt{1-\zeta^2}}$</p></li><li><p>幅值裕度h：相位为-π时，幅值距0dB的差值<br>相位裕度$\gamma$:幅值为1（0dB）时，相位距-π的差<br>根据幅相图，(0,0)出发为开环，(-1,0)出发为闭环</p></li><li><p>不同频段信息</p></li></ol><ul><li>低频段$G(j\omega)$反映了系统的稳态精度<br>0dB/sec-&gt;稳态精度</li><li>中频段：穿越0dB$\omega_c$<br>反映了系统的平稳性和快速性<br>-20dB/sec开环积分，闭环一阶，快速性<br>-40dB/sec开环双积分，闭环二阶，零阻尼，频率段不宜过宽，穿越频率取-20斜率</li><li>高频段反映了系统对高频干扰抑制能力</li></ul><h2 id="系统矫正"><a href="#系统矫正" class="headerlink" title="系统矫正"></a>系统矫正</h2><h3 id="串联矫正"><a href="#串联矫正" class="headerlink" title="串联矫正"></a>串联矫正</h3><ol><li><p>超前矫正<br>$G_c(s)=\frac{1+aTs}{1+Ts},a&gt;1$</p></li><li><p>滞后矫正<br>$G_c(s)=\frac{1+bTs}{1+Ts},b&lt;1$</p></li><li><p>滞后超前矫正<br>两个合起来</p></li><li><p>PID矫正器</p></li><li><p>复合矫正<br>前置矫正：指令-&gt;Gc(s)-&gt;误差，一般补偿分母s，开环前向增益1<br>干扰前置补偿：干扰测量-&gt;Gc(s)-&gt;误差，误差-&gt;干扰端传函$Gs^{-1}$</p></li></ol><h2 id="根轨迹"><a href="#根轨迹" class="headerlink" title="根轨迹"></a>根轨迹</h2><p>（开环-&gt;闭环稳定性）:分析G(s)的N、P，看闭环系统稳定性<br>开环传递函数中开环增益K从0-无穷时，闭环特征根的移动轨迹<br>单位负反馈闭环传递函数<br>$\phi(s) = \frac{C(s)}{R(s)}=\frac{G(s)}{1+G(s)}$<br>G(s)是一个 </p><p><img src="/img/%E6%88%AA%E5%B1%8F2020-04-12%20%E4%B8%8B%E5%8D%883.14.24-1.png" alt="截屏2020-04-12 下午3.14.24"></p><h3 id="非线性系统"><a href="#非线性系统" class="headerlink" title="非线性系统"></a>非线性系统</h3><p>叠加原理不适用<br>常规分类：<br>死区<br>饱和<br>间隙-滞环</p><p>系统收敛：消耗系统能量<br>系统发散：从外界获取能量</p><h1 id="相关词汇"><a href="#相关词汇" class="headerlink" title="相关词汇"></a>相关词汇</h1><p>$X_{ss}(t)$:ss-steady state<br>$T_s$Delay time<br>$T_r$Rise time<br>$M_p$Max Overshoot<br>$T_{ss}$Setting time调节时间<br>BIBO:输入稳定，输出稳定bounded input-bounded output<br>Real:实轴<br>Im：虚轴<br>Proportional：比例<br>Integral：积分<br>Differential：微分<br>bounded input-bounded output：稳定性<br>$\forall$for all ：任意<br>$\exists$ at least one ：存在<br>$\left | \cdot  \right |$norm：范数</p><h1 id="工程数学基础"><a href="#工程数学基础" class="headerlink" title="工程数学基础"></a>工程数学基础</h1><h2 id="1-特征值-特征向量-过渡矩阵-rightarrow-矩阵对角化"><a href="#1-特征值-特征向量-过渡矩阵-rightarrow-矩阵对角化" class="headerlink" title="1. 特征值,特征向量,过渡矩阵$\rightarrow$矩阵对角化"></a>1. 特征值,特征向量,过渡矩阵$\rightarrow$矩阵对角化</h2><p>特征值$\lambda$有$\lambda v=Av$<br>$\ | \lambda I-A\ | = 0$<br>特征值<br>解法：将$\lambda$代回$( \lambda I - A)<em> v = 0$<br>$\lambda_1 、\lambda_2$对应特征向量$v_1 、v_2$<br><em>*过渡矩阵</em></em>：特征向量组成的矩阵<br>$P =<br>\begin {pmatrix} v_1&amp;v_2<br>\end {pmatrix}$<br>$AP=A[v_1  v_2] = [Av_1 Av_2]=[\lambda_1v_1 \lambda_2 v_2]=<br>\begin{bmatrix}<br>\lambda_1v_{11} &amp; \lambda_2v_{21}\\<br>\lambda_1v_{12} &amp; \lambda_2v_{22}<br>\end{bmatrix}<br>=P\Lambda<br>$<br>所以有，单位向量矩阵P将A特征值对角化矩阵<br>$P^-1AP = \Lambda$</p><h2 id="2-线性化-Linearization"><a href="#2-线性化-Linearization" class="headerlink" title="2. 线性化 Linearization"></a>2. 线性化 Linearization</h2><p>非线性：$1/x,\sqrt{x},x^n等$</p><ul><li>用泰勒级数展开<br>在平衡点(Fixed point)$x_0$附近线性化</li></ul><ol><li>令导数项为0，求得平衡点x的值$x=x_0$</li><li>把$x_\sigma = x_0 + x_d$代入$f(x_\sigma)=f(x_0)+f’(x_0)(x_\sigma-x_0)$</li><li>把$x = x_\sigma$代入微分方程<br>将$\sigma$的x用x_0和x_d替换，然后<br>得到了关于x_d的线性化微分方程<br>$\dot x = A x + b u$求A的雅可比矩阵<br>行是函数，列为对变量的偏导；<br>求平衡点，代入偏导雅可比矩阵；<br>展开得到线性化后的微分方程</li></ol><h2 id="3-卷积与LTI冲激响应（LTI：linear-time-invariant-system）"><a href="#3-卷积与LTI冲激响应（LTI：linear-time-invariant-system）" class="headerlink" title="3. 卷积与LTI冲激响应（LTI：linear time invariant system）"></a>3. 卷积与LTI冲激响应（LTI：linear time invariant system）</h2><p>卷积：$x(t) = f(t)*h(t)=\int_0^t f(\tau)h(t-\tau)d\tau$<br>$f(t)$=输入<br>$h(t)$=单位冲激响应<br>$L_{卷积}$=L乘积</p><h2 id="4-欧拉公式Euler’s-Formula"><a href="#4-欧拉公式Euler’s-Formula" class="headerlink" title="4. 欧拉公式Euler’s Formula"></a>4. 欧拉公式Euler’s Formula</h2><p>$e^{i\theta}=\cos(\theta)+i\sin(\theta)$</p><h2 id="5-复数Complex-Number"><a href="#5-复数Complex-Number" class="headerlink" title="5. 复数Complex Number"></a>5. 复数Complex Number</h2><p> $\sin(x) = C\rightarrow x = \pi/2+2k\pi + \ln(C\pm\sqrt{C^2-1})i$<br>$Z = a + b i $<br>$Re(Z) =a $<br>$Im(Z)=b $<br>$\left | Z \right | = \sqrt{a^2+b^2}$<br>$Z = \left | Z \right | \cdot (\cos\theta+i\sin\theta)= \left | Z \right | \cdot e^{i\theta}$<br>$Z_1 \cdot Z_2 = \left | Z_1 \right | \left | Z_2 \right | e^{\theta_1+\theta_2}$<br>$Z+\bar Z = 2a$<br>$Z- \bar Z = 2bi$</p><h2 id="6-阈值选取"><a href="#6-阈值选取" class="headerlink" title="6. 阈值选取"></a>6. 阈值选取</h2><p>Normal Distribution正态分布、高斯分布<br>$X = (\mu,\sigma^2)$<br>漏检False Dismissal<br>误警False Alarm</p><h1 id="Advanced控制理论"><a href="#Advanced控制理论" class="headerlink" title="Advanced控制理论"></a>Advanced控制理论</h1><p>状态空间：State-Space，包含输入、输出、状态，写成一阶微分方程的形式<br>$\dot x = A x + B u$<br>$y = Cx+Du$</p><h2 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h2><h3 id="两种类型"><a href="#两种类型" class="headerlink" title="两种类型"></a>两种类型</h3><ol><li><p>Lyapunov稳定性：有界<br>$\forall t_0, \forall \epsilon &gt;0, \exists \delta (t_0, \epsilon):\left | x(t_0)\right |&lt;\delta(t_0,\epsilon)\Rightarrow \forall t \geqslant t_0,  \left | x(t) \right | &lt; \epsilon$<img src="/img/15753853291223.jpg" alt=""><br>$a \, of\,  \lambda_i \leqslant 0$实部<br>判断方法：</p></li><li><p>渐进稳定性：<br>$\exists \delta(t_0)&gt;0: \left |x(t_0)\right |&lt;\delta(t_0) \Rightarrow<br>\lim \limits_{t \rightarrow \infty }<br>\left | x(t)\right | = 0<br>$<br>$a \, of\,  \lambda_i &lt; 0$实部</p></li></ol><h3 id="判别方法"><a href="#判别方法" class="headerlink" title="判别方法"></a>判别方法</h3><ol><li>直接方法：解微分方程(Direct method)<br>求解λ的值，判断正负</li><li>第二方法：(2nd method)<br>$(i)V(0) = 0$<br>$(ii) V(x) \geqslant  0 , in\,  D-{0}$ PSD:postive semi definit<br>$(iii)\dot V(x) \leqslant 0 , in\,  D-{0}$NSD:negative semi definit<br>$\Rightarrow x = 0$</li></ol><h3 id="3-不稳定"><a href="#3-不稳定" class="headerlink" title="3. 不稳定"></a>3. 不稳定</h3><p>存在至少一个特征值实部大于零</p><h2 id="相图分析-phase-portrait"><a href="#相图分析-phase-portrait" class="headerlink" title="相图分析-phase-portrait"></a>相图分析-phase-portrait</h2><p>plot(x,$\dot x$)，通过x初值，分析点在轨迹上的移动，判断稳不稳定<br>matlab绘制实例</p><pre><code>% 画解微分方程组的相图clear;cla;clc;[x,y]=meshgrid(linspace(-5,5));streamslice(x,y,0 * x + 2 * y,-3 * x + 0 * y );xlabel('x');ylabel('y');</code></pre><p><img src="/img/15747442437226.jpg" alt="w400"></p><p>特征值和相图的关系<br><img src="/img/15753593791413.jpg" alt=""></p><h2 id="齐次状态方程解-dot-x-A-x"><a href="#齐次状态方程解-dot-x-A-x" class="headerlink" title="齐次状态方程解$\dot x = A x$"></a>齐次状态方程解$\dot x = A x$</h2><p>$\dot x = a x\rightarrow x(t) = e^{at}x(0)$<br>同理，多元线性方程<br>$\dot x = a x\rightarrow x(t) = e^{At}x(0)$<br>其中，<strong>状态转移矩阵$\Phi(t)$解法</strong></p><ul><li>数值法：<br>$\Phi(t) = e^{At}=I+At+\frac{1}{2!}A^2t^2+…+\frac{1}{k!}A^kt^k$</li><li>解析法：<br>$\Phi(t) = L^{-1}[sI-A]^{-1}$</li></ul><p>性质：<br>$\Phi(0) = I$<br>$x(t) = \Phi(t-t_0)x(t_0)$<br>$\Phi ^{-1}(t) = \Phi(-t)$</p><h2 id="非齐次状态方程-dot-x-A-x-B-u"><a href="#非齐次状态方程-dot-x-A-x-B-u" class="headerlink" title="非齐次状态方程$\dot x = A x + B u$"></a>非齐次状态方程$\dot x = A x + B u$</h2><p>$x(t) = \Phi (t)x(0)+ \int_0^t\Phi(t-\tau)Bu(\tau)d\tau$<br>初始状态x(0)响应+输入项u(t)响应</p><h2 id="线性系统可控性与可观测性"><a href="#线性系统可控性与可观测性" class="headerlink" title="线性系统可控性与可观测性"></a>线性系统可控性与可观测性</h2><p>可控性：$\forall x(0),x(t_f), \exists t_f &lt; +\infty , u[0,t_f], st. x(0)\rightarrow x(t_f)$<br>充要条件：</p><ol><li><p>$S = [b\, Ab\, A^2…\, A^{n-1}b]$<br>理论可行，但是实际物理不一定<br>以离散系统为例证明：</p><script type="math/tex; mode=display">x_ 0 = 0\\x_1 = Ax_0 + Bu_0 = Bu_0\\x_2 = Ax_1 + Bu_1 = ABu_0 + B u_1\\x_3 = Ax_2 + Bu_2 = A^2Bu_0 + AB u_1 + B u_2\\</script><p>Matlab 求解，Co矩阵 “ctrb(A,B)”</p></li><li><p>$rank[S] = n, det \,  S \neq 0$</p></li></ol><p>可观性：$\forall t \in [t_0,t_f],已知y(t),u(t),可求x(t_0)$<br>$rank<br>\begin{bmatrix}<br>C\\<br>CA\\<br>CA^2\\<br>…\\<br>CA^{n-1}<br>\end{bmatrix}<br>=n<br>$</p><h3 id="引理"><a href="#引理" class="headerlink" title="引理"></a>引理</h3><p>$f(\lambda) = \sum_{i=0}^{n}a_i\lambda ^i$<br>$f(A) = 0 \rightarrow A^n = \sum_{i=0}^{n-1}a_iA^i$</p><p>求解$\left | \lambda I - A\right |$的特征多项式<br>将$\lambda = A $代入，得到递推公式，解算$A^n$</p><h2 id="状态反馈与状态观测器"><a href="#状态反馈与状态观测器" class="headerlink" title="状态反馈与状态观测器"></a>状态反馈与状态观测器</h2><p>取$u=v-kx$，其中，v为参考输入，系统闭环矩阵由A变为A-Bk</p><ol><li>不改变可控性，有可能改变可观性</li><li>闭环特征值</li></ol><h2 id="状态观测器"><a href="#状态观测器" class="headerlink" title="状态观测器"></a>状态观测器</h2><p><img src="/img/15755438743134.jpg" alt=""></p><h1 id="Kalman滤波器原理以及在matalb中的实现"><a href="#Kalman滤波器原理以及在matalb中的实现" class="headerlink" title="Kalman滤波器原理以及在matalb中的实现"></a>Kalman滤波器原理以及在matalb中的实现</h1><p>状态转移矩阵：<br>这里要改一下，改成估计量<br>$x_t^- = F_t x_{t-1} + B_t u_t$</p><p>状态转移矩阵:$P_t^-=FP_{t-1}F^T+Q$</p><p>协方差矩阵:<br>$<br>\begin{bmatrix}<br>\sigma_{11}&amp;\sigma_{12}\\<br>\sigma_{12}&amp;\sigma_{22}\\<br>\end{bmatrix}<br>$</p><p><img src="/img/15748205077671.jpg" alt="w400"></p><p>卡尔曼方程≠状态观测器<br><img src="/img/15755459115506.jpg" alt="m180"></p><p><img src="/img/15755450314782.jpg" alt=""><br>以小车为例，讲卡尔曼滤波最优状态估计<br><img src="/img/15755448894756.jpg" alt=""><br>在上图中，P是观测值$\hat x$的方差<br>R是观测器中，来自预估值的比例</p><p>概率函数相乘，多传感器信息融合</p><h2 id="非线性控制理论"><a href="#非线性控制理论" class="headerlink" title="非线性控制理论"></a>非线性控制理论</h2><h3 id="ARC"><a href="#ARC" class="headerlink" title="ARC"></a>ARC</h3><p>Barbalat’s 引理 lemma</p><ol><li>$V\geq0$</li><li>$\dot{V} \leq -g(t)$, where $g(t)\geq 0$</li><li>$\dot{g}(t)\in L_{\infty}$, if $\dot{g}(t)$ is bounded the $g(t)$ is uniformly continous.<br>Then, $\lim_{t-&gt;\infty} g(t)=0$<br>Consquently, $\lim_{t-&gt;\infty} e = 0 (k\neq0)$</li></ol><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高级控制理论 </tag>
            
            <tag> 经典控制理论 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mac设置</title>
      <link href="/posts/settings-mac/"/>
      <url>/posts/settings-mac/</url>
      
        <content type="html"><![CDATA[<h1 id="系统相关"><a href="#系统相关" class="headerlink" title="系统相关"></a>系统相关</h1><h2 id="系统安装工具"><a href="#系统安装工具" class="headerlink" title="系统安装工具"></a>系统安装工具</h2><ul><li><p>系统安装、刻录工具<br><a href="https://rufus.akeo.ie/downloads/">U启动盘制作工具rufus</a><br>WTG辅助工具wtg-assistant</p></li><li><p>bootcamp蓝牙鼠标连不上<br>重置SMC，关机，control➕option➕shift➕电源for10s，再开机</p></li></ul><h2 id="Terminal——终端"><a href="#Terminal——终端" class="headerlink" title="Terminal——终端"></a>Terminal——终端</h2><ul><li>系统允许任何来源安装包<br>sudo spctl —master-disable</li><li>使其变为可执行脚本<br><code>chmod u+x filename</code> </li><li>更改skim背景色<br><code>defaults write -app skim SKPageBackgroundColor -array 0.78 0.93 0.8 1</code></li><li>命令行压缩加密压缩包<br>压缩文件<br><code>zip -e test.zip test.txt</code><br>压缩文件夹<br><code>zip -er test.zip test</code></li><li>读写ntfs 文件灰色，无法打开，拷贝<br><code>xattr -d com.apple.FinderInfo filepath</code></li><li><p>跳过验证dmg<br><code>xattr -d com.apple.quarantine '/Applications/Xcode.app'</code></p></li><li><p>brew<br><a href="https://www.jianshu.com/p/67db55780450">brew安装</a><br><a href="https://www.jianshu.com/p/6ea6e19c060d">mac brew install 慢解决办法</a></p></li><li><p>mac10.15软件安装提示已损坏解决办法<br>终端执行<br><code>sudo spctl --master-disablesudo xattr -r -d com.apple.quarantine /Applications/Sketch.app/</code></p></li><li><p>编辑环境变量文件文件<br>```cd ~/<br>vim .bash_profile</p><pre><code>粘贴入下列代码</code></pre><h1 id="proxy-list"><a href="#proxy-list" class="headerlink" title="proxy list"></a>proxy list</h1><p>alias proxy=’export all_proxy=socks5://127.0.0.1:1086’<br>alias unproxy=’unset all_proxy’</p><pre><code>control + c 键入wq保存退出 保存隐藏文件到环境变量```cd ~/source .bash_profile</code></pre></li></ul><h3 id="咳血上网"><a href="#咳血上网" class="headerlink" title="咳血上网"></a>咳血上网</h3><ul><li><a href="https://zcssr.me/auth/login">HJF-ZCSSR订阅购买网站</a></li><li>订阅地址：<ul><li>ssr订阅：<code>https://n55.pw/link/PgKooWdckjZl5hf⑧</code></li><li>clash订阅：<code>https://n55.pw/link/PgKooWdckjZl5hf⑧?clash=①</code></li></ul></li><li>节点测速链接<ul><li><a href="https://fast.com/zh/cn/#">Netflix</a></li><li><a href="https://www.speedtest.net/">speedtest</a></li></ul></li></ul><h2 id="hosts修改"><a href="#hosts修改" class="headerlink" title="hosts修改"></a>hosts修改</h2><p>shift+command+G<br>前往<br><code>/private/etc/</code></p><h2 id="Mac系统插件推荐"><a href="#Mac系统插件推荐" class="headerlink" title="Mac系统插件推荐"></a>Mac系统插件推荐</h2><ul><li>On my way!微信插件</li><li><a href="https://www.zhihu.com/question/24850356">浏览器弹出mackeeper广告清理</a></li><li><a href="https://www.macx.cn/thread-2204536-1-1.html">油猴</a></li></ul><h2 id="Mac-OS-X-11中的-usr-bin-的“Operation-not-permitted”"><a href="#Mac-OS-X-11中的-usr-bin-的“Operation-not-permitted”" class="headerlink" title="Mac OS X 11中的/usr/bin 的“Operation not permitted”"></a>Mac OS X 11中的/usr/bin 的“Operation not permitted”</h2><p><a href="https://www.jianshu.com/p/22b89f19afd6">https://www.jianshu.com/p/22b89f19afd6</a></p><h2 id="设置mac-PATH"><a href="#设置mac-PATH" class="headerlink" title="设置mac PATH"></a>设置mac PATH</h2><p>在mac系统下打开终端，输入：<br><code>touch .bash_profileopen -e .bash_profile</code><br>这样会弹出一个“.bash_profile”文件.<br>打开文件后应该是空白的，在文件中添加：<br>export PATH=${PATH}:????</p><p>其中????代表你电脑中adb文件的路径，本人的配置文件如下：<br><code>export PATH=${PATH}:~/Library/Android/sdk/platform-tools</code><br>添加完后，保存并关闭文件，至此，adb配置完毕。</p><h2 id="前往网上邻居"><a href="#前往网上邻居" class="headerlink" title="前往网上邻居"></a>前往网上邻居</h2><p>finder目录<code>command+K</code><br><strong>One cloud</strong>:<br><code>smb://192.168.31.200</code></p><h2 id="Terminal-commands"><a href="#Terminal-commands" class="headerlink" title="Terminal commands"></a>Terminal commands</h2><p>图片本地压缩工具：<code>imageoptim aaa.jpg</code><br>开源软件安装：<code>brew install example</code><br>python库安装<code>pip3 install example</code><br>最后更新配置的环境变量<code>source .bash_profile</code></p><p>同理：http代理设置如下：</p><ul><li>让终端走http代理——应用层，不改变系统层<pre><code>export http_proxy="http://localhost:1087"export https_proxy="http://localhost:1087"</code></pre></li></ul><p><a href="https://mirrors.tuna.tsinghua.edu.cn/help/homebrew/">brew 源替换清华</a><br>git 太慢的解决办法</p><ol><li>在<a href="https://www.ipaddress.com/查询网址对应ip">https://www.ipaddress.com/查询网址对应ip</a></li><li>手动更改hosts</li></ol><pre><code>199.232.68.133 raw.githubusercontent.com199.232.69.194 github.global.ssl.fastly.net140.82.114.4 github.com</code></pre><ol><li><p>刷新dns缓存<br><code>sudo dscacheutil -flushcache</code></p></li><li><p>git 代理设置<br>手动操作</p></li></ol><ul><li>设置</li></ul><pre><code>git config --global http.proxy socks5://127.0.0.1:1086;git config --global https.proxy socks5://127.0.0.1:1086</code></pre><ul><li>卸载</li></ul><pre><code>git config --global --unset http.proxygit config --global --unset https.proxy</code></pre><ul><li>写入命令行vim添加：</li></ul><pre><code>alias git_proxy='git config --global http.proxy socks5://127.0.0.1:1086; git config --global https.proxy socks5://127.0.0.1:1086'alias ungit_proxy='git config --global --unset http.proxy; git config --global --unset https.proxy'</code></pre><p>查看是否添加上：<br><code>cat ~/.gitconfig</code></p><ul><li>brew源更改（采用阿里云）</li></ul><pre><code>cd "$(brew --repo)"# 查看远程仓库git remote -v# 删除远程git remote rm origin # 添加阿里源 ：git remote add origin https://mirrors.aliyun.com/homebrew/brew.git# 切换成阿里源: git remote set-url origin https://mirrors.aliyun.com/homebrew/brew.git</code></pre><ul><li>brew-core源更改</li></ul><pre><code>cd "$(brew --repo)/Library/Taps/homebrew/homebrew-core"# 查看远程仓库 git remote -v # 删除远程： git remote rm origin # 添加阿里源 ：git remote add origin https://mirrors.aliyun.com/homebrew/homebrew-core.git# 切换成阿里源： git remote set-url origin https://mirrors.aliyun.com/homebrew/homebrew-core.git</code></pre><ul><li>bottle源更改</li></ul><pre><code>echo 'export HOMEBREW_BOTTLE_DOMAIN=https://mirrors.aliyun.com/homebrew/homebrew-bottles' &gt;&gt; ~/.bash_profilesource ~/.bash_profile</code></pre><ul><li>cask源更改（中科大源）</li></ul><pre><code>cd "$(brew --repo)"/Library/Taps/homebrew/homebrew-caskgit remote rm origin git remote add origin https://mirrors.ustc.edu.cn/homebrew-cask.gitgit remote set-url origin https://mirrors.ustc.edu.cn/homebrew-cask.git</code></pre><ul><li>环境变量设置，快捷命令设置<br>自己在 ~/.bash_profile 中配置环境变量, 可是每次重启终端后配置的不生效.需要重新执行<br><code>$source ~/.bash_profile</code><br>发现zsh加载的是 ~/.zshrc文件，而 ‘.zshrc’ 文件中并没有定义任务环境变量。<br>解决办法</li></ul><p>在~/.zshrc文件最后，增加一行：<br><code>source ~/.bash_profile</code></p><h2 id="UEFI多系统引导工具"><a href="#UEFI多系统引导工具" class="headerlink" title="UEFI多系统引导工具"></a>UEFI多系统引导工具</h2><ul><li>clover</li><li>rEFInd：</li><li>grub4dos</li></ul><h2 id="Finder"><a href="#Finder" class="headerlink" title="Finder"></a>Finder</h2><ul><li>显示隐藏文件：shift + Command + . </li></ul><h2 id="ntfs原生挂载"><a href="#ntfs原生挂载" class="headerlink" title="ntfs原生挂载"></a>ntfs原生挂载</h2><p>terminal：<br><code>sudo nano /etc/fstab</code><br><code>LABEL=Elements\040SE none ntfs rw,auto,nobrowse</code><br>\040代表空格<br>ctrl + x 保存，y确定</p><h1 id="Coding"><a href="#Coding" class="headerlink" title="Coding"></a>Coding</h1><h2 id="Latex"><a href="#Latex" class="headerlink" title="Latex"></a>Latex</h2><ol><li>文献不引用编译会报错，修正方法，clean过程文件，重新编译</li><li><a href="http://www.latexstudio.net/archives/12260.html">mac vs code 改编译器</a></li><li><a href="http://www.latexstudio.net/archives/12321.html">mac vs_code skim_pdf_viewer设置</a></li><li>vscode-skim正向同步：命令行，sync from cursor，快捷键option+command+J</li><li>vscode-skim反向同步：shift+command+click</li><li>vscode-编译：command + shift + B</li><li>xelatex编译慢的解决办法，重建字体缓存<code>fc -cache -fv</code></li></ol><h3 id="Mac中输入latex公式，用mathtype编译"><a href="#Mac中输入latex公式，用mathtype编译" class="headerlink" title="Mac中输入latex公式，用mathtype编译"></a>Mac中输入latex公式，用mathtype编译</h3><p>mac word 中键入latex公式<br>输入格式如下$f(x) = a^2+2$<br>按下option(alt)+\，mathtype会编译，并且可以修改</p><h2 id="其他插件-多数可见"><a href="#其他插件-多数可见" class="headerlink" title="其他插件-多数可见"></a>其他插件-多数可见</h2><p>pdf: PDF Expert、skim<br>远程控制: AnyDesk<br>文献管理: Mendeley Desktop<br>编程学习: Code Runner<br>翻墙: <a href="https://github.com/XX-net/XX-Net">xx.net</a><br>Markdown：MWeb，<a href="https://zh.mweb.im/how_to_use_library_in_ios.html">使用说明</a><br>safari 插件：polyglot，双击选中翻译</p><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><ol><li><a href="http://matplotlib.org/users/installing.html" title="matplotlib">matplotlib官网</a></li><li>VSCODE，编译器选Python3，设置路径</li><li>mac上使用virtualenv搭建多个<a href="https://www.jianshu.com/p/6ff149813e6c">python环境</a></li><li>Python3.x.x后安装pip出现command not found 错误<a href="http://blog.csdn.net/llh_1178/article/details/77948568">http://blog.csdn.net/llh_1178/article/details/77948568</a></li><li>Matplotlib论文格式python plot<code>pip install git+https://github.com/garrettj403/SciencePlots.git</code></li><li>python3 matplot修改中文字体<br>以下内容只针对mac os x ，亲测有效</li></ol><hr><p>1.从mac字体目录/System/Library/Fonts<br>添加SimHei字体（simhei.ttf文件）到<br>/usr/local/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/xxx.ttf<br>2.rm -rf ~/.matplotlib/*.cache<br>注意rm -rf命令，确认路径没错在用设置matplotlib使用的字体资源<br>我是直接重命名的方式，避免出错。<br>3.<br>代码中添加<br>mpl.rcParams[‘font.sans-serif’] = u’SimHei’</p><ol><li><a href="https://blog.csdn.net/gmr2453929471/article/details/78655834">更改字体</a></li></ol><h2 id="黑苹果安装"><a href="#黑苹果安装" class="headerlink" title="黑苹果安装"></a>黑苹果安装</h2><p>聪聪黑苹果一键安装工具</p><h1 id="Something-interesting"><a href="#Something-interesting" class="headerlink" title="Something interesting"></a>Something interesting</h1><h2 id="US-fake信息"><a href="#US-fake信息" class="headerlink" title="US-fake信息"></a>US-fake信息</h2><p><a href="https://www.fakenamegenerator.com/index.php#">https://www.fakenamegenerator.com/index.php#</a></p><h2 id="mac手柄ps3-controller-on-windows"><a href="#mac手柄ps3-controller-on-windows" class="headerlink" title="mac手柄ps3 controller on windows"></a>mac手柄ps3 controller on windows</h2><p><a href="https://www.youtube.com/watch?v=c0qXZHNj_P4">https://www.youtube.com/watch?v=c0qXZHNj_P4</a><br>第三方mac无线支持<br><a href="https://gist.github.com/OlesenkoViktor/32c700e025bf4567db8feb1ed467f8ee">https://gist.github.com/OlesenkoViktor/32c700e025bf4567db8feb1ed467f8ee</a></p><p>最后发现，先启动retroarch之后，手柄就可以在openemu等平台使用</p><h2 id="mac——安卓刷机"><a href="#mac——安卓刷机" class="headerlink" title="mac——安卓刷机"></a>mac——安卓刷机</h2><p>android adb 黑域<br><code>adb devicesadb -d shell sh /data/data/me.piebridge.brevent/brevent.sh</code></p><p>fastboot模式：<code>adb  reboot bootloader</code></p><p><a href="https://www.jianshu.com/p/5ba1cf5869bc">mac_adb_安卓刷机</a></p><p>[pixel_root教程] (<a href="https://highonandroid.com/android-smartphones/how-to-root-android-p9-0-pixelpixel-xlpixel-2pixel-2xl/">https://highonandroid.com/android-smartphones/how-to-root-android-p9-0-pixelpixel-xlpixel-2pixel-2xl/</a>)</p><p><a href="https://twrp.me">TWRP下载地址</a>：第三方recovery<br>root 管理器：magisk</p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 设置备忘 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 系统 </tag>
            
            <tag> Mac </tag>
            
            <tag> 黑苹果 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Latex设置</title>
      <link href="/posts/settings-latex/"/>
      <url>/posts/settings-latex/</url>
      
        <content type="html"><![CDATA[<h1 id="Texpad-备忘"><a href="#Texpad-备忘" class="headerlink" title="Texpad 备忘"></a>Texpad 备忘</h1><h2 id="实时编译"><a href="#实时编译" class="headerlink" title="实时编译"></a>实时编译</h2><p>Texpad live 支持实时编译<br>缺点：不支持高级packages，如cref</p><p>经过验证，下列包不支持实时编译</p><pre><code>\crefname&amp;#123;figure&amp;#125;&amp;#123;Fig.&amp;#125;&amp;#123;Figs.&amp;#125;\crefname&amp;#123;table&amp;#125;&amp;#123;Table.&amp;#125;&amp;#123;Tables.&amp;#125;\crefname&amp;#123;appendix&amp;#125;&amp;#123;&amp;#125;&amp;#123;&amp;#125;\crefname&amp;#123;equation&amp;#125;&amp;#123;&amp;#125;&amp;#123;&amp;#125;</code></pre><p>所以最后文档定型之后，调整格式的时候再添加</p><h2 id="强制使用自定义图例标签，ref"><a href="#强制使用自定义图例标签，ref" class="headerlink" title="强制使用自定义图例标签，ref"></a>强制使用自定义图例标签，ref</h2><p>\renewcommand{\Figurename}{Fig.}</p><h2 id="投稿latex模板自定义修改"><a href="#投稿latex模板自定义修改" class="headerlink" title="投稿latex模板自定义修改"></a>投稿latex模板自定义修改</h2><p>一般要求单列，双倍间距（可以在cls文件里面调）</p><h1 id="Word公式转换"><a href="#Word公式转换" class="headerlink" title="Word公式转换"></a>Word公式转换</h1><p>mathtype支持latex公式和mathml公式的转换<br>Win10有BUG，默认报错找不到<code>.xml</code>文件<br>需要用管理员打开word，才能mathtype不报错</p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 设置备忘 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> snippets </tag>
            
            <tag> latex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matlab设置</title>
      <link href="/posts/settings-matlab/"/>
      <url>/posts/settings-matlab/</url>
      
        <content type="html"><![CDATA[<h2 id="代码片段snippets"><a href="#代码片段snippets" class="headerlink" title="代码片段snippets"></a>代码片段snippets</h2><ul><li>保存pdf调整a4纸至合适大小</li></ul><pre><code>h = figure;plot(1:10);set(h,'Units','Inches');pos = get(h,'Position');set(h,'PaperPositionMode','Auto','PaperUnits','Inches','PaperSize',[pos(3), pos(4)])print(h,'filename','-dpdf','-r0')</code></pre><ul><li>缺省参数默认值设定</li></ul><pre><code>function f(arg1, arg2, arg3)if ~exist('arg2', 'var')    arg2 = arg2Default;end</code></pre><ul><li><a href="https://blog.csdn.net/ckzhb/article/details/81105384">plot-legend多行设置</a></li></ul><pre><code>hg1 = legend('第一条');set(hg1,'FontSize',12,'Location', 'SouthOutside','box','off');  %注：将legend放在图外面时，Legend 1不能通过鼠标移动，只能通过代码调整位置 % ============= Legend 2 :ah2 = axes('position',get(gca,'position'),'visible','off');hg2 = legend(ah2, [p2 p3], '第二条', '第三条');set(hg2,'FontSize',12,'Location', 'SouthOutside',...        'Orientation','horizontal','box','off');</code></pre><p>Another way:<br><code>legend({'cos(x)','cos(2x)','cos(3x)','cos(4x)'},'Location','northwest','NumColumns',2)</code></p><ul><li>mac打开时闪退<br><code>/Applications/Polyspace/R2019b.app/bin/matlab -nosplash</code></li><li>matlab-mex命令 10.15.4问题<br><code>https://www.mathworks.com/matlabcentral/answers/512901-mex-xcodebuild-error-sdk-macosx10-15-4-cannot-be-located/?s_tid=mlc_lp_leaf</code></li></ul><h2 id="绘制等高线"><a href="#绘制等高线" class="headerlink" title="绘制等高线"></a>绘制等高线</h2><pre><code>contour(u, v, z, [-0.5, -0.5], 'LineWidth', 2)</code></pre><p>区间是zlim</p><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 设置备忘 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> snippets </tag>
            
            <tag> matlab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python-snippets</title>
      <link href="/posts/settings-python/"/>
      <url>/posts/settings-python/</url>
      
        <content type="html"><![CDATA[<h2 id="python读取txt数据plot"><a href="#python读取txt数据plot" class="headerlink" title="python读取txt数据plot"></a>python读取txt数据plot</h2><h2 id="python保存data到excel"><a href="#python保存data到excel" class="headerlink" title="python保存data到excel"></a>python保存data到excel</h2><pre><code>import numpy as npimport pandas as pd# prepare for datadata = np.arange(1,101).reshape((10,10))data_df = pd.DataFrame(data)# change the index and column namedata_df.columns = ['A','B','C','D','E','F','G','H','I','J']data_df.index = ['a','b','c','d','e','f','g','h','i','j']# create and writer pd.DataFrame to excelwriter = pd.ExcelWriter('Save_Excel.xlsx')data_df.to_excel(writer,'page_1',float_format='%.5f') # float_format 控制精度writer.save()</code></pre><h2 id="python-Science-风格画图"><a href="#python-Science-风格画图" class="headerlink" title="python Science 风格画图"></a>python Science 风格画图</h2><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 设置备忘 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> snippets </tag>
            
            <tag> python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>template</title>
      <link href="/posts/template/"/>
      <url>/posts/template/</url>
      
        <content type="html"><![CDATA[<h1 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h1><script type="math/tex; mode=display">\pi_{\theta}(s, a)=\mathbb{P}[a \mid s, \theta]</script><script type="math/tex; mode=display">\hat{\mathcal{P}}_{s, s^{\prime}}^{a} =\frac{1}{N(s, a)} \sum_{k=1}^{K} \sum_{t=1}^{T_{k}} 1\left(s_{t}^{k}, a_{t}^{k}, s_{t+1}^{k}=s, a, s^{\prime}\right)</script><script type="math/tex; mode=display">\hat{\mathcal{R}}_{s}^{a} =\frac{1}{N(s, a)} \sum_{k=1}^{K} \sum_{t=1}^{T_{k}} 1\left(s_{t}^{k}, a_{t}^{k}=s, a\right) r_{t}^{k}</script><script type="math/tex; mode=display">\mathcal{L}_{i}\left(w_{i}\right)=\mathbb{E}_{s, a, r, s^{\prime}} \sim \mathcal{D}_{i}\left[\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime} ; w_{i}^{-}\right)-Q\left(s, a ; w_{i}\right)\right)^{2}\right]</script><script type="math/tex; mode=display">\pi</script><p><img src="/img/contact.jpg" alt=""></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      
        <tags>
            
            <tag> test </tag>
            
            <tag> hello world </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
